\subsection{Definitions}
In this course, \emph{ring} means a commutative nonzero ring.
If \( R \) is a ring, \( R[X] \) denotes the ring of polynomials with elements \( \sum_{i=0}^n a_i X^i \), and the usual operations of addition and multiplication.
A polynomial \( f \in R[X] \) can be interpreted as a function \( f \colon R \to R \), given by \( x \mapsto \sum_{i=0}^n a_i x^i \).
It is, however, important to distinguish the polynomial and its associated function; the polynomial is not in general uniquely determined by the function.
For example, let \( R = \faktor{\mathbb Z}{p\mathbb Z} \), so for all \( a \in R \), we have \( a^p = a \), and hence \( X^p \) and \( X \) are different polynomials yet represent the same function.

Recall from Groups, Rings and Modules that if \( R = K \) is a field, \( K[X] \) is a Euclidean domain (and hence is a unique factorisation domain, a Noetherian ring, a principal ideal domain, and an integral domain).
Hence, there is a division algorithm: for polynomials \( f, g \in K[X] \), there exists a unique \( q, r \in K[X] \) such that \( f = gq + r \) and \( \deg r < \deg g \), where we denote \( \deg 0 = -\infty \).
If \( g = X - a \) is linear, \( f = (X-a)q + r \) where \( r = f(a) \in K \); this is the familiar remainder theorem.
Note that every polynomial \( f \in K[X] \) is a product of irreducible polynomials since \( K[X] \) is a unique factorisation domain, and there are greatest common divisors which can be computed using Euclid's algorithm in the usual way.

\begin{proposition}
	Let \( K \) be a field, and \( 0 \neq f \in K[X] \).
	Then, \( f \) has at most \( \deg f \) roots in \( K \).
\end{proposition}
\begin{proof}
	If \( f \) has no roots, the proof is complete.
	If \( f \) has a root \( a \), consider \( f = (X - a)q + f(0) = (X - a)q \).
	For a root \( b \) of \( f \), either \( b = a \) or \( q(b) = 0 \).
	By induction, \( q \) has at most \( \deg q \) roots, since \( \deg q < \deg f \).
	Then \( \deg q + 1 \leq \deg f \) as required.
\end{proof}

\subsection{Symmetric polynomials}
\begin{definition}
	Let \( R \) be a ring, and let \( n \geq 1 \).
	A polynomial \( f \in R[X_1, \dots, X_n] \) is \emph{symmetric} if, for every permutation \( \sigma \in S_n \), we have \( f(X_{\sigma(1)}, \dots, X_{\sigma(n)}) = f(X_1, \dots, X_n) \), where \( S_n \) is the symmetric group of degree \( n \).
\end{definition}
Note that constant polynomials are symmetric, and the property of symmetry is closed under addition and multiplication.
Hence, the set of symmetric polynomials is a subring of \( R[X_1, \dots, X_n] \).
\begin{example}
	\( X_1 + \dots + X_n \) is symmetric.
	More generally, \( p_k = X_1^k + \dots + X_n^k \) is symmetric.
\end{example}
\begin{proposition}
	Let \( f \sigma(X) = f(X_{\sigma(1)}, \dots, X_{\sigma(n)}) \).
	This gives an action (on the right) of the group \( S_n \) on \( R[X_1, \dots, X_n] \).
	A polynomial \( f \in R[X_1, \dots, X_n] \) is symmetric if and only if \( f \) is fixed under the action of \( S_n \); in other words, \( f\sigma = f \) for all \( \sigma \in S_n \).
\end{proposition}
\begin{example}
	The \emph{elementary symmetric functions} or \emph{elementary symmetric polynomials} are
	\[ S_r(X_1, \dots, X_n) = \sum_{i_1 < \dots < i_r} X_{i_1} X_{i_2} \cdots X_{i_r} \]
	For instance,
	\[ S_2(X_1, X_2, X_3) = X_1 X_2 + X_1 X_3 + X_2 X_3 \]
	It is clear that these are symmetric polynomials.
\end{example}
\begin{theorem}
	Every symmetric polynomial over a ring \( R \) can be expressed as a polynomial in the \( S_r \) for \( 1 \leq r \leq n \), with coefficients in \( R \).
	Further, there are no non-trivial relations between the \( S_r \).
\end{theorem}
