\subsection{Fourier transforms}
In this section, we will write \( L^p(\mathbb R^d) \) for the set of measurable functions \( f \colon \mathbb R^d \to \mathbb C \) such that \( \norm{f}_p = \qty(\int_{\mathbb R^d} \abs{f(x)}^p \dd{x})^{\frac 1p} < \infty \).
We can extend the integral as a complex linear map \( L^1(\mathbb R) \to \mathbb C \) by defining
\[ \int_{\mathbb R} (u + iv)(x) \dd{x} = \int_{\mathbb R} u(x) \dd{x} + i \int_{\mathbb R} v(x) \dd{x} \]
Note that for some \( u + iv = \alpha \in \mathbb C \) with \( \abs{\alpha} = 1 \),
\[ \abs{\int_{\mathbb R^d} f(x) \dd{x}} = \int_{\mathbb R^d} \alpha f(x) \dd{x} = \int_{\mathbb R^d} u(x) \dd{x} + i \int_{\mathbb R^d} v(x) \dd{x} \]
But since the left hand side is real-valued, the \( i \int_{\mathbb R^d} v(x) \dd{x} \) term vanishes.
So
\[ \abs{\int_{\mathbb R^d} f(x) \dd{x}} = \int_{\mathbb R^d} u(x) \dd{x} \leq \int_{\mathbb R^d} \abs{f(x)} \dd{x} \]
\begin{definition}
	Let \( f \in L^1(\mathbb R^d) \).
	We define the \emph{Fourier transform} \( \hat f \) by
	\[ \hat f(u) = \int_{\mathbb R^d} f(x) e^{i\inner{u,x}} \dd{x} \]
	where \( \inner{u,x} = \sum_{i=1}^d u_i x_i \).
\end{definition}
\begin{remark}
	Note that \( \abs{\hat f(u)} \leq \norm{f}_1 \).
	Also, if \( u_n \to u \), then \( e^{i\inner{u_n,x}} \to e^{i\inner{u,x}} \).
	By the dominated convergence theorem with dominating function \( \abs{f} \), we have \( \hat f(u_n) \to \hat f(u) \), so \( f \) is a continuous bounded function.
\end{remark}
\begin{definition}
	Let \( f \in L^1(\mathbb R^d) \) such that \( \hat f \in L^1(\mathbb R^d) \).
	Then we say that the \emph{Fourier inversion formula} holds for \( f \) if
	\[ f(x) = \frac{1}{(2\pi)^d} \int_{\mathbb R^d} \hat f(u) e^{-i\inner{u,x}} \dd{u} \]
	almost everywhere in \( \mathbb R^d \).
\end{definition}
\begin{definition}
	Let \( f \in L^1(\mathbb R^d) \cap L^2(\mathbb R^d) \).
	Then the \emph{Plancherel identity} holds for \( f \) if
	\[ \norm{\hat f}_2 = (2\pi)^{\frac d2} \norm{f}_2 \]
\end{definition}
We will show that the Fourier inversion formula holds whenever \( \hat f \in L^1(\mathbb R^d) \), and the Plancherel identity holds for all \( f \in L^1(\mathbb R^d) \cap L^2(\mathbb R^d) \).
\begin{remark}
	Given the Plancherel identity, the Fourier transform is a linear isometry of \( L^2(\mathbb R^d) \), by approximating any function in \( L^2(\mathbb R^d) \) by integrable functions.
\end{remark}
\begin{definition}
	Let \( \mu \) be a finite Borel measure on \( \mathbb R^d \).
	We define the Fourier transform of the measure by
	\[ \hat\mu(u) = \int_{\mathbb R^d} e^{i\inner{u,x}} \dd{\mu(x)} \]
\end{definition}
Note that \( \abs{\hat \mu(u)} \leq \mu(\mathbb R^d) \), and \( \hat \mu \) is continuous by the dominated convergence theorem.
If \( \mu \) has a density \( f \) with respect to the Lebesgue measure, \( \hat\mu = \hat f \).
\begin{definition}
	Let \( X \) be an \( \mathbb R^d \)-valued random variable.
	The \emph{characteristic function} \( \varphi_X \) is given by
	\[ \varphi_X(u) = \expect{e^{i\inner{u,X}}} = \hat \mu_X(u) \]
	where \( \mu_X \) is the law of \( X \).
\end{definition}

\subsection{Convolutions}
\begin{definition}
	Let \( f \in L^1(\mathbb R^d) \) and \( \nu \) be a probability measure on \( \mathbb R^d \).
	We define their \emph{convolution} \( f \ast \nu \) by
	\[ (f \ast \nu)(x) = \begin{cases}
		\int_{\mathbb R^d} f(x-y) \dd{\nu(y)} & \text{if } (y \mapsto f(x-y)) \in L^1(\nu) \\
		0 & \text{else}
	\end{cases} \]
\end{definition}
\begin{remark}
	If \( 1 \leq p < \infty \), by Jensen's inequality,
	\[ \int_{\mathbb R^d} \qty( \int_{\mathbb R^d} \abs{f(x-y)} \dd{\nu(y)} )^p \dd{x} \leq \int_{\mathbb R^d} \int_{\mathbb R^d} \abs{f(x-y)}^p \dd{\nu(y)} \dd{x} = \int_{\mathbb R^d} \int_{\mathbb R^d} \abs{f(x-y)}^p \dd{x} \dd{\nu(y)} = \int_{\mathbb R^d} \int_{\mathbb R^d} \abs{f(x)} \dd{\nu(y)} \dd{x} = \int_{\mathbb R^d} \abs{f(x)} \dd{x} = \norm{f}_p^p \]
	So \( f \in L^p(\mathbb R^d) \), we have \( (y \mapsto f(x-y)) \in L^p(\nu) \) almost everywhere, and again by Jensen's inequality,
	\[ \norm{f \ast \nu}_p^p = \int_{\mathbb R^d} \abs{ \int_{\mathbb R^d} f(x-y)\dd{\nu(y)} }^p \dd{x} \leq \int_{\mathbb R^d} \qty( \int_{\mathbb R^d} \abs{f(x-y)} \dd{\nu(y)} )^p \dd{x} \leq \norm{f}_p^p \]
	Hence \( f \mapsto f \ast \nu \) is a contraction on \( L^p(\mathbb R^d) \).
\end{remark}
In the case where \( \nu \) has a density \( g \) with respect to the Lebesgue measure, we write \( f \ast g = f \ast \nu \).
\begin{definition}
	For probability measures \( \mu, \nu \) on \( \mathbb R^d \), their convolution \( \mu \ast \nu \) is a probability measure on \( \mathbb R^d \) given by the law of \( X + Y \) where \( X, Y \) are independent random variables with laws \( \mu \) and \( \nu \), so
	\[ (\mu \ast \nu)(A) = \prob{X+Y \in A} = \int_{\mathbb R^d \times \mathbb R^d} \mathbbm 1_A(x+y) \dd{(\mu \otimes \nu)(x, y)} = \int_{\mathbb R^d} \int_{\mathbb R^d} \mathbbm 1_A(x+y) \dd{\nu(y)} \dd{\mu(x)} \]
\end{definition}
If \( \mu \) has density \( f \) with respect to the Lebesgue measure, \( \mu \ast \nu \) has density \( f \ast \nu \) with respect to the Lebesgue measure.
Indeed,
\[ (\mu \ast \nu)(A) = \int_{\mathbb R^d} \int_{\mathbb R^d} \mathbbm 1_A(x+y) f(x) \dd{x} \dd{\nu(y)} = \int_{\mathbb R^d} \int_{\mathbb R^d} \mathbbm 1_A(v) f(v-y) \dd{v} \dd{\nu(y)} = \int_{\mathbb R^d} \mathbbm 1_A(v) \int_{\mathbb R^d}f(v-y) \dd{\nu(y)} \dd{v} = \int_{\mathbb R^d} \mathbbm 1_A(v) (f \ast \nu)(v) \dd{v} \]
\begin{proposition}
	\( \widehat{f \ast v}(u) = \hat f(u) \hat \nu(u) \).
\end{proposition}
\begin{proposition}
	\( \widehat{\mu \ast \nu}(u) = \expect{e^{i\inner{u,X+Y}}} = \expect{e^{i\inner{u,X}}e^{i\inner{u,Y}}} = \hat \mu(u) \hat \nu(u) \).
\end{proposition}

\subsection{Fourier transforms of Gaussians}
\begin{definition}
	The \emph{normal distribution} \( N(0,t) \) is given by the probability density function
	\[ g_t(x) = \frac{1}{\sqrt{2\pi t}} e^{-\frac{x^2}{2t}} \]
\end{definition}
If \( \varphi_X \) is the characteristic function of a standard normal random variable, by integration by parts,
\begin{align*}
	\dv{u} \varphi_X(u) &= \dv{u} \int_{\mathbb R} e^{iux} g_1(x) \dd{x} \\
	&= \int_{\mathbb R} g_1(x) \dv{u} e^{iux} \dd{x} \\
	&= \frac{i}{\sqrt{2\pi}} \int_{\mathbb R} \underbrace{e^{iux}}_{v} \underbrace{x e^{-\frac{x^2}{2}}}_{w'} \dd{x} \\
	&= \frac{i^2}{\sqrt{2\pi}} \int_{\mathbb R} u e^{iux} e^{-\frac{x^2}{2}} \dd{x} \\
	&= -u \varphi_X(u)
\end{align*}
Hence,
\[ \dv{u}\qty(e^{\frac{u^2}{2}} \varphi_X(u)) = ue^{\frac{u^2}{2}} \varphi_X(u) - e^{\frac{u^2}{2}} u \varphi_X(u) = 0 \]
In particular, \( \varphi_X(u) = \varphi_X(0) e^{-\frac{u^2}{2}} = e^{-\frac{u^2}{2}} \).
In other words, \( \hat g_1(u) = \sqrt{2\pi} g_1(u) \).

In \( \mathbb R^d \), consider a Gaussian random vector \( Z = (Z_1, \dots, Z_d) \) with independent and identically distributed entries \( Z_i \sim N(0,1) \).
Then, the joint probability density function of \( \sqrt{t}Z \) is
\[ g_t(x) = \prod_{j=1}^d \frac{1}{\sqrt{2\pi t}} e^{-\frac{x_j^2}{2t}} = (2\pi t)^{-\frac{d}{2}} e^{-\frac{\norm{x}^2}{2t}} \]
The Fourier transform of \( g_t \) is
\[ \hat g_t(u) = \expect{e^{i\inner{u,\sqrt{t}Z}}} = \expect{\prod_{j=1}^d e^{iu_j \sqrt{t} z_j}} = \prod_{j=1}^d \expect{e^{iu_j \sqrt{t} z_j}} = \prod_{j=1}^d e^{-u_j^2 \frac{t}{2}} = e^{-\frac{\norm{u}^2 t}{2}} \]
which implies that in general, \( \hat g_t(u) = (2\pi)^{-\frac{d}{2}} t^{\frac{d}{2}} g_{\frac{1}{t}}(u) \).
Taking the Fourier transform with respect to \( u \), \( \hhat g_t = (2\pi)^d g_t \), and since \( g_t(-x) = g_t(x) \) and the Lebesgue measure is translation invariant, we have
\[ g(x) = \frac{1}{(2\pi)^d} \hhat g_t(x) = \frac{1}{(2\pi)^d} = \int_{\mathbb R^d} e^{-i\inner{u,x}} \hat g_t(u) \dd{u} \]
so the Fourier inversion theorem holds for such Gaussian random vectors.
\begin{definition}
	We say that a function on \( \mathbb R^d \) is a \emph{Gaussian convolution} if it is of the form
	\[ f \ast g_t(x) = \int_{\mathbb R^d} f(x-y) g_t(y) \dd{y} \]
	where \( x \in \mathbb R^d, t > 0, f \in L^1(\mathbb R^d) \).
\end{definition}
We can show that \( f \ast g_t \) is continuous on \( \mathbb R^d \), and \( \norm{f \ast g_t}_1 \leq \norm{f}_1 \).
Note that \( \widehat{f \ast g_t}(u) = \hat f(u) e^{-\frac{\norm{u}^2 t}{2}} \), so \( \norm{\widehat{f \ast g_t}}_\infty \leq \norm{f}_1 \), giving \( \norm{\widehat{f \ast g_t}}_1 \leq \norm{f}_1 (2\pi)^{\frac{d}{2}} t^{-\frac{d}{2}} < \infty \).
\begin{lemma}
	The Fourier inversion theorem holds for all Gaussian convolutions.
\end{lemma}
\begin{proof}
	We can use the Fourier inversion theorem for \( g_t(y) \) to see that
	\begin{align*}
		(2\pi)^d f \ast g_t(x) &= (2\pi)^d \int_{\mathbb R^d} f(x-y) g_t(y) \dd{y} \\
		&= \int_{\mathbb R^d} f(x-y) \int_{\mathbb R^d} e^{-i\inner{u,y}} \hat g_t(u) \dd{u} \dd{y} \\
		&= \int_{\mathbb R^d} e^{-i\inner{u,x}} \int_{\mathbb R^d} f(x-y) e^{i\inner{u,x-y}} \dd{y} \hat g_t(u) \dd{u} \\
		&= \int_{\mathbb R^d} e^{-i\inner{u,x}} \int_{\mathbb R^d} f(z) e^{i\inner{u,z}} \dd{z} \hat g_t(u) \dd{u} \\
		&= \int_{\mathbb R^d} e^{-i\inner{u,x}} \hat f(u) \hat g_t(u) \dd{u} \\
		&= \int_{\mathbb R^d} e^{-i\inner{u,x}} \widehat{f \ast g_t}(u) \dd{u}
	\end{align*}
\end{proof}
\begin{remark}
	If \( \mu \) is a finite measure, then \( \mu \ast g_t = \mu \ast g_{\frac{t}{2}} \ast g_{\frac{t}{2}} \) with \( \mu \ast g_{\frac{t}{2}} \in L^1 \), so is also a Gaussian convolution.
\end{remark}
\begin{lemma}[Gaussian convolutions are dense in \( L^p \)]
	Let \( f \in L^p \) where \( 1 \leq p < \infty \).
	Then \( \norm{f \ast g_t - f}_p \to 0 \) as \( t \to 0 \).
\end{lemma}
\begin{proof}
	One can easily show that the space \( C_c(\mathbb R^d) \) of continuous functions of compact support is dense in \( L^p \).
	Hence, for all \( \varepsilon > 0 \), there exists \( h \in C_c(\mathbb R^d) \) such that \( \norm{f - h}_p < \frac{\varepsilon}{3} \), and by properties of the convolution, we also obtain
	\[ \norm{f \ast g_t - h \ast g_t}_p = \norm{(f - h) \ast g_t}_p \leq \norm{f - h}_p < \frac{\varepsilon}{3} \]
	So
	\[ \norm{f \ast g_t - f}_p \leq \norm{f \ast g_t - h \ast g_t}_p + \norm{h \ast g_t + h}_p + \norm{h - f}_p < \frac{\varepsilon}{2} + \norm{h \ast g_t - h}_p \]
	so it suffices to prove the result for \( f = h \in C_c(\mathbb R^d) \).
	We define a new map \( e(y) = \int_{\mathbb R^d} \norm{h(x-y) - h(x)}^p \dd{x} \).
	Since \( h \) is bounded on its bounded support, the dominated convergence theorem implies that \( e \) is continuous at \( y = 0 \).
	Note that \( e(y) \leq 2^{p+1} \norm{h}_p^p \).
	Hence, by Jensen's inequality,
	\begin{align*}
		\norm{h \ast g_t - h}_p^p &= \int_{\mathbb R^d} \abs{ \int_{\mathbb R^d} (h(x-y) - h(x)) g_t(y) \dd{y} }^p \dd{x} \\
		&\leq \int_{\mathbb R^d} \int_{\mathbb R^d} \abs{h(x-y) - h(x)}^p \dd{x} g_t(y) \dd{y} \\
		&= \int_{\mathbb R^d} e(y) g_t(y) \dd{y} \\
		&= \int_{\mathbb R^d} \underbrace{e(\sqrt{t} z)}_{\to e(0) = 0 \text{ as } t \to 0} g_1(z) \dd{z} \\
		&\to 0
	\end{align*}
\end{proof}
