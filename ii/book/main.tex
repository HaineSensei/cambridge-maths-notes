\newcommand{\yearnumber}{II}
\input{../../book_template.tex}

\chapter{Algebraic Topology}
This course is an introduction to the basic ideas of algebraic topology.
In the first half of the course, we study an invariant of based topological spaces called the fundamental group.
This invariant associates a group to a topological space (with a basepoint).
It has the important property that a continuous map between topological spaces induces a homomorphism between their fundamental groups, and that the composition of two maps is mapped to the composition of the corresponding homomorphisms.
In slightly fancier language, the fundamental group determines a functor from the category of based topological spaces to the category of groups.
The phenomena that the fundamental group detects are essentially one-dimensional; it measures the failure of closed loops in the space to bound two-dimensional disks.

In the second half of the course, we study another functor from spaces to groups, called homology, which enables us to understand higher-dimensional `holes' in the space.
There are many different ways to define homology; we use a relatively concrete one called simplicial homology, which makes sense for a somewhat restricted class of spaces.
The notion of homology plays a central role in modern geometry and topology as well as in many branches of algebra and number theory.

Using these invariants we can distinguish various spaces from each other; for example, we can prove that \( \mathbb R^n \) is not homeomorphic to \( \mathbb R^m \) when \( n \) is not equal to \( m \).
We are also able to prove the fundamental theorem of algebra, and to show that certain maps from a space to itself (for example, any continous map from the closed \( n \)-dimensional disk to itself) must have fixed points.

\subfile{../algtop/main.tex}

\chapter{Probability and Measure}
In this course, we study measure theory and integration, and its applications to probability theory.
We begin by defining the notion of a measure, which extends the notion of the length of an interval to a much larger class of `measurable' sets.
In the context of a probability space, a probability measure is a way to associate probabilities to events that could occur.
Measures have the countable additivity property, which allows us to compute the measure of certain limits of measurable sets.
Using this property, we can analyse limiting behaviour by considering the measure of a set on which a certain event occurs.

Measure theory allows us to define the Lebesgue integral.
This integral agrees with the Riemann integral on most well-behaved functions, but it has many more convenient properties concerning limits.
For example, the dominated convergence theorem gives a sufficient condition for when the limit of the integrals of functions is the integral of the limit.
Another example is that the set of Lebegsue integrable functions forms a complete normed vector space, but this is not true of the Riemann integral.

Using the Lebesgue integral, we can define the Fourier transform of an integrable function.
This linear operator is `almost' injective: if the Fourier transform of a function is also integrable, we can recover the original function almost everywhere.
Properties of the Fourier transform are used to deduce the central limit theorem.

\subfile{../pm/main.tex}

\chapter{Graph Theory}
A graph is a set of vertices, each pair of which may be joined with an edge.
The fact that graphs can be used to model any symmetric relation makes them widely applicable to various areas of mathematics such as knot theory.

We begin by studying various notions of connectivity of graphs, and then discuss planarity.
The famous four-colour theorem states that a planar graph can be drawn using only four colours for the vertices, such that no two joined vertices share the same colour.
While the proof of this theorem is extremely long, we prove the five-colour theorem and related results about graphs on other surfaces.

As graphs grow, we are interested in their asymptotic behaviour.
For example, how many edges must there be in a graph before we can guarantee that there is a triangle?
We study various properties of this form, and prove sufficient conditions to see certain behaviour in any given graph.
We also use probability theory to provide bounds on how likely certain events in a random graph are to occur.

\subfile{../graph/main.tex}

\chapter{Automata and Formal Languages}
Computation, or computability, is central to modern mathematics.
However, we very rarely think about the precise definition of what it means for something to be `computable'.
There is an important difference between existence and algorithmic access to a witness.
In this course, we discuss the precise definition of computability, and use it to prove that there is no algorithm to solve certain problems.

There are many possible ways to define computation and computability, and it is a remarkable fact that most `reasonable' definitions of computable functions coincide.
This is known as the Church--Turing thesis, and it allows us to reason about computation without being tied to a specific model, such as register machines, the Turing machine, or Church's recursive functions.

A language is a set of strings called words.
Languages can be used to model countable sets, such as the set of powers of two, the set of primes, or the set of numbers which describe a register machine that determine if a given computation will halt or not.
We will explore different types of language, and use computation theory to study which properties of languages can be determined algorithmically.
We prove that there is a large class of languages for which there is an algorithm to determine if a given word lies in the language, but a much smaller class of languages for which we can determine algorithmically if they contain any words at all.

\subfile{../afl/main.tex}

\chapter{Galois Theory}
Suppose \( K \) and \( L \) are fields, and \( K \subseteq L \).
We can view \( L \) as a vector space over \( K \), and therefore analyse things like its dimension.
We study how these extensions of fields interact, and how they can embed inside each other.

To analyse these field extensions, we will understand the Galois group associated to a particular field extension \( K \subseteq L \).
This group describes the different ways that \( L \) can embed into itself, while preserving the structure of \( K \).
This turns out to provide a measure of the complexity of \( L \) with respect to \( K \).

The central result of the course is the Galois correspondence.
If \( K \subseteq L \), there may be other fields lying between \( K \) and \( L \).
We prove that the subgroups of the Galois group correspond exactly to these intermediate fields.

We apply Galois theory to some problems that had been unsolved for many centuries or millenia.
Classic examples include doubling the cube and trisecting the angle.
We also prove that there is no formula for finding a root of the general quintic.

\subfile{../galois/main.tex}

\chapter{Coding and Cryptography}
Coding theory allows us to mathematically reason about methods of communication.
The theory is largely broken into two parts: noiseless coding and noisy coding.

Noiseless codes describe ways to compress data into less space.
Such schemes have been in use since at least the time of the Ancient Greeks, who used torches placed upon hilltops to concisely convey Greek letters over a long distance.
We explore some examples of noiseless codes, and prove theoretical results about how efficiently they can be expected to encode data from a variety of sources.

Noisy coding aims to detect, or possibly correct, errors that may have been introduced while transmitting data across a noisy channel.
An example of such a code is the International Standard Book Number: it detects any digit typed incorrectly, and any transposition of two adjacent digits.
We investigate how reliably channels can transmit data, and at what rate.
In practice, noiseless and noisy codes are combined to transmit data across a noisy channel with high reliability and efficiency.

In addition to transmitting data reliably, we may also wish to transmit our message securely.
This leads to the study of cryptography.
There are several possible aims that a cryptographic cipher might try to achieve, for example ensuring that a message was not read or tampered with, or `signing' a message to authenticate that it originated from a particular sender.
These concepts form the basis of modern internet security.

\subfile{../cc/main.tex}

\chapter{Quantum Information and Computation}
Computers manipulate bits of information to process inputs and answer questions.
Regardless of the physical form of the computer, it has certain fundamental theoretical limitations.
As the size of a bit string increases, the number of possible values of the string increases exponentially, and this means that many computational tasks require exponential amounts of time or space to compute a result.

Quantum computation allows us to bypass some of these limitations by leveraging features of quantum mechanics.
In the quantum case, we store information using quantum bits (`qubits') instead of classical bits.
While a classical computer can only operate on a single state at a time, we can construct a superposition of quantum states and operate on them all at once.
We can use this to solve certain classical problems with a quantum computer faster than is possible with a classical computer, even in theory.

One example of a difficult problem is \( \mathsf{SAT} \), the Boolean satisfiability problem.
The input is a Boolean function in \( n \) variables, and we wish to determine whether there is an assignment of the variables that makes the formula true.
This problem is \( \mathsf{NP} \)-complete: any problem in the complexity class \( \mathsf{NP} \) can be reduced to a case of \( \mathsf{SAT} \).
One of the quantum algorithms discussed in this course is Grover's quantum search algorithm, which solves \( \mathsf{SAT} \) with a quadratic speedup compared to the classical complexity.
This shows that Grover's algorithm can be applied to any \( \mathsf{NP} \) problem to give a quadratic speedup.
Hence, quantum computers can be used to solve a wide class of problems faster than a classical computer can.

\subfile{../qic/main.tex}

\chapter{Number Fields}
A number field is a field extension of \( \mathbb Q \), generated by finitely many algebraic numbers.
Common number fields include the rationals \( \mathbb Q \), the Gaussian rationals \( \mathbb Q(i) \), and more general quadratic fields \( \mathbb Q(\sqrt{d}) \).
The field of rationals contain the ring of integers \( \mathbb Z \), and each number field similarly contains its own ring of algebraic integers.
For example, the ring of algebraic integers in \( \mathbb Q(i) \) is \( \mathbb Z[i] \).

While the field structure of a number field is typically relatively simple, the ring structure of the algebraic integers can offer more insight into the field in question.
In general, the ring of algebraic integers is not a unique factorisation domain, but some fields have `better' or `worse' factorisation properties than others.
We quantify the degree to which unique factorisation fails by assigning a group to each number field, called the class group.
If the class group is large, there are many ways in which unique factorisation could fail.
A remarkable fact proven in this course is that the class group is finite.

We also study the units in the ring of algebraic integers.
The roots of unity in a number field are units, but there may be other units not of this form.
Dirichlet's unit theorem describes a geometric interpretation of the set of units.
In particular, modulo the roots of unity, they form a lattice isomorphic to \( \mathbb Z^k \) for some \( k \in \qty{0, 1, \dots} \).
We can use this theorem to find all of the integer solutions of problems like Pell's equation, \( x^2 - d y^2 = \pm 1 \).

\subfile{../nf/main.tex}

\chapter{Algebraic Geometry}
In this course, we study the duality between systems of polynomial equations and the geometry or topology of their solution sets.
Sets of points that arise as solution sets of polynomials are called algebraic varieties.
We therefore study the correspondence between sets of polynomials and the varieties they define.

One can show that the set of varieties satisfy the axioms of the closed sets of a topological space.
We can thus define a topology where the closed sets are precisely the algebraic varieties; this is called the Zariski topology.
This very explicit description of the closed sets allows us to study this topology in depth.
There are some drawbacks; the Zariski topology is not even Hausdorff.

Some geometric properties of algebraic varieties can be studied algebraically.
For example, the dimension of a variety is the amount of algebraically independent transcendental elements of a field associated to the variety.
Perhaps the simplest varieties are the curves, those varieties with dimension 1.
They have comparatively simple field structure, and are studied in depth.

\subfile{../alggeom/main.tex}

\chapter{Logic and Set Theory}
Mathematics is the study of logical systems, and proving true statements about them.
In this course, we make precise the notion of a proof, and what it means for a logical sentence to be true.
This allows us to reason about truth mathematically rather then philosophically.
One important result, the completeness theorem, states that a sentence is true exactly when it has a proof.
This assures us that proofs are a sensible way of showing that a statement is true, and shows us that if a statement is false there must be a counterexample.

A major application of our theory of logic is set theory.
With it, we can formalise the intuitive notion of a set into a concrete mathematical object that can be studied in its own right.
We can prove results about sets and set theory itself without worrying about circular logic.

To learn about the structure of the universe of sets, we will study ordinals and cardinals, which are different kinds of transfinite number.
Ordinals measure discrete processes that are allowed to continue past infinity.
They have rich structure, and are used to prove important and far-reaching results, such as Zorn's lemma.
Cardinals measure the sizes of sets.
Both ordinals and cardinals have their own arithmetic, which allow us to reason about various kinds of composition of sets and orders.

\subfile{../lst/main.tex}

\end{document}
