\subsection{???}
\begin{corollary}
	If \( F = \mathbb C \), for any symmetric bilinear form \( \phi \) there exists a basis of \( V \) such that \( [\phi]_B \) is
	\[
		\begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
\end{corollary}
\begin{proof}
	Since any symmetric bilinear form \( \phi \) in a finite-dimensional \( F \)-vector space \( V \) can be diagonalised, let \( E = (e_1, \dots, e_n) \) such that \( [\phi]_E \) is diagonal with diagonal entries \( a_i \).
	Order the \( a_i \) such that \( a_i \) is nonzero for \( 1 \leq i \leq r \), and the remaining values (if any) are zero.
	For \( i \leq r \), let \( \sqrt{a_i} \) be a choice of a complex root for \( a_i \).
	Then \( v_i = \frac{e_i}{\sqrt{a_i}} \) for \( i \leq r \) and \( v_i = e_i \) for \( i > r \) gives the basis \( B \) as required.
\end{proof}
\begin{corollary}
	Every symmetric matrix of \( M_n(\mathbb C) \) is congruent to a unique matrix of the form
	\[
		\begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
	where \( r \) is the rank of the matrix.
\end{corollary}
\begin{corollary}
	Let \( F = \mathbb R \), and let \( V \) be a finite-dimensional \( \mathbb R \)-vector space.
	Let \( \phi \) be a symmetric bilinear form on \( V \).
	Then there exists a basis \( B = (v_1, \dots, v_n) \) of \( V \) such that
	\[
		[\phi]_B = \begin{pmatrix}
			I_p & 0    & 0 \\
			0   & -I_q & 0 \\
			0   & 0    & 0
		\end{pmatrix}
	\]
	for some integers \( p, q \).
\end{corollary}
\begin{proof}
	Since square roots do not necessarily exist in \( \mathbb R \), we cannot use the form above.
	We first diagonalise the bilinear form in some basis \( E \).
	Then, reorder and group the \( a_i \) into a positive group of size \( p \), a negative group of size \( q \), and a zero group.
	Then,
	\[
		v_i = \begin{cases}
			\frac{e_i}{\sqrt{a_i}}  & i \in \qty{1, \dots, p}     \\
			\frac{e_i}{\sqrt{-a_i}} & i \in \qty{p+1, \dots, p+q} \\
			e_i                     & i \in \qty{p+q+1, \dots, n}
		\end{cases}
	\]
	This gives a new basis as required.
\end{proof}

\subsection{Sylvester's law}
\begin{definition}
	Let \( F = \mathbb R \).
	The \textit{signature} of a bilinear form \( \phi \) is
	\[
		s(\phi) = p - q
	\]
	where \( p \) and \( q \) are defined as in the corollary above.
\end{definition}
\begin{theorem}
	Let \( F = \mathbb R \).
	Let \( V \) be a finite-dimensional \( \mathbb R \)-vector space.
	If a real symmetric bilinear form is represented by some matrix
	\[
		\begin{pmatrix}
			I_p & 0    & 0 \\
			0   & -I_q & 0 \\
			0   & 0    & 0
		\end{pmatrix}
	\]
	in some basis \( B \), and some other matrix
	\[
		\begin{pmatrix}
			I_{p'} & 0       & 0 \\
			0      & -I_{q'} & 0 \\
			0      & 0       & 0
		\end{pmatrix}
	\]
	in another basis \( B' \), then \( p = p' \) and \( q = q' \).
	Thus, the signature of the matrix is well defined.
\end{theorem}
\begin{definition}
	Let \( \phi \) be a symmetric bilinear form on a real vector space \( V \).
	We say that
	\begin{enumerate}[(i)]
		\item \( \phi \) is \textit{positive definite} if \( \phi(u,u) > 0 \) for all nonzero \( u \in V \);
		\item \( \phi \) is \textit{positive semidefinite} if \( \phi(u,u) \geq 0 \) for all \( u \in V \);
		\item \( \phi \) is \textit{negative definite} or \textit{negative semidefinite} if \( \phi(u,u) < 0 \) or \( \phi(u,u) \leq 0 \) respectively for all nonzero \( u \in V \).
	\end{enumerate}
\end{definition}
\begin{example}
	The matrix
	\[
		\begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
	is positive definite for \( r = n \), and positive semidefinite for \( r < n \).
\end{example}
\noindent We now prove Sylvester's law.
\begin{proof}
	In order to prove uniqueness of \( p \), we will characterise the matrix in a way that does not depend on the basis.
	In particular, we will show that \( p \) is the largest dimension of a vector subspace of \( V \) such that the restriction of \( \phi \) on this subspace is positive definite.
	Suppose we have \( B = (v_1, \dots, v_n) \) and
	\[
		[\phi]_B = \begin{pmatrix}
			I_p & 0    & 0 \\
			0   & -I_q & 0 \\
			0   & 0    & 0
		\end{pmatrix}
	\]
	We consider
	\[
		X = \genset{v_1, \dots, v_p}
	\]
	Then we can easily compute that \( \eval{\phi}_X \) is positive definite.
	Let
	\[
		Y = \genset{v_{p+1}, \dots, v_n}
	\]
	Then, as above, \( \eval{\phi}_Y \) is negative semidefinite.
	Suppose that \( \phi \) is positive definite on another subspace \( X' \).
	In this case, \( Y \cap X' = \qty{0} \), since if \( y \in Y \cap X' \) we must have \( Q(y) \leq 0 \), but since \( y \in X' \) we have \( y = 0 \).
	Thus, \( Y + X' = Y \oplus X' \), so \( n = \dim V \geq \dim Y + \dim X' \).
	But \( \dim Y = n - p \), so \( \dim X' \leq p \).
	The same argument can be executed for \( q \), hence both \( p \) and \( q \) are independent of basis.
\end{proof}

\subsection{Kernels of bilinear forms}
\begin{definition}
	Let \( K = \qty{ v \in V \colon \forall u,v \in V, \phi(u,v) = 0 } \).
	This is the \textit{kernel} of the bilinear form.
\end{definition}
\begin{remark}
	By the rank-nullity theorem,
	\[
		\dim K + \rank \phi = n
	\]
	Using the above notation, we can show that there exists a subspace \( T \) of dimension \( n - (p+q) + \min\qty{p,q} \) such that \( \eval{\phi}_T = 0 \).
	Indeed, let \( B = (v_1, \dots, v_n) \) such that
	\[
		[\phi]_B = \begin{pmatrix}
			I_p & 0    & 0 \\
			0   & -I_q & 0 \\
			0   & 0    & 0
		\end{pmatrix}
	\]
	The quadratic form has a zero subspace of dimension \( n - (p+q) \) in the bottom right.
	But by setting
	\[
		T = \qty{v_1 + v_{p+1}, \dots, v_q + v_{p+q}, v_{p+q+1}, \dots, v_n}
	\]
	we can combine the positive and negative blocks (assuming here that \( p \geq q \) to produce more linearly independent elements of the kernel.
	In particular, \( \dim T \) is the largest possible dimension of a subspace \( T' \) of \( V \) such that \( \eval{\phi}_{T'} = 0 \).
\end{remark}

\subsection{Sesquilinear forms}
Let \( F = \mathbb C \).
The standard inner product on \( \mathbb C^n \) is defined to be
\[
	\inner{\begin{pmatrix} x_1 \\ \vdots \\ v_n \end{pmatrix}, \begin{pmatrix} y_1 \\ \vdots \\ y_n \end{pmatrix}} = \sum_{i=1}^n x_i \overline y_i
\]
This is not a bilinear form on \( \mathbb C \) due to the complex conjugate, it is linear in the first entry.
\begin{definition}
	Let \( V, W \) be \( \mathbb C \)-vector spaces.
	A form \( \phi \colon V \times W \to \mathbb C \) is called \textit{sesquilinear} if it is linear in the first entry, and
	\[
		\phi(v, \lambda_1 w_1 + \lambda_2 w_2) = \overline \lambda_1 \phi(v,w_1) + \overline \lambda_2 \phi(v,w_2)
	\]
	so it is antilinear with respect to the second entry.
\end{definition}
