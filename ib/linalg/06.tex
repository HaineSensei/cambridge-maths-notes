\subsection{Change of Basis}
Suppose we have two bases \( B = \qty{v_1, \dots, v_n}, B' = \qty{v_1', \dots, v_n'} \) of \( V \) and corresponding \( C, C' \) for \( W \).
If we have a linear map \( [\alpha]_{B,C} \), we are interested in finding the components of this linear map in another basis, that is,
\[
	[\alpha]_{B,C} \mapsto [\alpha]_{B',C'}
\]
\begin{definition}
	The \textit{change of basis} matrix \( P \) from \( B' \) to \( B \) is
	\[
		P = \begin{pmatrix}
			[v_1']_B & \cdots & [v_n']_B
		\end{pmatrix}
	\]
	which is the identity map in \( B' \), written
	\[
		P = [\mathbb I]_{B', B}
	\]
\end{definition}
\begin{lemma}
	For a vector \( v \),
	\[
		[v]_B = P [v]_{B'}
	\]
\end{lemma}
\begin{proof}
	We have
	\[
		[\alpha(v)]_C = [\alpha]_{B,C} \cdot [v]_C
	\]
	Since \( P = [\mathbb I]_{B', B} \),
	\[
		[\mathbb I(v)]_B = [\mathbb I]_{B', B} \cdot [v]_{B'} \implies [v]_B = P[v]_{B'}
	\]
	as required.
\end{proof}
\begin{remark}
	\( P \) is an invertible \( n \times n \) square matrix.
	In particular,
	\[
		P^{-1} = [\mathbb I]_{B,B'}
	\]
	Indeed,
	\[
		I_n = [\mathbb I \cdot \mathbb I]_{B,B} = [\mathbb I]_{B',B} \cdot [\mathbb I]_{B',B}
	\]
	where \( I_n \) is the \( n \times n \) identity matrix.
\end{remark}
\begin{proposition}
	If \( \alpha \) is a linear map from \( V \) to \( W \), and \( P = [\mathbb I]_{B',B}, Q = [\mathbb I]_{C',C} \), we have
	\[
		A' = [\alpha]_{B',C'} = [\mathbb I]_{C,C'}[\alpha]_{B,C}[\mathbb I]_{B,'B} = Q^{-1}AP
	\]
	where \( A = [\alpha]_{B,C}, A' = [\alpha]_{B',C'} \).
\end{proposition}
\begin{proof}
	\begin{align*}
		[\alpha(v)]_C                     & = Q [\alpha(v)]_{C'}          \\
		                                  & = Q [\alpha]_{B',C'} [v]_{B'} \\
		[\alpha(v)]_C                     & = [\alpha]_{B,C} [v]_B        \\
		                                  & = AP[v]_{B'}
		\therefore \forall v,\ QA[v]_{B'} & = AP[v]_{B'}                  \\
		\therefore QA                     & = AP
	\end{align*}
	as required.
\end{proof}

\subsection{Equivalent Matrices}
\begin{definition}
	Matrices \( A, A' \) are called \textit{equivalent} if
	\[
		A' = Q^{-1}AP
	\]
	for some invertible \( m \times m, n \times n \) matrices \( Q, P \).
\end{definition}
\begin{remark}
	This defines an equivalence relation on \( M_{m,n}(F) \).
	\begin{itemize}
		\item \( A = I_m^{-1} A I_n \);
		\item \( A' = Q^{-1} AP \implies A = Q A' P^{-1} \);
		\item \( A' = Q^{-1}AP, A'' = (Q')^{-1}A'P' \implies A'' = (QQ')^{-1}A(PP') \).
	\end{itemize}
\end{remark}
\begin{proposition}
	Let \( \alpha \colon V \to W \) be a linear map.
	Then there exists a basis \( B \) of \( V \) and a basis \( C \) of \( W \) such that
	\[
		[\alpha]_{B,C} = \begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
	so the components of the matrix are exactly the identity matrix of size \( r \) in the top-left corner, and zeroes everywhere else.
\end{proposition}
\begin{proof}
	We first fix \( r \in \mathbb N \) such that \( \dim \ker \alpha = n - r \).
	Then we will construct a basis \( \qty{v_{r+1}, \dots, v_n} \) of the kernel.
	We extend this to a basis of the entrety of \( V \), that is, \( \qty{v_1,\dots,v_n} \).
	Then, we want to show that
	\[
		\qty{\alpha(v_1), \dots, \alpha(v_r)}
	\]
	is a basis of \( \Im \alpha \).
	Indeed, it is a generating family:
	\begin{align*}
		v         & = \sum_{i=1}^n \lambda_i v_i         \\
		\alpha(v) & = \sum_{i=1}^n \lambda_i \alpha(v_i) \\
		          & = \sum_{i=1}^r \lambda_i \alpha(v_i) \\
	\end{align*}
	Then if \( y \in \Im \alpha \), there exists \( v \) such that \( \alpha(v) = y \).
	Further, it is a free family:
	\begin{align*}
		\sum_{i=1}^r \lambda_i \alpha(v_i)                        & = 0                            \\
		\alpha\qty(\sum_{i=1}^r \lambda_i v_i)                    & = 0                            \\
		\sum_{i=1}^r \lambda_i v_i                                & \in \ker \alpha                \\
		\sum_{i=1}^r \lambda_i v_i                                & = \sum_{i=r+1}^n \lambda_i v_i \\
		\sum_{i=1}^r \lambda_i v_i - \sum_{i=r+1}^n \lambda_i v_i & = 0                            \\
	\end{align*}
	But since \( \qty{v_1, \dots, v_n} \) is a basis, \( \lambda_i = 0 \) for all \( i \).
	Hence \( \qty{\alpha(v_i)} \) is a basis of \( \Im \alpha \).
	Now, we wish to extend this basis to the whole of \( W \) to form
	\[
		\qty{\alpha(v_1), \dots, \alpha(v_r), w_{r+1}, \dots, w_n}
	\]
	Now,
	\begin{align*}
		[\alpha]_{BC} & = \begin{pmatrix}
			\alpha(v_1) & \cdots & \alpha(v_r) & \alpha(v_{r+1}) & \cdots & \alpha(v_n)
		\end{pmatrix} \\
		              & = \begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\end{align*}
\end{proof}
\begin{remark}
	This also proves the rank-nullity theorem:
	\[
		\rank \alpha + \null \alpha = n
	\]
\end{remark}
\begin{corollary}
	Any \( m \times n \) matrix \( A \) is equivalent to a matrix of the form
	\[
		\begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
	where \( r = \rank A \).
\end{corollary}

\subsection{Rank}
\begin{definition}
	Let \( A \in M_{m,n}(F) \).
	Then, the \textit{column rank} of \( A \), here denoted \( r_c(A) \), is the dimension of the subspace of \( F^n \) spaned by the column vectors.
	\[
		r_c(F) = \dim \vecspan \qty{c_1, \dots, c_n}
	\]
\end{definition}
\begin{remark}
	If \( \alpha \) is a linear map, represented in bases \( B, C \) by the matrix \( A \), then
	\[
		\rank A = r_c(A)
	\]
\end{remark}
\begin{proposition}
	Two matrices are equivalent if they have the same column rank:
	\[
		r_c(A) = r_c(A')
	\]
\end{proposition}
\begin{proof}
	If the matrices are equivalent, then \( A = [\alpha]_{BC}, A' = [\alpha]_{B',C'} \).
	Then
	\[
		r_c(A) = r_c(\alpha) = r_c(A')
	\]
	Conversely, if \( r_c(A) = r_c(A') = r \), then \( A, A' \) are equivalent to
	\[
		\begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}
	\]
	By transitivity, \( A, A' \) are equivalent.
\end{proof}
\begin{theorem}
	Column rank \( r_c(A) \) and row rank \( r_c(A^\transpose) \) are equivalent.
\end{theorem}
\begin{proof}
	Let \( r = r_C(A) \).
	Then,
	\[
		Q^{-1}AP = \begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}_{m \times n}
	\]
	Then, consider
	\[
		P^\transpose A^\transpose \qty(Q^{-1})^\transpose = (Q^{-1}AP)^\transpose = \begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}_{m \times n}^\transpose = \begin{pmatrix}
			I_r & 0 \\
			0   & 0
		\end{pmatrix}_{n \times m}
	\]
	Note that we can swap the transpose and inverse on \( Q \) because
	\begin{align*}
		(AB)^\transpose          & = B^\transpose A^\transpose           \\
		\qty(QQ^{-1})^\transpose & = Q^\transpose \qty(Q^{-1})\transpose \\
		I                        & = Q^\transpose \qty(Q^{-1})\transpose \\
		\qty(Q^\transpose)^{-1}  & = \qty(Q^{-1})\transpose
	\end{align*}
	Then \( r_c(A) = \rank(A) = \rank(A^\transpose) = r_c(A^\transpose) \).
\end{proof}
\noindent So we can drop the concepts of column and row rank, and just talk about rank as a whole.
