\subsection{Examples of convex functions}
\begin{example}
	Consider the function \( f \colon \mathbb R \to \mathbb R \) defined by
	\[
		f(x) = x^2
	\]
	The domain is clearly convex.
	To show convexity, we need
	\[
		f((1-t)x+ty) - (1-t)f(x) - tf(y) \leq 0
	\]
	We have
	\[
		[(1-t)x+ty]^2 - (1-t)x^2 - ty^2 = x^2(1-t)(-t) + ty^2(1-t) + 2(1-t)txy = -(1-t)t(x-y)^2 < 0
	\]
	as required.
	Hence \( f(x) = x^2 \) is a strictly convex function.
\end{example}
\begin{example}
	Consider
	\[
		f(x) = \frac{1}{x}
	\]
	where the domain is \( \mathbb R \setminus \{ 0 \} \).
	This domain is not convex, so \( f \) is not convex.
	However, restricted to the domain \( \qty{ x \in \mathbb R \colon x > 0 } \), \( f \) can be shown to be convex.
\end{example}

\subsection{Conditions for convexity}
\textit{Proofs for these conditions, where appropriate, are given in Lecture 1 of the IB Optimisation course.}
\begin{theorem}
	If \( f \) is a once-differentiable function, then \( f \) is convex if and only if
	\[
		f(\vb y) \geq f(\vb x) + (\vb y - \vb x) \cdot \grad{f}(\vb x)
	\]
\end{theorem}
\begin{corollary}
	If \( f \) is convex, and has a stationary point, then it is a global minimum.
\end{corollary}
\begin{proof}
	Suppose the stationary point is at \( \vb x_0 \), so \( \grad{f}(\vb x_0) = \vb 0 \).
	We then have
	\[
		f(\vb y) \geq f(\vb x_0) + (\vb y - \vb x_0) \cdot \vb 0
	\]
	which is larger than \( f(\vb x_0) \) as required.
\end{proof}

\begin{theorem}
	If \( f \) is a once-differentiable function, then \( f \) is convex if
	\[
		(\grad{f(\vb y)} - \grad {f(\vb x)}) \cdot (\vb y - \vb x) \geq 0
	\]
	This can be thought of as stating that \( f' \) is monotonically increasing.
\end{theorem}

\begin{theorem}
	If \( f \) is a twice-differentiable function, then \( f \) is convex if and only if
	\[
		\laplacian{f} \succeq 0
	\]
	i.e.\ all eigenvalues of the Hessian matrix are non-negative.
	Note that \( \laplacian{f} \succ 0 \) implies strict convexity.
\end{theorem}

\begin{example}
	Consider the function
	\[
		f(x,y) = \frac{1}{xy}
	\]
	for \( x > 0, y > 0 \).
	Then the Hessian is
	\[
		H = \frac{1}{xy}\begin{pmatrix}
			\frac{2}{x^2} & \frac{1}{xy}  \\
			\frac{1}{xy}  & \frac{2}{y^2} \\
		\end{pmatrix}
	\]
	Then,
	\[
		\det H = \frac{3}{x^3 y^3} > 0
	\]
	\[
		\tr H > 0
	\]
	Hence the eigenvalues are both positive.
	So \( f \) is strictly convex.
\end{example}

\subsection{Legendre transform}
\begin{definition}
	The Legendre transform of a function \( f \colon \mathbb R^n \to \mathbb R \) is a function \( f^\star \) given by
	\[
		f^\star(\vb p) = \sup_{\vb x} (\vb p \cdot \vb x - f(\vb x))
	\]
	The domain of \( f^\star \) is such that the supremum provided is finite.
	In one dimension, we can consider \( f^\star(p) \) to be the maximum vertical distance between the graphs of \( y = f(x) \) and \( y = px \).
\end{definition}
\begin{example}
	Consider the function \( f(x) = ax^2 \), which is convex where \( a > 0 \).
	Computing the derivative of the right hand side and setting it to zero,
	\begin{align*}
		f^\star(p) & = \sup_x (px - ax^2)                           \\
		           & = p\qty(\frac{p}{2a}) - a \qty(\frac{p}{2a})^2 \\
		           & = \frac{p^2}{4a}
	\end{align*}
	We can apply the Legendre transform twice:
	\[
		f^{\star\star}(s) = \sup_p (sp - f^\star(p)) = as^2 = f(s)
	\]
	In fact, if \( f \) is convex, then we always have \( f^{\star\star} = f \).
	If \( a < 0 \), the supremum does not exist so \( f^\star \) has an empty domain, and thus \( f^{\star\star} \neq f \).
\end{example}
\begin{proposition}
	If the domain of \( f^\star \) is non-empty, it is a convex set, and \( f^\star \) is convex.
\end{proposition}
\begin{proof}
	Given \( \vb p, \vb q \) in the domain of \( f^\star \),
	\begin{align*}
		f^\star((1-t)\vb p + t \vb q) & = \sup_{\vb x} \qty[(1-t)\vb p \cdot \vb x + t \vb q \cdot \vb x - f(\vb x)]                                      \\
		                              & = \sup_{\vb x} \qty[(1-t)(\vb p \cdot \vb x - f(\vb x)) + t (\vb q \cdot \vb x - f(\vb x))]                       \\
		                              & \leq \sup_{\vb x} \qty[(1-t)(\vb p \cdot \vb x - f(\vb x))] + \sup_{\vb x} \qty[t (\vb q \cdot \vb x - f(\vb x))] \\
		                              & < \infty
	\end{align*}
	as required.
\end{proof}

\noindent In practice, if \( f \) is convex and differentiable, we compute \( f^\star(\vb p) \) by considering the derivative:
\[
	\grad(\vb p \cdot \vb x - f(\vb x)) = 0 \implies \vb p = \grad{f}
\]
If \( f \) is strictly convex, the condition \( \vb p = \grad{f} \) has a unique inverse to give \( \vb x \) as a function of \( \vb p \), so \( f^\star(\vb p) = \vb p \cdot \vb x(\vb p) - f(\vb x(\vb p)) \).
This eliminates the supremum condition.
