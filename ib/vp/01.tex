\subsection{The Brachistochrone Problem}
Consider a particle sliding on a wire under the influence of gravity between two fixed points in the plane.
What is the shape of the wire that produces the shortest travel time between the end points, given that the particle starts at rest?
This problem is known as the brachistochrone problem, an archetypical variational problem.
Suppose the end points are labelled \(A\) and \(B\), where \(A\) is the origin, i.e.
\((x_1, y_1) = (0, 0)\), and where \(B\) has coordinates \((x_2, y_2)\).
Note that \(y_2 < 0\) in order that the particle has sufficient energy to reach the destination.
The travel time \(T\) is given by
\[
	T = \int \dd{t} = \int_A^B \frac{\dd{\ell}}{v(x, y)}
\]
Note that the kinetic energy and the potential energy sum to a constant.
\[
	\frac{1}{2}mv^2 + mgy = mgy_1 = 0 \implies v = \sqrt{2g}\sqrt{-y}
\]
So we must find the function \(y\) that minimises
\[
	T[y] = \frac{1}{\sqrt{2g}} \int_0^{x_2} \frac{\sqrt{1+y'^2}}{\sqrt{-y}}\dd{x}
\]
subject to \(y_0 = 0\), \(y(x_2) = y_2\).
This problem's solution will be explored in a later lecture.

\subsection{Geodesics}
A geodesic is the shortest path \(\gamma\) between two points on a surface \(\Sigma\), assuming such a path exists.
Initially, let \(\Sigma = \mathbb R^2\).
On this plane, the Pythagorean theorem for measuring distances holds.
Using a Cartesian coordinate system, we can say that a point \(A\) has coordinates \((x_1, y_1)\), and a point \(B\) has coordinates \((x_2, y_2)\).
The distance from \(A\) to \(B\) along any path \(\gamma\) can be computed using a line integral.
\[
	D[y] = \int_A^B \dd{\ell} = \int_{x_1}^{x_2} \sqrt{1+y'^2}\dd{x}
\]
In this case, we have defined \(y\) as a function of \(x\), and we seek to minimise \(D\) by varying the path \(\gamma\) on which we are moving.

\subsection{Calculus of Variations}
A variational problem involves minimising an object of the form
\[
	F[y] = \int_{x_1}^{x_2} f(x, y(x), y'(x)) \dd{x}
\]
subject to fixed values of \(y\) at the end points.
We call such an \(F\) a \textit{functional}; it is a function on the space of functions.
Calculus applied to functionals is called the calculus of variations; we would like to find minima and maxima of functionals.
In order to talk about functionals rigorously, we must define first the space of functions we are operating on; analogously to how we must define the domain of a function we are analysing when dealing with real or complex analysis.
We write \(C(\mathbb R)\) for the space of continuous functions on \(\mathbb R\), and \(C^k(\mathbb R)\) for the space of functions with continuous \(k\)th derivatives on \(\mathbb R\).
Sometimes, the notation \(C_{(\alpha, \beta)}^k(\mathbb R)\) is used to denote \(C^k(\mathbb R)\) such that \(f(\alpha)\) and \(f(\beta)\) are fixed, typically fixed to zero.

\subsection{Variational Principles}
We can now define what variational principles are: they are such principles where laws follow from finding the minima or maxima of functionals.
An introductory example is Fermat's principle, which states that light that travels between two points takes the path which requires the least travel time.
There is also the principle of least action.
Consider a particle moving under some potential \(V(\vb x)\), and let \(T = \frac{1}{2}m\abs{\dot {\vb x}}^2\) be its kinetic energy.
We can define
\[
	S[\gamma] = \int_{t_1}^{t_2} (T - V)\dd{t}
\]
where \(\gamma\) represents the path along which the particle travels.
The left hand side \(S[\gamma]\) is called the \textit{action}, and the principle of least action states that the action is minimised along paths of motion.
Then, Newton's laws of motion should follow from this principle by minimising action.
