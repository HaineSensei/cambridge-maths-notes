\subsection{Weak Duality}
We would like to solve a problem
\begin{alignat*}{2}
	 & \underset{\vb x \in \mathcal X}{\text{minimise}} & \qquad & f(\vb x)         \\
	 & \text{subject to}                                &        & h(\vb x) = \vb b
\end{alignat*}
by constructing the Lagrangian
\[
	L(\vb x, \vb \lambda) = f(\vb x) - \vb\lambda^\transpose (h(\vb x) - \vb b)
\]
We now define the quantity
\[
	g(\vb \lambda) = \inf_{\vb x \in \mathcal X} L(\vb x, \vb \lambda)
\]
\begin{theorem}[Weak duality theorem]
	If \( \vb x \in \mathcal X(\vb b) \) and \( \vb\lambda \in \vb\Lambda \), then \( f(\vb x) \geq g(\lambda) \).
	In particular,
	\[
		\inf_{\vb x \in \mathcal X(\vb b)} f(\vb x) \geq \sup_{\vb \lambda \in \vb \Lambda} g(\vb \lambda)
	\]
\end{theorem}
\begin{proof}
	\begin{align*}
		\inf_{\vb x \in \mathcal X(\vb b)} f(\vb x) & = \inf_{\vb x \in \mathcal X(\vb b)} f(\vb x) - \vb \lambda^\transpose (h(\vb x) - \vb b) \\
		                                            & \geq \inf_{\vb x \in \mathcal X} f(\vb x) - \vb \lambda^\transpose (h(\vb x) - \vb b)     \\
		                                            & = \inf_{\vb x \in \mathcal X} L(\vb x, \vb \lambda)                                       \\
		                                            & = g(\vb\lambda)
	\end{align*}
\end{proof}
Using this weak duality property, if \( \inf_{\vb x \in \mathcal X(\vb b)} f(\vb x) \) is difficult to solve, we can first attempt \( \sup_{\vb \lambda \in \vb \Lambda} g(\vb \lambda) \).
The problem
\begin{alignat*}{2}
	 & \text{maximise}   & \qquad & g(\vb \lambda)              \\
	 & \text{subject to} &        & \vb \lambda \in \vb \Lambda
\end{alignat*}
is called the \textit{dual problem}.
The original is called the \textit{primal problem}.
The optimal cost of the primal problem is always greater than or equal to the optimal cost of the dual problem.
The \textit{duality gap} is the difference:
\[
	\inf_{\vb x \in \mathcal X(\vb b)} f(\vb x) - \sup_{\vb \lambda \in \vb \Lambda} g(\vb \lambda)
\]
If the duality gap is zero, then we say that \textit{strong duality} holds.
This strengthens the inequality into an equality.

\subsection{Strong Duality and the Lagrange Method}
If the Lagrange method works, then we know that
\[
	\inf_{\vb x \in \mathcal X} L(\vb x, \vb \lambda) = \inf_{\vb x \in \mathcal X(\vb b)} L(\vb x, \vb \lambda)
\]
So, taking such a \( \vb \lambda \) in the proof above, we have equality instead of inequality.
Hence the problem has strong duality.
Conversely, if the duality gap is zero, then there exists a \( \vb \lambda \) such that the inequality above is an equality.
Hence, for this \( \vb \lambda \),
\[
	\inf_{\vb x \in \mathcal X} L(\vb x, \vb \lambda) = \inf_{\vb x \in \mathcal X(\vb b)} L(\vb x, \vb \lambda)
\]
Hence this is the \( \vb \lambda \) which will solve the Lagrange method.
In summary, strong duality holds exactly when the Lagrange method works.

\subsection{Hyperplane Condition for Strong Duality}
\begin{definition}
	A function \( \phi \colon \mathbb R^m \to \mathbb R \) is said to have a \textit{supporting hyperplane} at a point \( \vb b \) if there exists \( \vb \lambda \in \mathbb R^m \) such that for all \( \vb c \in \mathbb R^m \),
	\[
		\phi(\vb c) \geq \phi(\vb b) + \vb\lambda^\transpose (\vb c - \vb b)
	\]
\end{definition}
\noindent Pictorially, \( \phi \) has a supporting hyperplane if there is a plane passing through \( (\vb b, \phi(\vb b)) \), where \( \phi \) is always above the plane.
This could be, for example, a tangent plane at \( \vb b \).
% A \textit{separating} hyperplane is a plane where the inequality could be reversed, so the plane would be above all other values of \( \phi \).
% Not sure if this is relevant?

\begin{definition}
	A function \( \phi \colon \mathbb R^m \to \mathbb R \) associated with the primal problem by
	\[
		\phi(\vb c) = \inf_{\vb x \in \mathcal X(\vb c)} f(\vb x)
	\]
	This \( \phi \) can be thought of as the optimal cost of a family of optimisation problems with different functional constraint values \( \vb c \).
	This is called the \textit{value function}.
\end{definition}

\begin{theorem}[Strong duality theorem]
	Strong duality holds if and only if the value function \( \phi \) has a separating hyperplane at \( \vb b \).
\end{theorem}
\begin{proof}
	First, we show that a separating hyperplane implies strong duality.
	We have \( \vb \lambda \) such that
	\[
		\phi(\vb c) \geq \phi(\vb b) + \vb\lambda^\transpose (\vb c - \vb b)
	\]
	Then, we have
	\begin{align*}
		g(\vb \lambda) & = \inf_{\vb x \in \mathcal X} f(\vb x) - \vb\lambda^\transpose (h(\vb x) - \vb b)                                                                                                                           \\
		               & = \inf_{\vb c} \inf_{\vb x \in \mathcal X(\vb c)} f(\vb x) - \underbrace{\vb\lambda^\transpose (h(\vb x) - \vb c)}_{\mathclap{\text{zero since we are extremising}}} - \vb\lambda^\transpose(\vb c - \vb b) \\
		               & = \inf_{\vb c} \phi(\vb c) - \vb\lambda^\transpose(\vb c - \vb b)                                                                                                                                           \\
		               & \geq \phi(\vb b)
	\end{align*}
	By weak duality, we also have the reverse direction: \( g(\vb \lambda) \leq \phi(\vb b) \)
	Hence, \( g(\vb \lambda) = \phi(\vb b) \) and strong duality holds.
	Conversely, if strong duality holds, we want to show the existence of such a hyperplane.
	We have We have \( \vb \lambda \) such that \( g(\vb \lambda) = \phi(\vb b) \).
	For such a \( \vb \lambda \), we have
	\begin{align*}
		\phi(\vb b) = g(\vb \lambda) & = \inf_{\vb x \in \mathcal X} f(\vb x) - \vb\lambda^\transpose (h(\vb x) - \vb b)                                        \\
		                             & = \inf_{\vb x \in \mathcal X} f(\vb x) - \vb\lambda^\transpose (h(\vb x) - \vb c) - \vb\lambda^\transpose(\vb c - \vb b) \\
		                             & \leq \phi(\vb c) - \vb\lambda^\transpose(\vb c - \vb b)
	\end{align*}
	The last inequality holds due to weak duality.
	So \( \vb \lambda \) gives a supporting hyperplane.
\end{proof}

\subsection{Strong Duality and Convex Functions}
We would now like to consider for which problems \( \phi(\vb b) \) has a separating hyperplane.
The following theorem is stated without proof.
\begin{theorem}
	A function \( \phi \colon \mathbb R^m \to \mathbb R \) is convex if and only if every point \( \vb b \in \mathbb R^m \) has a separating hyperplane.
\end{theorem}
Now, for which problems do we have a convex value function?
\begin{theorem}
	Consider a minimisation problem
	\begin{alignat*}{2}
		 & \underset{\vb x \in \mathcal X}{\text{minimise}} & \qquad & f(\vb x)            \\
		 & \text{subject to}                                &        & h(\vb x) \leq \vb b
	\end{alignat*}
	with value function \( \phi \).
	Then \( \phi \) is convex if:
	\begin{enumerate}[(i)]
		\item \( \mathcal X \) is convex;
		\item \( f \) is convex;
		\item \( h \) is convex.
	\end{enumerate}
\end{theorem}
\noindent This is proven in the Example Sheets.

\subsection{Shadow Prices Interpretation of Lagrange Multipliers}
Suppose a factory owner produces \( n \) types of products from \( m \) types of raw materials.
Suppose the owner produces \( \vb x = (x_1, x_2, \dots, x_n) \) products, then the profit is some function \( f(\vb x) \).
We then create \( h_j(\vb x) \) to be the amount of raw material \( j \) consumed when making products \( \vb x \).
The owner wants to maximise \( f(\vb x) \) subject to \( h_i(\vb x) \leq b_i \) where \( b_i \) is the maximum amount of raw material \( i \) that is available.

Now, suppose a supplier offers some \( \vb\varepsilon = (\varepsilon_1, \varepsilon_2, \dots, \varepsilon_m) \) extra raw materials to the factory owner.
We would like to calculate how much this \( \vb\varepsilon \) is worth.
The factory owner will try to maximise this new problem, replacing \( \vb b \mapsto \vb b + \vb\varepsilon \).
For a small enough \( \vb\varepsilon \), this can be expressed easily using the value function.

\[
	\phi(\vb b + \vb\varepsilon) - \phi(\vb b) \approx \sum_{j=1}^m \pdv{\phi}{b_j}(\vb b) \varepsilon_j
\]
The quantity \( \pdv{\phi}{b_j}(\vb b) \) is the price of material \( j \), and \( \grad \phi(\vb b) \) is the vector of prices.
These are called the `shadow prices'; they are hidden to the outside world but depend on the internal state of the factory.

\begin{theorem}
	If \( \phi \) is differentiable at \( \vb b \) and has a separating hyperplane given by \( \vb \lambda \), then
	\[
		\vb \lambda = \grad{\phi}(\vb b)
	\]
\end{theorem}
\begin{proof}
	Let \( \vb a = (a_1, a_2, \dots, a_m) \) be an arbitrary vector.
	Then from the supporting hyperplane condition, for some small \( \delta > 0 \) we have
	\[
		\frac{\phi(\vb b + \delta\vb a)}{\delta} \geq \vb \lambda^\transpose \vb a
	\]
	Since \( \phi \) is differentiable, the limit can be taken to give
	\[
		\grad{\phi}(\vb b) \cdot \vb a \geq \vb \lambda^\transpose \vb a
	\]
	But \( \vb a \) was arbitrary.
	This can only hold if \( \vb \lambda = \grad{\phi}(\vb b) \) as required.
	So the Lagrange multiplier \( \vb \lambda \) at \( \vb b \) is equal to the gradient vector of \( \phi \) which is the gradient of partial derivatives and also the vector of shadow prices.
\end{proof}

\noindent Suppose that a particular raw material was not used up.
Then there is a slack value in the inequality.
The shadow price is zero in this instance, since we do not need more of this material.
So the corresponding Lagrange multiplier is equal to zero.
Conversely, if we are paying something for this material, then we must have used up all of that material.
This is exactly the complementary slackness property seen earlier.

There is also an economics interpretation of the dual problem.
Such a problem can be seen from the perspective of the raw material seller.
This seller charges a certain price \( \vb \lambda \) for their raw materials, and then buys the finished product from the factory.
The profit of the raw material seller is
\[
	\underbrace{\vb\lambda^\transpose (h(\vb x) - \vb b)}_{\text{cost of materials}} - \underbrace{f(\vb x)}_{\text{buying products}}
\]
For every choice of \( \vb\lambda \), the factory owner will try to maximise their profit, that is, find an \( \vb x^\star \) such that we maximise
\[
	\underbrace{f(\vb x)}_{\text{selling products}} - \underbrace{\vb\lambda^\transpose (h(\vb x) - \vb b)}_{\text{cost of materials}}
\]
