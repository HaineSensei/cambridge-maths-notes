\subsection{Strong Markov property}
The simple Markov property shows that, if \( X_m = i \),
\[
	X_{m + n} \sim \Markov{\delta_i, P}
\]
and this is independent of \( X_0, \dots, X_m \).
The strong Markov property will show that the same property holds when we replace \( m \) with a finite random `time' variable.
It is not the case that \textit{any} random variable will work; indeed, an \( m \) very dependent on the Markov chain itself might not satisfy this property.
\begin{definition}
	A random time \( T \colon \Omega \to \qty{0, 1, \dots} \cup \qty{\infty} \) is called a \textit{stopping time} if, for all \( n \in \mathbb N \), \( \qty{ T = n } \) depends only on \( X_0, \dots, X_n \).
\end{definition}
\begin{example}
	The hitting time \( T_A = \inf \qty{ n \geq 0 \colon X_n \in A} \) is a stopping time.
	This is because we can write
	\[
		\qty{T_A = n} = \qty{X_0 \in A, \dots, X_{n-1} \not\in A, X_n \in A}
	\]
\end{example}
\begin{example}
	The time \( L_A = \sup \qty{n \geq 0 \colon X_n \in A} \) is not a stopping time.
	This is because we need to know information about the future behaviour of \( X_n \) in order to guarantee that we are at the supremum of such events.
\end{example}
\begin{theorem}[Strong Markov Property]
	Let \( X \sim \Markov(\lambda, P) \) and \( T \) be a stopping time.
	Conditional on \( T < \infty \) and \( X_T = i \),
	\[
		\qty(X_{n + T})_{n \geq 0} \sim \Markov{\delta_i, P}
	\]
	and this distribution is independent of \( X_0, \dots, X_T \).
\end{theorem}
\begin{proof}
	We need to show that, for all \( x_0, \dots, x_n \) and for all vectors \( w \) of any length,
	\begin{align*}
		 & \prob{X_T = x_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i}                    \\
		 & = \delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_T) = w \colon T < \infty, X_T = i}
	\end{align*}
	Suppose that \( w \) is of the form \( w = (w_0, \dots, w_k) \).
	Then,
	\begin{align*}
		 & \prob{X_T = X_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i}                      \\
		 & = \frac{\prob{X_k = x_0, \dots, X_{k+n} = x_n, (X_0, \dots, X_k)=w, T=k,X_k=i}}{\prob{T < \infty, X_T = i}}
	\end{align*}
	Now, since \( \qty{T=k} \) depends only on \( X_0, \dots, X_k \), by the simple Markov property we have
	\begin{align*}
		 & \prob{X_k = x_0, \dots, X_{k+n} = x_n \mid (X_0, \dots, X_k) = w, T = k, X_k = i}                        \\
		 & = \prob{X_k = x_0, \dots, X_{k+n} = x_n \mid X_k = i} = \delta_{i x_0} P(x_0, x_1) \dots P(x_{n-1}, x_n)
	\end{align*}
	Now,
	\begin{align*}
		 & \prob{X_T = x_0, \dots, X_{T+n} = x_n, (X_0, \dots, X_T) = w \mid T < \infty, X_T = i}                                                  \\
		 & = \frac{\delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_k) = w \colon T = k, X_k = i}}{\prob{T < \infty, X_T = i}} \\
		 & = \delta_{i x_0} P(x_0,x_1) \dots P(x_{n-1}, x_n) \prob{(X_0, \dots, X_T) = w \colon T < \infty, X_T = i}
	\end{align*}
	as required.
\end{proof}
\begin{example}
	Consider a simple random walk on \( I = \mathbb N \), where \( P(x,x\pm 1) = \frac{1}{2} \) for \( x \neq 0 \), and \( P(0,1) = 1 \).
	Now, let \( h_i = \psub{i}{T_0 < \infty} \).
	We want to calculate \( h_1 \).
	We can write
	\[
		h_1 = \frac{1}{2} + \frac{1}{2} h_2
	\]
	but the system of recursion relations this generates is difficult to solve.
	Instead, we will write
	\[
		h_2 = \psub{2}{T_0 < \infty}
	\]
	Note that in order to hit 0, we must first hit 1.
	So conditioning on the first hitting time of 1 being finite, after this time the process starts again from 1.
	We can write \( T_0 = T_1 + \widetilde T_0 \), where \( \widetilde T_0 \) is independent of \( T_1 \), with the same distribution as \( T_0 \) under \( \mathbb P_1 \).
	Now,
	\[
		h_2 = \psub{2}{T_0 < \infty, T_1 < \infty} = \psub{2}{T_0 < \infty \mid T_1 < \infty} \psub{2}{T_2 < \infty}
	\]
	Note that
	\[
		\psub{2}{T_0 < \infty \mid T_1 < \infty} = \psub{2}{T_1 + \widetilde T_0 < \infty \mid T_1 < \infty} = \psub{2}{\widetilde T_0 < \infty \mid T_1 < \infty} = \psub{1}{T_0 < \infty}
	\]
	But \( \psub{2}{T_1 < \infty} = \psub{1}{T_0 < \infty} \), so
	\[
		h_2 = \psub{2}{T_1 < \infty} \psub{1}{T_0 < \infty}
	\]
	By translation invariance,
	\[
		h_2 = h_1^2
	\]
	In general, therefore, for any \( n \in \mathbb N \),
	\[
		h_n = h_1^n
	\]
\end{example}

\subsection{Transience and recurrence}
\begin{definition}
	Let \( X \) be a Markov chain, and let \( i \in I \).
	\( i \) is called \textit{recurrent} if
	\[
		\psub{i}{X_n = i \text{ for infinitely many } n} = 1
	\]
	\( i \) is called \textit{transient} if
	\[
		\psub{i}{X_n = i \text{ for infinitely many } n} = 0
	\]
\end{definition}
\noindent We will prove that any \( i \) is either recurrent or transient.
\begin{definition}
	Let \( T_i^{(0)} = 0 \) and inductively define
	\[
		T_i^{(r+1)} = \inf \qty{n \geq T_i^{(r)} + 1 \colon X_n = i}
	\]
	We write \( T_i^{(1)} = T_i \), called the first return time (or first passage time) to \( i \).
	Let \( f_i = \psub{i}{T_i < \infty} \).
	Let
	\[
		V_i = \sum_{n=0}^\infty 1(X_m = i)
	\]
	which is the number of visits to \( i \).
\end{definition}
