\subsection{Definition}
Let \( I \) be a finite or countable set.
All of our random variables will be defined on the same probability space \( (\Omega, \mathcal F, \mathbb P) \).
\begin{definition}
A stochastic process \( (X_n)_{n \geq 0} \) is called a \textit{Markov chain} if \( \forall n \geq 0 \) and for \( x_1 \dots x_{n+1} \in I \), #1
\end{definition}
We can think of \( n \) as a discrete measure of time.
If \( \prob{X_{n+1} = y | X_n = x} \) for all \( x, y \) is independent of \( n \), then \( X \) is called time-homogeneous.
Otherwise, \( X \) is called time-inhomogeneous.
In this course, we only study time-homogeneous Markov chains.
If we consider time-homogeneous chains only, we may as well take \( n = 0 \) and we can write
\[ P(x,y) = \prob{X_1 = y | X_0 = x};\quad \forall x,y \in I \]
\begin{dfinition}
A \textit{stochastic matrix} is a matrix where the sum of each row is equal to 1.
\end{definition}
We call \( P \) the \textit{transition matrix}.
It is a stochastic matrix:
\[ \sum_{y \in I} P(x,y) = 1 \]
\begin{remark}
The index set does not need to be \( \mathbb N \); it could alternatively be \( \qty{0,1,\dots,N} \) for \( N \in \mathbb N \).
\end{remark}
We say that \( X \) is \(\mathrm{Markov}(\lambda, P)\) if \( X_0 \) has distribution \lambda, and P is the transition matrix.
Hence,
\begin{enumerate}[(i)]
\item \( \prob{X_0 = x_0} = \lambda_{x_0} \)
\item \( \prob{X_{n+1} = x_{n+1} | X_n = x_n, \dots, X_0 = x_0} = P(x_n, x_{n+1}) =: P_{x_n x_{n+1}} \)
\end{enumerate}
We usually draw a diagram of the transition matrix using a graph.
Directed edges between nodes are labelled with their transition probabilities.

\subsection{Sequence Definition}
\begin{theorem}
The process \( X \) is Markov(lambda, P) if and only if \( \forall n \geq 0 \) and all \( x_0, \dots, x_n \in I \), we have
\[ \prob{X_0 = x_0, \dots, X_n = x_n} = \lambda_{x_0} P(x_0, x_1) P(x_1, x_2) \dots P(x_{n-1}, x_n) \]
\end{theorem}
\begin{proof}
If \( X \) is Markov, then we have
\begin{align*}
\prob{X_0 = x_0, \dots, X_n = x_n} &= \prob{X_n = x_n | X_{n-1} = x_{n-1}, \dots, X_0 = x_0} \prob{X_{n-1} = x_{n-1}, \dots, X_0 = x_0} \\
&= P(x_{n-1}, x_n) \prob{X_{n-1} = x_{n-1}, \dots, X_0 = x_0} \\
&= P(x_{n-1}, x_n) \dots P(x_0, x_1) \lamba_{x_0}
\end{align*}
as required.
Conversely,
\prob{X_0 = x_0} = \lambda_{x_0}
satisfies (i).
The transition matrix is given by
\[ \prob{X_n = x_n | previous} = \frac{\lambda_{x_0} P(x_0, x_1) \dots P(x_{n-1}, x_n)}{\lambda_{x_0} P(x_0, x_1) \dots P(x_{n-2}, x_{n-1})} = P(x_{n-1}, x_n) \]
which is exactly the Markov property as required.
\end{proof}

\subsection{Point Masses}
\begin{definition}
For \( i \in I \), the \( \delta_i \)-mass at \( i \) is defined by
\[ \delta_{ij} = \mathbb 1{i = j} \]
This is a probability measure that has probability 1 at \( i \) only.
\end{definition}

\subsection{Independence of Sequences}
Recall that discrete random variables \( (X_n) \) are considered independent if for all \( x_1, \dots, x_n \in I \), we have
\[ \prob{X_1 = x_1, \dots, X_n = x_n} = \prob{X_1 = x_1}\dots\prob{X_n = x_n} \]
A sequence \( (X_n) \) is independent if for all \( k \), \( i_1 < i_2 < \dots < i_n \) and for all \( x_1, \dots, x_k \), we have
\[ \prob{X_{i_1} = x_1, \dots, X_{i_k} = x_k} = \prod_{j=1}^n \prob{X_{i_j} = x_j} \]
Let \( X = (X_n), Y = (Y_n) \) be sequences of discrete random variables.
They are independent if for all \(k,m\), \( i_1 < \dots < i_k \), \( j_1 < \dots < j_m \),
\[ \prob{X_1 = x_1, \dots, X_{i_k} = x_{i_k}, Y_{j_1} = y_{j_1}, \dots, Y_{j_m}} = \prob{} separate Xs and Ys into 2 probs \]

\subsection{Simple Markov Property}
\begin{theorem}
Suppose \( X \) is Markov(\lambda, P).
Let \( m \in \mathbb N \) and \( i \in I \).
Given that \( X_m = i \), we have that the process after time \( m \), written \( (X_{m+n})_{n \geq 0} \), is Markov(\delta_i, P), and it is independent of \( X_0, \dots, X_n \).
\end{theorem}
Informally, the past and the future are independent given the present.
\begin{proof}
We must show that
\[ \prob{X_m = x_0, \dots, X_{m+n} = x_n | X_m = i} = \delta_{i x_0} P(x_0, x_1) \dots P(x_{n-1}, x_n) \]
\end{proof}
