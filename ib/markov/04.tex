\subsection{??}
Consider the Markov chain previously explored.
% copy this
Let \( A = \qty{4} \).
Then \( h_1^A = 0 \) since there is no route from 1 to 4.
From the theorem above, the system of linear equations is
\[
	h_2 = \frac{1}{2} h_1 + \frac{1}{2} h_3
\]
\[
	h_3 = \frac{1}{2} h_4 + \frac{1}{2} h_2
\]
\[
	h_4 = 1
\]
Hence,
\[
	h_2 = \frac{2}{3} h_1 + \frac{1}{3}
\]
\[
	h_3 = \frac{1}{3} h_1 + \frac{2}{3}
\]
So the minimal solution arises at \( h_1 = 0 \).
\begin{example}
	Consider \( I = \mathbb N \), and
	\[
		P(i, i+1) = p \in (0,1);\quad P(i, i-1) = 1-p = q
	\]
	Then \( h_i = \psub{i}{T_0 < \infty} \) hence \( h_0 = 1 \).
	The linear equations are
	\[
		p \neq q \implies h_i = p h_{i+1} + q h_{i-1}
	\]
	\[
		p(h_{i+1} - h_i) = q(h_i - h_{i-1})
	\]
	Let \( u_i = h_i - h_{i-1} \).
	Then,
	\[
		\frac{q}{p} u_i = \dots = \qty(\frac{q}{p})^i u_1
	\]
	Hence
	\[
		h_i = \sum_{j=1}^i (h_j - h_{j-1}) + 1 = 1 - (1-h_i) \sum_{j=1}^i \qty(\frac{q}{p})^j
	\]
	The general solution is therefore
	\[
		h_i = a + b \qty(\frac{q}{p})^i
	\]
	If \( q > p \), then minimality of \( h_i \) implies \( b = 0 \), \( a = 1 \).
	Hence,
	\[
		h_i = 1
	\]
	Otherwise, if \( p > q \), minimality of \( h_i \) implies \( a = 0 \), \( b = 1 \).
	Hence,
	\[
		h_i = \qty(\frac{q}{p})^i
	\]
	If \( p = q = \frac{1}{2} \), then
	\[
		h_i = \frac{1}{2} h_{i+1} + \frac{1}{2} h_{i-1}
	\]
	Hence, \( h_i = a + bi \).
	Minimality implies \( a = 1 \) and \( b = 0 \).
	\[
		h_i = 1
	\]
\end{example}

\subsection{Birth and Death Chain}
Consider a Markov chain on \( \mathbb N \) with
\[
	P(i,i+1) = p_i;\quad P(i,i-1) = q_i;\quad \forall i,\ p_i + q_i = 1
\]
Now, consider \( h_i = \psub{i}{T_0 < \infty} \).
\( h_0 = 1 \), and \( h_i = p_i h_{i+1} + q_i h_{i-1} \).
\[
	p_i (h_{i+1} - h_i) = q_i (h_i - h_{i-1})
\]
Let \( u_i = h_i - h_{i-1} \) to give
\[
	u_{i+1} = \frac{q_i}{p_i} u_i = \underbrace{\prod{j=1}^i \frac{q_i}{p_i}}_{\gamma_i} u_i
\]
Then
\[
	h_i = 1 - (1 - h_1) \qty( \gamma_0 + \gamma_1 + \dots + \gamma_{i-1} )
\]
where we let \( \gamma_0 = 1 \).
Since \( h_i \) is the minimal non-negative solution,
\[
	h_i \geq 0 \implies 1 - h_1 \leq \frac{1}{\sum_{j=0}^{i-1} \gamma_j} \leq \frac{1}{\sum_{j=0}^{\infty} \gamma_j}
\]
By minimality, we must have exactly this bound.
If \( \sum_{j=0}^\infty \gamma_j = \infty \) then \( 1 - h_1 = 0 \implies h_i = 1 \) for all \( i \).
If \( \sum_{j=0}^\infty \gamma_j < \infty \) then
\[
	h_i = \frac{\sum_{j=i}^\infty \gamma_j}{\sum_{j=0}^\infty \gamma_j}
\]

\subsection{Mean Hitting Times}
Recall that
\[
	k_i^A = \esub{i}{T_A} = \sum_n n \psub{i}{T_A = n} + \infty \psub{i}{T_A = \infty}
\]
\begin{theorem}
	The vector \( (k_i^A)_{i \in I} \) is the minimal non-negative solution to the system of equations
	\[
		\begin{cases}
			0                                   & \text{if } i \in A     \\
			1 + \sum_{j \not\in A} P(i,j) k_j^A & \text{if } i \not\in A
		\end{cases}
	\]
\end{theorem}
\begin{proof}
	Suppose \( i \in A \).
	Then \( k_i = 0 \).
	Now suppose \( i \not\in A \).
	Further, we may assume that \( \psub{i}{T_A = \infty} = 0 \), since if that probability is positive then the claim is trivial.
	Indeed, if \( \psub{i}{T_A = \infty} > 0 \), then there must exist \( j \) such that \( P(i,j) > 0 \) and \( \psub{j}{T_A = \infty} > 0 \) since
	\[
		\psub{i}{T_A < \infty} = \sum_j P(i,j) h_j^A \implies 1 - \psub{i}{T_A = \infty} = \sum_j P(i,j) \qty(1 - \psub{j}{T_A = \infty})
	\]
	Because \( P \) is stochastic,
	\[
		\psub{i}{T_A = \infty} = \sum_j P(i,j) \psub{j}{T_A = \infty}
	\]
	so since the left hand side is positive, there must exist \( j \) with \( P(i,j) > 0 \) and \( \psub{j}{T_A = \infty > 0} \).
	For this \( j \), we also have \( k_j^A = \infty \).

	Now we only need to compute \( \sum_n n\psub{i}{T_A = n} \).
	\[
		\psub{i}{T_A = n} = \psub{i}{X_0 \not\in A, \dots, X_{n-1} \not\in A, X_n \in A}
	\]
	Then, using the same method as the previous theorem,
	\[
		k_i^A = \sum_n n \psub{i}{T_A = n} = 1 + \sum_{j \not\in A} P(i,j) k_j^A
	\]

	It now suffices to prove minimality.
	Suppose \( (x_i) \) is another solution to this system of equations.
	We need to show that \( x_i \geq k_i^A \) for all \( i \).
	Suppose \( i \not\in A \).
	Then
	\[
		x_i = 1 + \sum_{j \not\in A} P(i,j) x_j = 1 + \sum_{j \not\in A} P(i,j) \qty(1 + \sum_{k \not\in A} P(j,k) x_k)
	\]
	Expanding inductively,
	\[
		x_i = 1 + \sum_{j_1 \not\in A} P(i,j_1) + \sum_{j_1 \not\in A, j_2 \not\in A} P(i,j_1)P(j_1,j_2) + \dots + \sum_{j_1 \not\in A, \dots, j_n \not\in A} P(i,j_1) \dots P(j_{n-1}, j_n) + \sum_{j_1 \not\in A, \dots, j_{n+1} \not\in A} P(i,j) \dots P(j_n,j_{n+1})x_{j_{n+1}}
	\]
	Since \( x \) is non-negative, we can remove the last term and reach an inequality.
	\[
		x_i \geq 1 + \sum_{j_1 \not\in A} P(i,j_1) + \sum_{j_1 \not\in A, j_2 \not\in A} P(i,j_1)P(j_1,j_2) + \dots + \sum_{j_1 \not\in A, \dots, j_n \not\in A} P(i,j_1) \dots P(j_{n-1}, j_n)
	\]
	Hence
	\begin{align*}
		x_i \geq 1 + \psub{i}{T_A > 1} + \psub{i}{T_A > 2} + \dots + \psub{i}{T_A > n}             \\
		 & = \psub{i}{T_A > 0} + \psub{i}{T_A > 1} + \psub{i}{T_A > 2} + \dots + \psub{i}{T_A > n} \\
		 & = \sum_{k = 0}^n \psub{i}{T_A > k}
	\end{align*}
	for all \( n \).
	Hence, the limit of this sum is
	\[
		x_i \geq \sum_{k=0}^\infty \psub{i}{T_A > k} = \esub{i}{T_A}
	\]
	which gives minimality as required.
\end{proof}
