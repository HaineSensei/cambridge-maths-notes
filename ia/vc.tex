\documentclass{article}

\input{../util.tex}

\title{Vector Calculus}
\author{Cambridge University Mathematical Tripos: Part IA}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Differential Geometry of Curves}
\subsection{Notation}
Throughout this course, a column vector e.g.
\[ \begin{pmatrix}
        a \\ b \\ c
    \end{pmatrix} \]
it should be interpreted as the vector
\[ \bm x = a \bm e_x + b \bm e_y + x \bm e_z \]
where $\{ \bm e_x, \bm e_y, \bm e_z \}$ are the basis vectors aligned with the fixed Cartesian $x, y, z$ axes in $\mathbb R^3$. We will be dealing with various kinds of basis vectors through the course, so it is useful to define now that column vectors written as above always represent the standard basis.

\subsection{Parametrised Curves and Smoothness}
A parametrised curve $C$ in $R^3$ is the image of a continuous map $\bm x \colon [a, b] \to \mathbb R^3$, in which $t \mapsto \bm x(t)$. In Cartesian coordinates,
\[ \bm x(t) = \begin{pmatrix}
        x_1(t) \\ x_2(t) \\ x_3(t)
    \end{pmatrix} = \begin{pmatrix}
        x(t) \\ y(t) \\ z(t)
    \end{pmatrix} \]
The resultant curve has a direction, from $\bm x(a)$ to $\bm x(b)$.
\begin{definition}
    We say that $C$ is a differentiable curve if each of the components $\{x_i(t)\}$ are differentiable functions. $C$ is regular if it is differentiable and $\abs{\bm x'(t)} \neq 0$. If $C$ is differentiable and regular, we say that $C$ is smooth.
\end{definition}
\begin{note}
    We need this regularity condition because it is quite easy to create `bad curves' with cusps and spikes using only differentiable functions, for example
    \[ \bm x(t) = (t^2, t^3) \]
    The components are clearly differentiable, but $\bm x(t)$ has a cusp at $t = 0$. At this point, $\abs{\bm x'(0)} = 0$.
\end{note}
\begin{definition}
    Recall that $x_i(t)$ is called `differentiable' at $t$ if
    \[ x_i(t+h) = x_i(t) + x_i'(t)h + o(h) \]
    where $o(h)$ represents a function that obeys
    \[ \lim_{h \to 0} \frac{o(h)}{h} = 0 \]
    In terms of vectors,
    \[ \bm x(t+h) = \bm x(t) + \bm x'(t)h + o(h) \]
    where here $o(h)$ is a vector for which
    \[ \lim_{h \to 0} \frac{\abs{o(h)}}{h} = 0 \]
\end{definition}

\subsection{Arc Length}
We can approximate the length of a curve $C$ by splitting it into small straight lines and summing the lengths of such lines. We will introduce a partition $P$ of $[a, b]$ with $t_0 = a, t_N = b$ and
\[ t_0 < t_1 < t_2 < \dots < t_N \]
Let us now set $\Delta t_i = t_{i+1} - t_i$ and $\Delta t = \max_i \Delta t_i$. The length of the curve relative to $P$ is defined as
\[ \ell(C, P) = \sum_{i=0}^{N-1} \abs{\bm x(t_{i+1}) - \bm x(t_i)} \]
As $\Delta t$ gets smaller, we would expect $\ell(C, P)$ to give a better approximation to the true length of $C$, which we will call $\ell(C)$. Therefore we can define the length of $C$ by
\[ \ell(C) = \lim_{\Delta t \to 0} \sum_{i=0}^{N-1}\abs{\bm x(t_{i+1}) - \bm x(t_i)} = \lim_{\Delta t \to 0} \ell(C, P) \]
If this limit doesn't exist, we say that the curve is \textit{non-rectifiable}. Suppose $C$ is differentiable. Then
\begin{align*}
    \bm x(t_{i+1}) & = \bm x(t_i + t_{i+1} - t_i)                          \\
                   & = \bm x(t_i + \Delta t_i)                             \\
                   & = \bm x(t_i) + \bm x'(t_i) \Delta t_i + o(\Delta t_i)
\end{align*}
It follows then that
\[ \abs{\bm x(t_{i+1}) - \bm x(t_i)} = \abs{\bm x'(t_i)}\Delta t_i + o(\Delta t_i) \]
So if $C$ is differentiable,
\[
    \ell(C, P) = \lim_{\Delta t \to 0} \sum_{i=0}^{N-1} \left( \abs{\bm x'(t_i)}\Delta t_i + o(\Delta t_i)  \right)
\]
Recall that this $o(\Delta t_i)$ term represents a function for which $o(\Delta t_i) / \Delta t_i \to 0$. So for any $\varepsilon > 0$, if $\Delta t = \max_i \Delta t_i$ is sufficiently small, we have $\abs{o(\Delta t_i)} < \frac{\varepsilon}{b-a}\Delta t_i$, for $i = 0, \dots, N-1$. So by the Triangle Inequality, choosing $\Delta t$ sufficiently small,
\[
    \abs{\ell(C, P) - \sum_{i=0}^{N-1} \abs{\bm x'(t_i)}\Delta t_i} = \abs{\sum_{i=0}^{N-1} o(\Delta t_i)} < \frac{\varepsilon}{b-a}\underbrace{\sum_{i=0}^{N-1} \Delta t_i}_{b-a} = \varepsilon
\]
So the left hand side tends to zero as $\Delta t \to 0$. We then get
\begin{align*}
    \ell(C) & = \lim_{\Delta t \to 0} \ell(C, P)                                     \\
            & = \lim_{\Delta t \to 0} \sum_{i=0}^{N - 1} \abs{\bm x'(t_i)}\Delta t_i \\
            & = \int_a^b \abs{\bm x'(t)} \,\dd t
\end{align*}
according to Analysis I, and the definition of the Riemann Integral. So in summary, if $C \colon [a, b] \ni t \mapsto \bm x(t)$, then
\begin{align*}
    \ell(C) & = \int_a^b \abs{\bm x'(t)} \,\dd t \\
            & = \int_C \dd s
\end{align*}
where $\dd s$ is the `arc length element', i.e. $\dd s = \abs{\bm x'(t)} \,\dd t$. Similarly, we define
\[ \int_C f(\bm x) \,\dd s = \int_a^b f(\bm x(t)) \,\abs{\bm x'(t)} \,\dd t \]
If $C$ is made up of $M$ smooth curves $C_1, \dots, C_M$, we say that $C$ is `piecewise smooth'. We write $C = C_1 + \dots + C_M$ and define
\[ \int_C f(\bm x) \,\dd s = \sum_{i=1}^M \int_{C_i}f(\bm x) \,\dd s \]
Now note (informally) that
\[ \dd s = \abs{\bm x'(t)}\,\dd t = \sqrt{\left( \frac{\dd x}{\dd t} \right)^2 + \left( \frac{\dd y}{\dd t} \right)^2 + \left( \frac{\dd z}{\dd t} \right)^2} \,\dd t \]
i.e. (now very informally)
\[ \dd s^2 = \dd x^2 + \dd y^2 + \dd z^2 \]
which is Pythagoras' Theorem.

\subsection{Example of Arc Length}
Let $C$ be the circle of radius $r>0$ in $\mathbb R^3$
\[ \bm x(t) = \begin{pmatrix}
        r\cos t \\ r\sin t \\ 0
    \end{pmatrix};\quad t \in [0, 2\pi] \]
So
\[ \bm x'(t) = \begin{pmatrix}
        -r\sin t \\ r\cos t \\ 0
    \end{pmatrix} \]
Therefore
\[ \int_C \dd s = \int_0^{2\pi} \abs{\bm x'(t)} \,\dd t = \int_0^{2\pi} \sqrt{r^2 \sin^2 t + r^2 \cos^2 t} \,\dd t = \int_0^{2\pi} r \,\dd t = 2\pi r \]
Also, for example,
\[ \int_C x^2 y \,\dd s = \int_0^{2\pi} (r \cos t)^2 (r \sin t) \sqrt{r^2 \sin^2 t + r^2 \cos^2 t} \,\dd t = \int_0^{2\pi} r^3 \cos^2 t \sin t \,\dd t = 0 \]

\subsection{Choice of Parametrisation of Curves}
Does $\ell(C)$ depend on the choice of parametrisation of $\bm x(t)$? For example,
\[ \bm x(t) = \begin{pmatrix}
        r\cos t \\ r \sin t \\ 0
    \end{pmatrix};\quad t \in [0, 2\pi] \]
and
\[ \widetilde{\bm x}(t) = \begin{pmatrix}
        r\cos 2t \\ r \sin 2t \\ 0
    \end{pmatrix};\quad t \in [0, \pi] \]
both give rise to a circle, but have different forms. Suppose that $C$ has two different parametrisations,
\[ \bm x = \bm x_1(t);\quad a \leq t \leq b \]
\[ \bm x = \bm x_2(\tau);\quad \alpha \leq \tau \leq \beta \]
There must be some relationship $\bm x_2(\tau) = \bm x_1(t(\tau))$ for some function $t(\tau)$, since they represent the same curve. We can assume $\frac{\dd t}{\dd \tau} \neq 0$, so the map between $t$ and $\tau$ is invertible and differentiable (see IB Analysis and Topology). Note that
\begin{align*}
    \bm x_2'(\tau) & = \frac{\dd}{\dd \tau}\bm x_2(\tau)       \\
                   & = \frac{\dd}{\dd \tau}\bm x_1(t(\tau))    \\
    \intertext{By the Chain Rule,}
                   & = \frac{\dd t}{\dd \tau}\bm x_1'(t(\tau))
\end{align*}
And now from the above definitions,
\[ \int_C f(\bm x) \,\dd s = \int_a^b f(\bm x_1(t)) \, \abs{\bm x_1'(t)} \,\dd t \]
Making the substitution $t = t(\tau)$, and assuming $\frac{\dd t}{\dd \tau} > 0$, the lattern integral becomes
\[ \int_\alpha^\beta f(\bm x_2(\tau)) \, \underbrace{\abs{\bm x_1'(t(\tau))} \,\frac{\dd t}{\dd \tau}\dd \tau}_{\abs{\bm x_2'(\tau)}\,\dd \tau} = \int_\alpha^\beta f(\bm x_2(\tau)) \, \abs{\bm x_2'(\tau)} \,\dd \tau \]
which is precisely the same as $\int_C f(\bm x) \,\dd s$ using the $\bm x_2(\tau)$ parametrisation. When $\frac{\dd t}{\dd \tau} < 0$, you get the same result. So the definition of $\int_C f(\bm x) \, \dd s$ does \textit{not} depend on the choice of parametrisation of $C$.

\section{Curvature and Torsion}
\subsection{Parametrisation According to Arc Length}
We know that for any curve $C$ there exist multiple unique parametrisations. We will define the arc-length function for a curve $[a, b] \ni t \mapsto \bm x(t)$ by
\[ s(t) = \int_a^t \abs{\bm x'(\tau)} \,\dd \tau \]
So $s(a) = 0, s(b) = \ell(C)$. Using the Fundamental Theorem of Calculus, we have
\[ s'(t) = \abs{\bm x'(t)} \geq 0 \]
For regular curves, we have that
\[ s'(t) > 0 \]
So we can invert the relationship between $s$ and $t$; i.e. we can find $t$ as a function of $s$. Hence, we can parametrise curves with respect to arc length. If we write
\[ \bm r(s) = \bm x(t(s)) \]
where $0 \leq s \leq \ell(C)$, then by the chain rule we have
\[ \frac{\dd t}{\dd s} = \frac{1}{\frac{\dd s}{\dd t}} = \frac{1}{\abs{\bm x'(t(s))}} \]
So
\[ \bm r'(s) = \frac{\dd}{\dd s} \bm x(t(s)) = \frac{\dd t}{\dd s} \bm x'(t(s)) = \frac{\bm x'(t(s))}{\abs{\bm x'(t(s))}} \]
In other words, $\bm r'(s)$ is a unit vector tangential to the curve. This (consistently) gives
\[ \ell(C) = \int_0^{\ell(C)} \abs{\bm r'(s)} \,\dd s = \int_0^{\ell(C)} \dd s \]
as previously found above.

\subsection{Curvature}
Throughout this section, we will be talking about a generic regular curve $C$, parametrised with respect to arc length, where a position vector on $C$ is given by $\bm r(s)$. We will define the tangent vector
\[ \bm t(s) = \bm r'(s) \]
We already know that $\abs{\bm t(s)} = 1$. Therefore the only part of $\bm t$ that changes with respect to $s$ is its direction. So $\bm t'(s) = \bm r''(s)$ only measures the change in the direction of the tangent as we move along the curve. So intuitively, if $\abs{\bm r''(s)}$ is large then the curve is rapidly changing direction. If $\abs{\bm r''(s)}$ is small, the curve is approximately flat; there is little change in direction. Using this intuition, we will define curvature as
\[ \kappa(s) = \abs{\bm r''(s)} = \abs{\bm t'(s)} \]
In other words $\kappa$ is the magnitude of the acceleration a particle experiences while moving along the curve at unit speed.

\subsection{Torsion}
Since $\bm t = \bm r'(s)$ is a unit vector, differentiating $\bm t \cdot \bm t = 1$ gives $\bm t \cdot \bm t' = 0$. We will define the principal normal $\bm n$ by the formula
\[ \bm t' = \kappa \bm n \]
Note that $\bm n$ is everywhere normal to the curve $C$, since it is always perpendicular to the tangent vector $\bm t$, since $\bm t \cdot \bm n = 0$. We can extend the vectors $\{ \bm t, \bm n \}$ into an orthonormal basis by computing the cross product:
\[ \bm b = \bm t \times \bm n \]
We call $\bm b$ the binormal. It is a unit vector, since it is the cross product of two orthogonal unit vectors in $\mathbb R^3$. We also have that $\bm b \cdot \bm b' = 0$; also since $\bm t \cdot \bm b = 0$ and $\bm n \cdot \bm b = 0$, we must have
\[ 0 = (\bm t \cdot \bm b)' = \bm t' \cdot \bm b + \bm t \cdot \bm b' = \kappa \bm n \cdot b + \bm t \cdot \bm b' = \bm t \cdot \bm b' \]
So $\bm b'$ is orthogonal to both $\bm t$ and $\bm b$, i.e. it is parallel to $\bm n$. We will define the torsion $\tau$ of a curve by
\[ \bm b' = -\tau \bm n \]
A physical interpretation of torsion is a kind of `corkscrew' rotation in three dimensions.

\begin{proposition}[Fundamental Theorem of Differential Geometry of Curves]
    The curvature $\kappa(s)$ and torsion $\tau(s)$ uniquely define a curve in $\mathbb R^3$, up to translation and orientation.
\end{proposition}
\begin{proof}
    Since $\bm n = \bm b \times \bm t$, we have $\bm t' = \kappa(\bm b \times \bm t)$ and $\bm b' = -\tau(\bm b \times \bm t)$. This gives six equations (written in component form) for six unknowns. Given $\kappa(s)$ and $\tau(s)$, and given $\bm t(0)$ and $\bm b(0)$, we can construct the functions $\bm t(s), \bm b(s), \bm n(s) = \bm b(s) \times \bm t(s)$.
\end{proof}

\subsection{Radius of Curvature}
A generic curve $s \mapsto \bm r(s)$ can be Taylor expanded around $s=0$. Writing $\bm t = \bm t(0), \bm n = \bm n(0)$ and so on, we have
\begin{align*}
    \bm r(s) & = \bm r + s\bm r' + \frac{1}{2}s^2 \bm r'' + o(s^2)    \\
             & = \bm r + s\bm t + \frac{1}{2}s^2 \kappa\bm n + o(s^2)
\end{align*}
What circle that touches the curve at $s=0$ would be the best approximation for the curve at this point? Since the circle touches the curve, we know the position vectors (of the curve and the circle) match, and their first derivatives match. So we want to unify the second derivatives. The equation of such a circle of radius $R$ is
\[ \bm x(\theta) = \bm r + R(1 - \cos \theta)\bm n + R(\sin \theta) \bm t \]
Expanding this for small $\theta$ gives
\[ \bm x(\theta) = \bm r + R\theta\bm t + \frac{1}{2} R\theta^2\bm n + o(\theta^2) \]
But the arc length on a circle is simply $R\theta$. So in terms of arc length,
\[ \bm x(\theta) = \bm r + s\bm t + \frac{1}{2} s^2 \frac{1}{R}\bm n + o(s^2) \]
Hence by comparing coefficients,
\[ R = \frac{1}{\kappa} \]
We name this $R(s)$ the radius of curvature.

\subsection{Gaussian Curvature (non-examinable)}
This subsection is non-examinable. How can we find the curvature of a surface? At any point $\bm r$ on a surface, we have a normal vector $\bm n$. We can construct a plane containing this normal; such a plane will then intersect the surface near $\bm r$. This intersection is a curve $C$, which has a curvature $\kappa$. The choice of plane is arbitrary, however. To unify all of these different possible results for $\kappa$, we can compute the Gaussian curvature $\kappa_G$ by
\[ \kappa_G = \kappa_{\text{min}} \kappa_{\text{max}} \]
\begin{itemize}
    \item The Gaussian curvature of a flat plane is zero, since the minimum and maximum curvatures are both zero.
    \item On any point on a sphere of radius $R$, the Gaussian curvature is $\frac{1}{R^2}$, since any plane containing the normal produces a great circle of radius $R$, i.e. of curvature $\frac{1}{\kappa}$.
\end{itemize}

\begin{theorem}[Gauss's Remarkable Theorem]
    The Gaussian curvature of a surface $S$ is invariant under local isometries; i.e. if you bend the surface without stretching it.
\end{theorem}

\section{Coordinates, Differentials and Gradients}
\subsection{Differentials and First Order Changes}
Recall that for a function $f(u_1, \dots, u_n)$, we define the differential of $f$, written $\dd f$, by
\[ \dd f = \frac{\partial f}{\partial u_i} \dd u_i \]
noting that the summation convention applies. The $\dd u_i$ are called differential forms, which can be thought of as linearly independent objects (if the coordinates $u_1, \dots, u_n$ are independent), i.e. $\alpha_i \dd u_i = 0 \implies \alpha_i = 0$ for all $i$. Similarly, if we have a vector $\bm x(u_1, \dots, u_n)$, we define
\[ \dd \bm x = \frac{\partial \bm x}{\partial u_i} \dd u_i \]
As an example, let $f(u, v, w) = u^2 + w \sin(v)$. Then
\[ \dd f = 2u \,\dd u + w \cos(v) \,\dd v + \sin(v) \,\dd w \]
Similarly, given
\[ \bm x(u, v, w) = \begin{pmatrix}
        u^2 - v^2 \\ w \\ e^v
    \end{pmatrix} \]
we can compute
\[ \dd \bm x = \begin{pmatrix}
        2u \\ 0 \\ 0
    \end{pmatrix} \dd u + \begin{pmatrix}
        -2v \\ 0 \\ e^v
    \end{pmatrix} \dd v + \begin{pmatrix}
        0 \\ 1 \\ 0
    \end{pmatrix} \dd w \]
Differentials encode information about how a function (or vector field) changes when we change the coordinates by a small amount. By calculus,
\[ f(u + \delta u_1, \dots, u_n + \delta u_n) - f(u_1, \dots, u_n) = \frac{\partial f}{\partial u_i} \delta u_i + o(\delta \bm u) \]
So if $\delta f$ denotes the change in $f(u_1, \dots, u_n)$ under this small change in coordinates, we have, to first order,
\[ \delta f \approx \frac{\partial f}{\partial u_i}\delta u_i \]
The analogous result holds for vector vields:
\[ \delta \bm x \approx \frac{\partial \bm x}{\partial u_i}\delta u_i \]

\subsection{Coordinates and Line Elements in $\mathbb R^2$}
We can create multiple different consistent coordinate systems by defining a relationship between them. For example, polar coordinates $(r, \theta)$ and Cartesian coordinates $(x, y)$ can be related by
\[ x = r \cos \theta;\quad y = r \sin \theta \]
Even though this relationship is not bijective (there are multiple polar coordinates mapping to the origin), it's still a useful coordinate system because the vast majority of points work well. Even coordinate systems with a countable amount of badly-behaved points are still useful.

A general set of coordinates $(u, v)$ on $\mathbb R^2$ can be specified by their relationship to the standard Cartesian coordinates $(x, y)$. We must specify smooth, invertible functions $x(u, v)$, $y(u, v)$. We would also like to have a small change in one coordinate system to be equivalent to a small change in the other coordinate system (i.e. the inverse is also smooth). The same principle applies in $\mathbb R^3$ for three coordinates, for example.

Consider the standard Cartesian coordinates in $\mathbb R^2$.
\[ \bm x(x, y) = \begin{pmatrix}
        x \\ y
    \end{pmatrix} = x \bm e_x + y \bm e_y \]
Note that $\{\bm e_x, \bm e_y\}$ are orthonormal, and point in the same direction regardless of the value of $\bm x$: $\bm e_x$ points in the direction of changing $x$ with $y$ held constant, for example. Equivalently,
\[ \bm e_x = \frac{\frac{\partial}{\partial x} \bm x(x, y)}{\abs{\frac{\partial}{\partial x} \bm x(x, y)}};\quad \bm e_y = \frac{\frac{\partial}{\partial y} \bm x(x, y)}{\abs{\frac{\partial}{\partial y} \bm x(x, y)}} \]
Note that
\[ \dd \bm x = \frac{\partial \bm x}{\partial x}\dd x + \frac{\partial \bm x}{\partial y} \dd y = \dd x \,\bm e_x + \dd y \,\bm e_y \]
In other words, when applying the change in coordinate $x \mapsto x + \delta x$, the vector changes (to first order) to $\bm x \mapsto \bm x + \delta x \bm e_x$. In fact, in the case of Cartesian coordinates, this change is precisely correct for any size of $\delta$, since the coordinate basis vectors are the same everywhere. We call $\dd \bm x$ the line element; it tells us how small changes in coordinates produce changes in position vectors.

Now, let us consider polar coordinates in two-dimensional space. We can use the same idea as before, giving
\[ \bm e_r = \frac{\frac{\partial}{\partial r} \bm x(r, \theta)}{\abs{\frac{\partial}{\partial r} \bm x(r, \theta)}} = \begin{pmatrix}
        \cos\theta \\ \sin\theta
    \end{pmatrix};\quad \bm e_\theta = \frac{\frac{\partial}{\partial \theta} \bm x(r, \theta)}{\abs{\frac{\partial}{\partial \theta} \bm x(r, \theta)}} = \begin{pmatrix}
        -\sin\theta \\ \cos\theta
    \end{pmatrix} \]
Therefore, we have
\[ \bm x(r, \theta) = \begin{pmatrix}
        r \cos\theta \\ r \sin\theta
    \end{pmatrix} = r\bm e_r \]
Note that $\{\bm e_r, \bm e_\theta\}$ are also orthonormal at each $(r, \theta)$, but their exact values are not the same everywhere. Since the basis vectors are orthogonal, we can call $r$ and $\theta$ orthogonal curvilinear coordinates. Also, we can compute the line element $\dd \bm x$ as
\[ \dd \bm x = \frac{\partial \bm x}{\partial r} \dd r + \frac{\partial \bm x}{\partial \theta} \dd \theta = \begin{pmatrix}
        \cos \theta \\ \sin \theta
    \end{pmatrix} \dd r + \begin{pmatrix}
        -r \sin \theta \\ r \cos \theta
    \end{pmatrix} \dd \theta = \dd r \, \bm e_r + r\, \dd \theta \, \bm e_\theta \]
We see that a change in $\theta$ produces (up to first order) a change $\bm x \mapsto \bm x + r \,\delta \theta \,\bm e_\theta$, a change proportional to $r$. So a small change in $\theta$ could cause quite a large change in Cartesian coordinates.

\subsection{Orthogonal Curvilinear Coordinates}
We say that $(u, v, w)$ are a set of orthogonal curvilinear coordinates if the vectors
\[ \bm e_u = \frac{\frac{\partial \bm x}{\partial u}}{\abs{\frac{\partial \bm x}{\partial u}}};\quad \bm e_v = \frac{\frac{\partial \bm x}{\partial v}}{\abs{\frac{\partial \bm x}{\partial v}}};\quad \bm e_w = \frac{\frac{\partial \bm x}{\partial w}}{\abs{\frac{\partial \bm x}{\partial w}}} \]
form a right-handed, orthonormal basis for each $(u, v, w)$; but not necessarily the same basis over the entire vector field. It is standard to write
\[ h_u = \abs{\frac{\partial \bm x}{\partial u}};\quad h_v = \abs{\frac{\partial \bm x}{\partial v}};\quad h_w = \abs{\frac{\partial \bm x}{\partial w}} \]
We call $h_u, h_v, h_w$ the scale factors.  Note that the line element is
\begin{align*}
    \dd \bm x & = \frac{\partial \bm x}{\partial u}\dd u + \frac{\partial \bm x}{\partial v}\dd v + \frac{\partial \bm x}{\partial w} \dd w \\
              & = h_u \bm e_u \dd u + h_v \bm e_v \dd v + h_w \bm e_w \dd w
\end{align*}
So the scale factors show how first-order changes in the coordinates are scaled into changes in $\bm x$.

\subsection{Cylindrical Polar Coordinates}
We define $(\rho, \phi, z)$ by
\[ \bm x(\rho, \phi, z) = \begin{pmatrix}
        \rho \cos \phi \\
        \rho \sin \phi \\
        z
    \end{pmatrix} \]
where $0 \leq \rho; 0 \leq \phi < 2 \pi; z \in \mathbb R$. So we can find
\[ \bm e_\rho = \begin{pmatrix}
        \cos \phi \\ \sin \phi \\ 0
    \end{pmatrix};\quad \bm e_\phi = \begin{pmatrix}
        -\sin \phi \\ \cos \phi \\ 0
    \end{pmatrix};\quad \bm e_z = \begin{pmatrix}
        0 \\ 0 \\ 1
    \end{pmatrix} \]
The scale factors are
\[ h_\rho = 1;\quad h_\phi = \rho;\quad h_z = 1 \]
The line element is
\[ \dd \bm x = \dd \rho \, \bm e_\rho + \rho \, \dd \phi \, \bm e_\phi + \dd z \, \bm e_z \]
Note that
\[ \bm x = \rho \begin{pmatrix}
        \cos \phi \\ \sin \phi \\ 0
    \end{pmatrix} + z \begin{pmatrix}
        0 \\ 0 \\ 1
    \end{pmatrix} = \rho \bm e_\rho + z \bm e_z \]

\subsection{Spherical Polar Coordinates}
We define $(r, \theta, \phi)$ by
\[ \bm x(r, \theta, \phi) = \begin{pmatrix}
        r \cos \phi \sin \theta \\
        r \sin \phi \sin \theta \\
        r \cos \theta
    \end{pmatrix} \]
where $0 \leq r; 0 \leq \theta < 2 \pi; 0 \leq \phi < 2 \pi$. So we can find
\[ \bm e_r = \begin{pmatrix}
        \cos \phi \sin \theta \\ \sin \phi \sin \theta \\ \cos \theta
    \end{pmatrix};\quad \bm e_\theta = \begin{pmatrix}
        \cos \phi \cos \theta \\ \sin \phi \cos \theta \\ -\sin \theta
    \end{pmatrix};\quad \bm e_\phi = \begin{pmatrix}
        -\sin \phi \\ \cos \phi \\ 0
    \end{pmatrix} \]
The scale factors are
\[ h_r = 1;\quad h_\theta = r;\quad h_\phi = r \sin \theta \]
The line element is
\[ \dd \bm x = \dd r \, \bm e_r + r \, \dd \theta \, \bm e_\theta + r \sin \theta \, \dd \phi \, \bm e_\phi \]
Note that
\[ \bm x = r \begin{pmatrix}
        \cos \phi \sin \theta \\ \sin \phi \sin \theta \\ \cos \theta
    \end{pmatrix} = r \bm e_r \]

\section{Gradient Operator}
\subsection{Definition}
For $f \colon \mathbb R^3 \to \mathbb R$, we define the gradient of $f$, written $\nabla f$, by
\begin{equation}
    f(\bm x + \bm h) = f(\bm x) + \nabla f(\bm x) \cdot \bm h + o(\bm h)
    \tag{$\ast$}
\end{equation}
as $\abs{\bm h} \to 0$. The directional derivative of $f$ in the direction $\bm v$, denoted by $D_{\bm v} f$ or $\frac{\partial f}{\partial \bm v}$, is defined by
\[ D_{\bm v} f(\bm x) = \lim_{t \to 0} \frac{f(\bm x + t\bm v) - f(\bm x)}{t} \]
Alternatively,
\begin{equation}
    f(\bm x + t\bm v) = f(\bm x) + t D_{\bm v}f(\bm x) + o(t)
    \tag{$\dagger$}
\end{equation}
as $t \to 0$. Setting $\bm h = t\bm v$ in $(\ast)$, we have
\[ f(\bm x + t\bm v) = f(\bm x) + t \nabla f(\bm x) \cdot \bm v + o(t) \]
This gives another way to interpret the gradient of $f$. Comparing this result to $(\dagger)$, we see that
\[ D_{\bm v} f = \bm v \cdot \nabla f \]
By the Cauchy-Schwarz inequality, the dot product is maximised when the two vectors are parallel. Hence, the directional derivative is maximised when $\bm v$ points in the direction of $\nabla f$. So $\nabla f$ points in the direction of greatest increase of $f$. Similarly, $-\nabla f$ points in the direction of greatest decrease of $f$. For example, suppose $f(x) = \frac{1}{2}\abs{\bm x}^2$. Then
\[ f(\bm x + \bm h) = \frac{1}{2}(\bm x + \bm h)\cdot (\bm x + \bm h) = \frac{1}{2}\abs{\bm x}^2 + \frac{1}{2}(2\bm x \cdot \bm h) + \frac{1}{2}\abs{\bm h}^2 = f(\bm x) + \bm x \cdot \bm h + o(\bm h) \]
Hence $\nabla f(\bm x) = \bm x$.

\subsection{Gradient on Curves}
Suppose we have a curve $t \mapsto \bm x(t)$. How does some function $f$ change when moving along the curve? We will write $F(t) = f(\bm x(t)), \delta \bm x = \bm x(t + \delta t) - \bm x(t)$.
\begin{align*}
    F(t + \delta t) & = f(\bm x(t + \delta t))                                                \\
                    & = f(\bm x(t) + \delta \bm x)                                            \\
                    & = f(\bm x(t)) + \nabla f(\bm x(t)) \cdot \delta \bm x + o(\delta \bm x) \\
    \intertext{Since $\delta \bm x = \bm x'(t) \,\delta t + o(\delta t)$, we have}
    F(t + \delta t) & = F(t) + \bm x'(t) \cdot \nabla f(\bm x(t)) \,\delta t + o(\delta t)
\end{align*}
In other words,
\[ \frac{\dd F}{\dd t} = \frac{\dd}{\dd t}f(\bm x(t)) = \frac{\dd \bm x}{\dd t} \cdot \nabla f(\bm x(t)) \]

\subsection{Gradient on Surfaces}
Suppose we have a surface $S$ in $\mathbb R^3$ defined implicitly by
\[ S = \{ \bm x \in \mathbb R^3 : f(\bm x) = 0 \} \]
If $t \mapsto \bm x(t)$ is any curve in $S$, then $f(\bm x(t)) = 0$ everywhere. So
\[ 0 = \frac{\dd}{\dd t}f(\bm x(t)) = \nabla f(\bm x(t)) \cdot \frac{\dd \bm x}{\dd t} \]
So $\nabla f(\bm x(t))$, the gradient, is orthogonal to $\frac{\dd \bm x}{\dd t}$, the tangent vector of any chosen curve in $S$. So $\nabla f(\bm x(t))$ is normal to the surface.

\subsection{Coordinate-Independent Representation}
If we are working in an orthogonal curvilinear coordinate system $(u, v, w)$, it is not immediately clear how to compute $\nabla f$, since we need to represent this arbitrary perturbation $\bm h$ using $(u, v, w)$. In Cartesian coordinates it is simple; to represent the change $\bm x \mapsto \bm x + \bm h$ we simply add the components of $\bm x$ and $\bm h$.
\begin{align*}
    f(\bm x + \bm h) & = f((x + h_1, y + h_2, z + h_3))                                                                                                  \\
                     & = f(\bm x) + \frac{\partial f}{\partial x} h_1 + \frac{\partial f}{\partial y} h_2 + \frac{\partial f}{\partial z} h_3 + o(\bm h) \\
                     & = f(\bm x) + \begin{pmatrix}
        \partial f / \partial x \\ \partial f / \partial y \\ \partial f / \partial z
    \end{pmatrix} \cdot h + o(\bm h)                                                                        \\
\end{align*}
So we have
\[ \implies \nabla f = \begin{pmatrix}
        \partial f / \partial x \\ \partial f / \partial y \\ \partial f / \partial z
    \end{pmatrix} \]
Or, using suffix notation,
\[ \nabla f = \bm e_i \frac{\partial f}{\partial x_i};\quad [\nabla f]_i = \frac{\partial f}{\partial x_i} \]
We see that this $\nabla$ is a kind of vector differential operator. In Cartesian coordinates,
\[ \nabla = \bm e_x \frac{\partial}{\partial x} + \bm e_y \frac{\partial}{\partial y} + \bm e_z \frac{\partial}{\partial z} \equiv \bm e_i \frac{\partial}{\partial x_i} \]
From our previous example,
\[ f(\bm x) = \frac{1}{2}(x^2 + y^2 + z^2) = \frac{1}{2}\abs{\bm x}^2 \]
\begin{align*}
    [\nabla f]_i & = \frac{\partial}{\partial x_i}\left[ \frac{1}{2} x_j x_j \right] \\
                 & = \frac{1}{2} \left[ \delta_{ij} x_j + x_j \delta_{ij} \right]    \\
                 & = x_i                                                             \\
    \nabla f     & = \bm e_i x_i
\end{align*}
Let us return back to computing the gradient in the general case. Recall that in Cartesian coordinates, the line element is simple:
\[ \dd \bm x = \dd x_i \bm e_i \]
And also, if we have a function on $\mathbb R^3$ such as $f(x, y, z)$, it has the differential
\[ \dd f = \frac{\partial f}{\partial x_i}\dd x_i \]
Then,
\begin{align*}
    \nabla f \cdot \dd \bm x & = \left( \bm e_i \frac{\partial f}{\partial x_i} \right) \cdot \left( \bm e_j \dd x_j \right) \\
                             & = \frac{\partial f}{\partial x_i} \left( \bm e_i \cdot \bm e_j \right) \dd x_j                \\
                             & = \frac{\partial f}{\partial x_i} \delta_{ij} \dd x_j                                         \\
                             & = \frac{\partial f}{\partial x_i} \dd x_i                                                     \\
                             & = \dd f
\end{align*}
In other words, in \textit{any} set of coordinates,
\[ \nabla f \cdot \dd \bm x = \dd f \]

\subsection{Computing the Gradient Vector}
\begin{proposition}
    If $(u, v, w)$ are orthogonal curvilinear coordinates, and $f$ is a function of the position vector $(u, v, w)$, then
    \[ \nabla f = \frac{1}{h_u}\frac{\partial f}{\partial u}\bm e_u + \frac{1}{h_v}\frac{\partial f}{\partial v}\bm e_v + \frac{1}{h_w}\frac{\partial f}{\partial w}\bm e_w \]
\end{proposition}
\begin{proof}
    If $f = f(u, v, w)$ and $\bm x = \bm x(u, v, w)$, then
    \[ \dd f = \frac{\partial f}{\partial u}\dd u + \frac{\partial f}{\partial v}\dd v + \frac{\partial f}{\partial w}\dd w \]
    \[ \dd x = h_u \dd u \bm e_u + h_v \dd v \bm e_v + h_w \dd w \bm e_w \]
    Using the above result, we have
    \[ \nabla f \cdot \dd \bm x = \dd f \]
    \[ \left( (\nabla f)_u \bm e_u + (\nabla f)_v \bm e_v + (\nabla f)_w \bm e_w \right) \cdot \left( h_u \dd u \bm e_u + h_v \dd v \bm e_v + h_w \dd w \bm e_w \right) = \frac{\partial f}{\partial u}\dd u + \frac{\partial f}{\partial v}\dd v + \frac{\partial f}{\partial w}\dd w \]
    \[  (\nabla f)_u h_u \dd u + (\nabla f)_v h_v \dd v + (\nabla f)_w h_w \dd w = \frac{\partial f}{\partial u}\dd u + \frac{\partial f}{\partial v}\dd v + \frac{\partial f}{\partial w}\dd w \]
    Since $u, v, w$ are independent coordinates, $\dd u, \dd v, \dd w$ are linearly independent. So we can simply compare coefficients, getting
    \[ \nabla f = \frac{1}{h_u}\frac{\partial f}{\partial u}\bm e_u + \frac{1}{h_v}\frac{\partial f}{\partial v}\bm e_v + \frac{1}{h_w}\frac{\partial f}{\partial w}\bm e_w \]
    as required.
\end{proof}
\noindent In cylindrical polar coordinates, we have
\[ \nabla f = \frac{\partial f}{\partial \rho} \bm e_\rho + \frac{1}{\rho} \frac{\partial f}{\partial \phi} \bm e_\phi + \frac{\partial f}{\partial z} \bm e_z \]
In spherical polar coordinates, we have
\[ \nabla f = \frac{\partial f}{\partial r} \bm e_r + \frac{1}{r} \frac{\partial f}{\partial \theta} \bm e_\theta + \frac{1}{r\sin\theta} \frac{\partial f}{\partial \phi} \bm e_\phi \]
Then using the familiar example $f(\bm x) = \frac{1}{2}\abs{\bm x}^2$, we have
\[
    f = \begin{cases}
        \frac{1}{2}(x^2 + y^2 + z^2) & \text{in Cartesian coordinates}         \\
        \frac{1}{2}(\rho^2 + z^2)    & \text{in cylindrical polar coordinates} \\
        \frac{1}{2}r^2               & \text{in spherical polar coordinates}   \\
    \end{cases}
\]
Then we can check the value of $\nabla f$ in these different coordinate systems.
\begin{align*}
    \nabla f & = \begin{cases}
        x \bm e_x + y \bm e_y + z \bm e_z & \text{in Cartesian coordinates}         \\
        \rho \bm e_\rho + z \bm e_z       & \text{in cylindrical polar coordinates} \\
        r \bm e_r                         & \text{in spherical polar coordinates}   \\
    \end{cases} \\
             & = \bm x
\end{align*}

\end{document}