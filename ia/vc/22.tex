\subsection{Symmetry and antisymmetry}
Observe for a rank 2 tensor that
\[
	T_{ij} = \frac{1}{2}\left( T_{ij} + T_{ji} \right) + \frac{1}{2}\left( T_{ij} - T{ji} \right) \equiv S_{ij} + A_{ij}
\]
where the \(S_{ij}\) are the symmetric components, and the \(A_{ij}\) are the antisymmetric components of the tensor.
Note that the symmetric part \(S_{ij}\) has six independent components (the main diagonal and everything above it), and the antisymmetric part \(A_{ij}\) has three independent components (everything above the main diagonal) since the main diagonal is zero.
So the number of independent components of the symmetric part and the antisymmetric part add up to the number of independent components of a general rank 2 tensor in \(\mathbb R^3\) (nine).
Intuitively, we might think that the information contained in \(A_{ij}\) could be represented as some vector, since it has the same amount of independent components.
\begin{proposition}
	Every rank 2 tensor \(T_{ij}\) can be decomposed uniquely into
	\[
		T_{ij} = S_{ij} + \varepsilon_{ijk} \omega_k
	\]
	where
	\[
		\omega_i = \frac{1}{2}\varepsilon_{ijk} T_{jk}
	\]
	and \(S_{ij}\) is symmetric.
\end{proposition}
\begin{proof}
	From above, we can find \(S_{ij} = \frac{1}{2}\left( T_{ij} + T_{ji} \right)\).
	We now just need to show that
	\[
		\varepsilon_{ijk} \omega_k = \frac{1}{2}\left( T_{ij} - T{ji} \right)
	\]
	We can see that
	\begin{align*}
		\varepsilon_{ijk} \omega_k & = \frac{1}{2}\varepsilon_{ijk} \varepsilon_{k\ell m} T_{\ell m}                      \\
		                           & = \frac{1}{2}\qty(\delta_{i\ell} \delta_{jm} - \delta_{im}\delta_{j\ell}) T_{\ell m} \\
		                           & = \frac{1}{2}\qty(T_{ij} - T_{ji})
	\end{align*}
	To show uniqueness, we now suppose that
	\[
		T_{ij} = S_{ij} + A_{ij} = \widetilde{S}_{ij} + \widetilde{A}_{ij} = \widetilde{T}_{ij}
	\]
	If we take the symmetric part of both sides (i.e.\ \(T_{ij} + T_{ji} = \widetilde{T}_{ij} + \widetilde{T}_{ji}\)), we get \(S_{ij} = \widetilde{S}_{ij}\).
	Likewise, we have \(A_{ij} = \widetilde{A}_{ij}\) by eliminating the equal symmetric parts.
\end{proof}
\noindent As an example, consider an elastic body.
Each point \(\vb x\) in such a body will undergo a small displacement \(\vb u(\vb x)\) when applied to some force.
Consider nearby points \(\vb x + \delta\vb x\) and \(\vb x\) that were initially separated by \(\delta x\).
They will become separated by
\[
	(\vb x + \delta \vb x + \vb u(\vb x + \delta\vb x)) - (\vb x + \vb u(\vb x)) = \delta \vb x + \vb u(\vb x + \delta\vb x) - \vb u(\vb x)
\]
So the change in displacement is
\[
	\vb u(\vb x + \delta\vb x) - \vb u(\vb x)
\]
This value gives us an idea of how much deformation the body is subjected to.
Assuming this is a smooth deformation, we have
\[
	u_i(\vb x + \delta\vb x) - u_i(\vb x) = \pdv{u_i}{x_j}\delta_{x_j} + o(\delta \vb x)
\]
We then decompose \(\pdv{u_i}{x_j}\) as follows.
\[
	\pdv{u_i}{x_j} = e_{ij} + \varepsilon_{ijk}\omega_k
\]
where the \(e_{ij}\) is the symmetric part, and the \(\varepsilon_{ijk}\omega_k\) is the antisymmetric part.
In particular,
\[
	e_{ij} = \frac{1}{2}\qty(\pdv{u_i}{x_j} + \pdv{u_j}{x_i})
\]
is called the linear strain tensor.
Considering the other tensor,
\[
	\omega_k = \frac{1}{2}\varepsilon_{ijk}\pdv{u_j}{x_k} = \frac{-1}{2}\qty(\curl{\vb u})_i
\]
Then,
\[
	u_i(\vb x + \delta \vb x) - u_i(\vb x) = e_{ij} \delta x_j + [\delta \vb x \times \vb \omega]_i + o(\delta \vb x)
\]
So the antisymmetric part corresponds to a rotation, and is irrelevant for describing the deformation of the internals of the body.
So by separating the symmetric and antisymmetric parts, we can in fact remove the antisymmetric part from the equation in order to study just the linear strain.

\subsection{Inertia tensor}
As another example, let us consider the inertia tensor, which is a common rank 2 tensor.
Suppose a body with density \(\rho(\vb x)\) occupies a volume \(V \subset \mathbb R^3\), where each point in the body is rotating with constant angular velocity \(\vb\omega\) about an axis through the origin.
The velocity of a point \(\vb x \in V\) is given by \(\vb v = \vb \omega \times \vb x\).
Hence, the total angular momentum is
\begin{align*}
	\vb L & = \int_V \rho(\vb x) (\vb x \times \vb v) \dd{V}                                         \\
	      & = \int_V \rho(\vb x) (\vb x \times (\vb \omega \times \vb x)) \dd{V}                     \\
	L_i   & = \int_{\mathcal V} \rho(\vb x) (x_k x_k \omega_i - x_i x_j \omega_j) \dd{V}             \\
	      & = \int_{\mathcal V} \rho(\vb x) (x_k x_k \delta_{ij} \omega_j - x_i x_j \omega_j) \dd{V} \\
	      & = I_{ij}\omega_j
\end{align*}
where \(I_{ij}\) is the inertia tensor defined by
\[
	I_{ij} = \int_{\mathcal V} \rho(\vb x) (x_k x_k \delta_{ij} - x_i x_j) \dd{V}
\]
and where
\[
	\mathcal V = \qty{ x_i \colon x_i \vb e_i \in V }
\]
If we had used a different basis, we would have found
\begin{align*}
	I_{ij}' & = \int_{\mathcal V'} \rho(\vb x) (x_k' x_k' \delta_{ij} - x_i' x_j') \dd{V}          \\
	        & = R_{ip} R_{jq} \int_{\mathcal V} \rho(\vb x) (x_k x_k \delta_{pq} - x_p x_q) \dd{V} \\
	        & = R_{ip} R_{jq} I_{pq}
\end{align*}
So it really is a rank 2 tensor.
As an example, consider the ellipsoid
\[
	V = \qty{ \vb x \colon \frac{x_1^2}{a^2} + \frac{x_2^2}{b^2} + \frac{x_3^2}{c^2} \leq 1 }
\]
with uniform density \(\rho_0\).
Then the mass is given by
\[
	M = \frac{4}{3}\pi \rho_0 abc
\]
Then the inertia tensor with respect to this set of basis vectors is given by
\[
	I_{ij} = \int_{\mathcal V} \rho(\vb x) (x_k x_k \delta_{ij} - x_i x_j) \dd{V}
\]
To help with these integrals, we make the following parametrisation into scaled spherical coordinates:
\[
	\left\{ \begin{array}{l}
		x_1 = ar\cos\phi\sin\theta \\
		x_2 = br\sin\phi\sin\theta \\
		x_3 = cr\cos\theta
	\end{array} \right.\quad \phi\in[0, 2\pi),\theta\in[0, \pi], r \in[0, 1]
\]
Note that if \(i \neq j\), then by symmetry we have
\[
	\int_V \rho_0 x_i x_j \dd{V} = 0
\]
Further,
\begin{align*}
	I_{11} & = \rho_0 \int_V x_2^2 + x_3^2 \dd{V}                                                                                                                                  \\
	       & = \rho_0 abc \int_{\phi = 0}^{2\pi} \dd{\phi} \int_{\theta = 0}^\pi \dd{\theta} \int_{r = 0}^1 \dd{r} r^2 (b^2\sin^2\phi\sin^2\theta + c^2\cos^2\theta) r^2\sin\theta \\
	       & = \rho_0 \frac{abc}{5} \int_0^\pi (\pi b^2 \sin^2 \theta + 2\pi c^2\cos^2\theta) \sin\theta \dd{\theta}                                                               \\
	       & = \frac{3M}{20} \int_0^\pi (b^2 \sin^2 \theta + (2c^2 - b^2)\cos^2\theta\sin\theta) \dd{\theta}                                                                       \\
	       & = \frac{3M}{20} \qty(2b^2 + \frac{2}{3}\qty(2c^2 - b^2))                                                                                                              \\
	       & = \frac{M}{5} (b^2 + c^2)
\end{align*}
So by symmetry,
\[
	I_{22} = \frac{M}{5} (a^2 + c^2);\quad I_{33} = \frac{M}{5} (a^2 + b^2)
\]
Hence,
\[
	I_{ij} = \frac{M}{5} \begin{pmatrix}
		b^2 + c^2 & 0         & 0         \\
		0         & a^2 + c^2 & 0         \\
		0         & 0         & a^2 + b^2
	\end{pmatrix}
\]
In particular, if \(a=b=c\),
\[
	I_{ij} = \frac{2M}{5}\delta_{ij}
\]
\begin{proposition}
	If \(T_{ij}\) is symmetric, then there exists a basis \(\{ \vb e_i \}\) for which \(T_{ij}\) only has non-zero entries on the diagonal.
	The coordinate axes of this basis are called the principal axes of the tensor.
\end{proposition}
\begin{proof}
	Recall that for a real symmetric matrix \(M\), we can diagonalise it using an orthogonal transformation with determinant 1.
	The change of basis formula for a matrix is exactly that for a rank 2 tensor, so we can always choose such a change of basis to give a diagonal matrix.
\end{proof}
