\subsection{Basis Vectors}
To represent vectors as some collection of numbers, we can choose some basis vectors \(\vb e_1, \vb e_2, \vb e_3\) which are `orthonormal', i.e.\ they are unit vectors and pairwise orthogonal. Note that
\[ \vb e_i \cdot \vb e_j = \begin{cases}
		1 & \text{if } i = j \\
		0 & \text{otherwise}
	\end{cases} \]
The set \(\{ \vb e_1, \vb e_2, \vb e_3 \}\) is called a basis because any vector can be written uniquely as a linear combination of the basis vectors. Because we have orthonormal basis vectors, we can reduce this to
\[ \vb a = \sum_i \vb a_i \vb e_i \implies \vb a_i = \vb e_i \cdot \vb a \]
By representing a vector as a linear combination of basis vectors, it is very easy to evaluate the scalar product algebraically. To calculate the vector product, we first need to define whether \(\vb e_1 \times \vb e_2 = \vb e_3\) or \(-\vb e_3\). By convention, we assume that the basis vectors are right-handed, i.e.\ \(\vb e_1 \times \vb e_2 = \vb e_3\). Then we can calculate the formula for the cross product in terms of the vectors' components.

\subsection{Scalar Triple Product}
The scalar triple product is the scalar product of one vector with the cross product of two more.
\[ \vb a \cdot (\vb b \times \vb c) = \vb b \cdot (\vb c \times \vb a) = \vb c \cdot (\vb a \times \vb b) = [\vb a, \vb b, \vb c] \]
The result of the scalar triple product is the signed volume of the parallelepiped starting at the origin with axes \(\vb a\), \(\vb b\), \(\vb c\). We can represent this triple product as the determinant of a matrix:
\[
	\vb a \cdot (\vb b \times \vb c) =
	\begin{vmatrix}
		\vb a_1 & \vb a_2 & \vb a_3 \\
		\vb b_1 & \vb b_2 & \vb b_3 \\
		\vb c_1 & \vb c_2 & \vb c_3
	\end{vmatrix}
\]
If the scalar triple product is greater than zero, then \(\vb a, \vb b, \vb c\) is called a right handed set. If it is equal to zero, then the vectors are all coplanar: \(\vb c \in \vecspan \{ \vb a, \vb b \}\).

\subsection{Vector Triple Product}
The vector triple product is the cross product of three vectors. Note that this is non-associative. The proof is covered in the subsequent lecture.
\[ \vb a \times (\vb b \times \vb c) = (\vb a \cdot \vb c) \vb b - (\vb a\cdot \vb b) \vb c \]
\[ (\vb a \times \vb b) \times \vb c = (\vb a \cdot \vb c) \vb b - (\vb b\cdot \vb c) \vb a \]

\subsection{Lines}
A line through \(\vb a\) parallel to \(\vb u\) is defined by
\[ \vb r = \vb a + \lambda \vb u \]
where \(\lambda\) is some real parameter. We can eliminate lambda by using the cross product with \(\vb u\). This will allow us to get a \(\vb u \times \vb u\) term which will cancel to zero.
\[ \vb u \times \vb r = \vb u \times \vb a \]
Informally, this is saying that \(\vb r\) and \(\vb a\) have the same components perpendicular to \(\vb u\). Note that we can also reverse this process. Consider the equation
\[ \vb u \times \vb r = \vb c \]
By using the dot product with \(\vb u\) we can say
\[ \vb u \cdot (\vb u \times \vb r) = \vb u \cdot \vb c \]
If \(\vb u \cdot \vb c \neq 0\) then the equation is inconsistent. Otherwise, we can suppose that maybe \(\vb r = \vb u \times \vb c\) and use the formula for the vector product to get the left hand side to be \(\vb u \times (\vb u \times \vb c) = -\abs{\vb u}^2 \vb c\). Therefore, by inspection, \(\vb a = -\frac{1}{\abs{\vb u}^2}(\vb u \times \vb c)\) is a solution. Now, note that we can add any multiple of \(\vb u\) to \(\vb a\) and it remains a solution. So the general solution is \(\vb r = \vb a + \lambda\vb u\).

\subsection{Planes}
The general point on a plane that passes through \(\vb a\) and has directions \(\vb u\) and \(\vb v\) is
\[ \vb r = \vb a + \lambda \vb u + \mu \vb v \]
where \(\vb u\) and \(\vb v\) are not parallel, and \(\lambda\) and \(\mu\) are real parameters. We can do a dot product with \(\vb n = (\vb u \times \vb v)\) to eliminate both parameters.
\[ \vb n \cdot \vb r = \kappa \]
where \(\kappa = \vb n \cdot \vb a\). Note that \(\abs{\kappa}/\abs{\vb n}\) is the perpendicular distance from the origin to the plane.

\subsection{Other Vector Equations}
The equation of a sphere is given by a quadratic vector equation in \(\vb r\).
\[ \vb r^2 + \vb r \cdot \vb a = k \]
We can complete the square to give
\[ \left(\vb r + \frac 1 2 \vb a \right)^2 = \frac 1 4 \vb a^2 + k \]
which is clearly a sphere with centre \(-\frac 1 2 \vb a\) and radius \(\left( \frac 1 4 \vb a^2 + k \right)^{1/2}\).

Another example of a vector equation is
\[ \vb r + \vb a \times (\vb b \times \vb r) = \vb c \tag{1} \]
where \(\vb a, \vb b, \vb c\) are fixed. We can dot with \(\vb a\) to eliminate the second term:
\[ \vb a \cdot \vb r = \vb a \cdot \vb c \tag{2} \]
Note that using the dot product loses information --- this is simply a tool to make deductions; (2) does not contain the full information of (1). Combining (1) and (2), and using the formula for the vector triple product, we get
\begin{align*}
	\vb r + (\vb a \cdot \vb r) \vb b - (\vb a \cdot \vb b) \vb r          & = \vb c \tag{3} \\
	\implies \vb r + (\vb a \cdot \vb c) \vb b - (\vb a \cdot \vb b) \vb r & = \vb c
\end{align*}
This eliminates the dependency on \(\vb r\) inside the dot product. Now, we can factorise, leaving
\[ (1 - \vb a \cdot \vb b) \vb r = \vb c - (\vb a \cdot \vb c) \vb b \tag{4} \]
If \(1 - \vb a \cdot \vb b \neq 0\) then \(\vb r\) has a single solution, a point. Otherwise, the right hand side must also be zero (otherwise the equation is inconsistent). Therefore, \(\vb c - (\vb a \cdot \vb c)\vb b = \vb 0\). We can now combine this expression for \(\vb c\) into (3), eliminating the \((1- \vb a \cdot \vb b)\) term, to get
\[ (\vb a \cdot \vb r - \vb a \cdot \vb c) \vb b = \vb 0 \]
This shows us that (given that \(\vb b\) is non-zero) the solutions to the equation are given by (2), which is the equation of a plane.
