\subsection{Definition}
For an \(n \times n\) matrix \(M\) with columns \(\vb C_a = M\vb e_a\), then the determinant \(\det(M) = \abs{M} \in \mathbb R\) or \(\mathbb C\) is given by any of the following equivalent definitions.
\begin{align*}
	\det M
	 & = [\vb C_1, \vb C_2, \cdots, \vb C_n]                                                \\
	 & = [M\vb e_1, M\vb e_2, \cdots, M\vb e_n]                                             \\
	 & = \varepsilon_{ij\cdots l}M_{i1}M_{j2} \cdots M_{l n}                                \\
	 & = \sum_\sigma \varepsilon(\sigma) M_{\sigma(1)1}M_{\sigma(2)2} \cdots M_{\sigma(n)n}
\end{align*}
Here are some examples.
\begin{enumerate}
	\item \(n=2\)
	      \[
		      \det M = \sum_\sigma M_{\sigma(1)1}M_{\sigma(2)2} = \begin{vmatrix}
			      M_{11} & M_{21} \\ M_{12} & M_{22}
		      \end{vmatrix} = M_{11}M_{22} - M_{12}M_{21}
	      \]
	\item \(M\) diagonal, i.e.\ \(M_{ij} = 0\) for \(i \neq j\)
	      \[
		      M = \begin{pmatrix}
			      M_{11} & 0      & \cdots & 0      \\
			      0      & M_{22} & \cdots & 0      \\
			      \vdots & \vdots & \ddots & \vdots \\
			      0      & 0      & \cdots & M_{nn}
		      \end{pmatrix} \implies \det M = M_{11}M_{22}\cdots M_{nn}
	      \]
	\item Let \(M\) be \(n\times n\), \(A\) be \((n-1) \times (n-1)\), where
	      \[
		      M = \left( \begin{array}{c|c}
				      A & 0 \\\hline
				      0 & 1
			      \end{array} \right)
	      \]
	      We call \(M\) a matrix `in block form'.
	      So \(M_{ni} = M_{in} = 0\) if \(i \neq n\).
	      So we can restrict the permutation \(\sigma\) to only transmuting the first \((n-1)\) terms, i.e.\ \(\sigma(n) = n\).
	      So \(\det M = \det A\).
\end{enumerate}

\begin{proposition}
	If \(\vb R_a\) are the rows of \(M\), \(\det M\) is given by
	\begin{align*}
		\det M
		 & = [\vb R_1, \vb R_2, \cdots, \vb R_n]                                                \\
		 & = \varepsilon_{ij\cdots l}M_{1i}M_{2j} \cdots M_{nl}                                 \\
		 & = \sum_\sigma \varepsilon(\sigma) M_{1\sigma(1)}M_{2\sigma(2)} \cdots M_{n\sigma(n)}
	\end{align*}
	i.e.\ \(\det M = \det M^\transpose\).
\end{proposition}
\begin{proof}
	Recall that \((\vb C_a)_i = M_{ia} = (\vb R_i)_a\).
	We need to show that one of these definitions is equivalent to one of the previous definitions, then all other equivalent definitions follow.
	We use the \(\Sigma\) definition by considering the product \(M_{1\sigma(1)}M_{2\sigma(2)} \cdots M_{n\sigma(n)}\).
	We may rewrite this product in a different order: \(M_{\rho(1)1}M_{\rho(2)2} \cdots M_{\rho(n)n}\).
	Then \(\rho = \sigma^{-1}\).
	But then \(\varepsilon(\sigma) = \varepsilon(\rho)\), and a sum over \(\sigma\) is equivalent to a sum over \(\rho\).
\end{proof}

\subsection{Expanding by rows or columns}
For an \(n \times n\) matrix \(M\) with entries \(M_{ia}\), we define the minor \(M^{ia}\) to be the \((n-1)\times(n-1)\) determinant of the matrix obtained by deleting row \(i\) and column \(a\) from \(M\).
\begin{proposition}
	The determinant of a generic \(n \times n\) matrix \(M\) is given by
	\begin{align*}
		\det M
		 & = \sum_i (-1)^{i+a} M_{ia} M^{ia} \text{ for a fixed \(a\)} \\
		 & = \sum_a (-1)^{i+a} M_{ia} M^{ia} \text{ for a fixed \(i\)}
	\end{align*}
\end{proposition}
This process is known as expanding by row \(i\) or by column \(a\).
As an example, let us take the following \(4 \times 4\) complex matrix
\[
	M = \begin{pmatrix}
		i & 0  & 3  & 0  \\
		0 & 0  & 2i & 0  \\
		0 & 5i & 0  & -i \\
		2 & 0  & 0  & 1
	\end{pmatrix}
\]
Then, the determinant is given by (expanding by row 3)
\begin{align*}
	\det M
	 & = -5i\begin{vmatrix}
		i & 3  & 0 \\
		0 & 2i & 0 \\
		2 & 0  & 1
	\end{vmatrix} + i\begin{vmatrix}
		i & 0 & 3  \\
		0 & 0 & 2i \\
		2 & 0 & 0
	\end{vmatrix}                                                               \\
	 & = -5i\left[i\begin{vmatrix}
			2i & 0 \\
			0  & 1
		\end{vmatrix} - 3 \begin{vmatrix}
			0 & 0 \\
			2 & 1
		\end{vmatrix}\right] + i\left[-2i\begin{vmatrix}
			i & 0 \\
			2 & 0
		\end{vmatrix}\right] \\
	 & = -5i[i \cdot 2i - 3 \cdot 0] + i[-2i \cdot 0]                                                                             \\
	 & = -5i[-2] + i[0]                                                                                                           \\
	 & = 10i
\end{align*}

\subsection{Row and column operations}
Consider the following consequences of the properties of the determinant:
\begin{itemize}
	\item (row and column scaling) If \(\vb R_i \mapsto \lambda \vb R_i\) for a fixed \(i\), or \(\vb C_a \mapsto \lambda \vb C_a\), then \(\det M \mapsto \lambda \det M\) by multilinearity.
	      If we scale all rows or columns, then \(M \mapsto \lambda M\), so \(\det M \mapsto \lambda^n \det M\) where \(M\) is an \(n \times n\) matrix.
	\item (row and column operations) If \(\vb R_i \mapsto \vb R_i + \lambda \vb R_j\) where \(i \neq j\) (or the corresponding conversion with columns), then \(\det M \mapsto \det M\).
	\item (row and column exchanges) If we swap \(\vb R_i\) and \(\vb R_j\) (or two columns), then \(\det M \mapsto -\det M\).
\end{itemize}
For example, let us find the terminant of matrix \(A\), where
\[
	A = \begin{pmatrix}
		1 & 1 & a \\ a & 1 & 1 \\ 1 & a & 1
	\end{pmatrix};\quad a \in \mathbb C
\]
Then:
\begin{align*}
	\det A                                                    & = \begin{vmatrix} 1 & 1 & a \\ a & 1 & 1 \\ 1 & a & 1 \end{vmatrix}                            \\
	\vb C_1 \mapsto \vb C_1 - \vb C_3:\quad \det A            & = \begin{vmatrix} 1-a & 1 & a \\ a-1 & 1 & 1 \\ 0 & a & 1 \end{vmatrix}                            \\
	\det A                                                    & = (1-a)\begin{vmatrix} 1 & 1 & a \\ -1 & 1 & 1 \\ 0 & a & 1 \end{vmatrix}                       \\
	\vb C_2 \mapsto \vb C_2 - \vb C_3:\quad \det A            & = (1-a)\begin{vmatrix} 1 & 1-a & a \\ -1 & 0 & 1 \\ 0 & a-1 & 1 \end{vmatrix}                       \\
	\det A                                                    & = (1-a)^2\begin{vmatrix} 1 & 1 & a \\ -1 & 0 & 1 \\ 0 & -1 & 1 \end{vmatrix}                     \\
	\vb R_1 \mapsto \vb R_1 + \vb R_2 + \vb R_3 :\quad \det A & = (1-a)^2\begin{vmatrix} 0 & 0 & a+2 \\ -1 & 0 & 1 \\ 0 & -1 & 1 \end{vmatrix}                     \\
	\det A                                                    & = (1-a)^2(a+2)\begin{vmatrix}-1&0\\0&-1\end{vmatrix} = (1-a)^2(a+2)
\end{align*}

\subsection{Multiplicative property of determinants}
\begin{theorem}
	For \(n\times n\) matrices \(M, N\), \(\det (MN) = \det M \cdot \det N\).
\end{theorem}
\noindent We can prove this using the following elaboration on the definition of the determinant:
\begin{lemma}
	\[
		\varepsilon_{i_1 i_2 \cdots i_n} M_{i_1 a_1} M_{i_2 a_2} \cdots M_{i_n a_n} = (\det M) \varepsilon_{a_1 a_2 \cdots a_n}
	\]
\end{lemma}
\begin{proof}
	The left hand side and right hand side are each totally antisymmetric (alternating) in \(a_1, a_2, \cdots, a_n\), so they must be related by a constant of proportionality.
	To fix the constant, we can simply consider taking \(a_i = i\) and the result follows.
\end{proof}
\noindent Now, we prove the above theorem.
\begin{proof}
	Using the lemma above:
	\begin{align*}
		\det MN & = \varepsilon_{i_1 i_2 \cdots i_n} (MN)_{i_1 1} (MN)_{i_2 2} \cdots (MN)_{i_n n}                                                    \\
		        & = \varepsilon_{i_1 i_2 \cdots i_n} {M_{i_1 k_1} \atop N_{k_1 1}} {M_{i_2 k_2} \atop N_{k_2 2}} \cdots {M_{i_n k_n} \atop N_{k_n n}} \\
		        & = (\det M) \varepsilon_{a_1 a_2 \cdots a_n} N_{k_1 1} N_{k_2 2} \cdots N_{k_n n}                                                    \\
		        & = (\det M)(\det N)
	\end{align*}
	as required.
\end{proof}

\subsection{Consequences of multiplicative property}
\begin{enumerate}
	\item \(M^{-1}M = I \implies \det(M^{-1}) \det(M) = \det I = 1\).
	      Therefore, \(\det (M^{-1}) = (\det M)^{-1}\), so \(\det M\) must be nonzero for \(M\) to be invertible.
	\item For \(R\) real and orthogonal, \(R^\transpose R = I \implies \det(R^\transpose) \det(R) = 1\).
	      But \(\det (R^\transpose) = \det R\), so \((\det R)^2 = 1\), so \(\det R = \pm 1\).
	\item For \(U\) complex and unitary, \(U^\dagger U = I \implies \det(U^\dagger) \det(U) = 1\).
	      But since \(U^\dagger = \overline{U^\transpose}\), we have \(\overline{\det U} \det U = 1\), so \(\abs{(\det U)^2} = 1\), so \(\abs{\det U} = 1\).
\end{enumerate}

\subsection{Cofactors and determinants}
Consider a column of some \(n \times n\) matrix \(M\), written in the form
\[
	\vb C_a = \sum_i M_{ia} \vb e_i
\]
\begin{align*}
	\implies \det M & = [ \vb C_1, \cdots, \vb C_a, \cdots, \vb C_n ]                                         \\
	                & = [ \vb C_1, \cdots, \vb C_{a-1}, \sum_i M_{ia} \vb e_i, \vb C_{a+1}, \cdots, \vb C_n ] \\
	                & = \sum_i M_{ia} \Delta_{ia}
\end{align*}
where
\begin{align*}
	\Delta_{ia} & = [ \vb C_1, \cdots, \vb C_{a-1}, \vb e_i, \vb C_{a+1}, \cdots, \vb C_n ]                                                                                         \\
	            & = \begin{vmatrix}
		\mathhuge A                & \begin{matrix}
			0 \\ \vdots \\ 0
		\end{matrix} & \mathhuge B                \\
		\begin{matrix}
			0 & \cdots & 0
		\end{matrix} & 1                          & \begin{matrix}
			0 & \cdots & 0
		\end{matrix} \\
		\mathhuge C                & \begin{matrix}
			0 \\ \vdots \\ 0
		\end{matrix} & \mathhuge D
	\end{vmatrix}
	\intertext{where the zero entries in the rows arise from antisymmetry, giving}
	            & = \underbrace{(-1)^{n-a}}_{\text{amount of column transpositions}} \cdot \underbrace{(-1)^{n-i}}_{\text{amount of row transpositions}} \begin{vmatrix}
		\mathhuge A & \mathhuge B \\
		\mathhuge C & \mathhuge D
	\end{vmatrix} \\
	            & = (-1)^{i+a}M^{ia}
\end{align*}
where \(M^{ia}\) is the minor in this position; the determinant of the matrix with this particular row and column removed.
We call \(\Delta_{ia}\) the cofactor.
\[
	\det M = \sum_i M_{ia} \Delta_{ia} = \sum_i(-1)^{i+a}M_{ia}M^{ia}
\]
Similarly, by considering rows,
\[
	\det M = \sum_a M_{ia} \Delta_{ia} = \sum_a(-1)^{i+a}M_{ia}M^{ia}
\]

\subsection{Adjugates and inverses}
Reasoning as above, consider \(\vb C_b = \sum_i M_{ib} \vb e_i\).
Then,
\[
	[\vb C_1, \cdots, \vb C_{a-1}, \vb C_b, \vb C_{a+1}, \cdots, \vb C_n ] = \sum_i M_{ib} \Delta_{ia}
\]
If \(a=b\) then clearly this is \(\det M\).
Otherwise, \(\vb C_b\) is equal to one of the other columns, so \(\sum_i M_{ib} \Delta_{ia} = 0\).
\[
	\sum_i M_{ib} \Delta_{ia} = (\det M)\delta_{ab}
\]
Similarly,
\[
	\sum_a M_{ja} \Delta_{ia} = (\det M)\delta_{ij}
\]
Now, let \(\Delta\) be the matrix of cofactors (i.e.\ entries \(\Delta_{ia}\)), and we define the adjugate \(\adjugate M = \Delta^\transpose\).
Then
\[
	\Delta_{ia}M_{ib} = \adjugate M_{ai}M_{ib} = (\adjugate M M)_{ab} = (\det M)\delta_{ab}
\]
Therefore,
\[
	\adjugate M M = (\det M) I
\]
We can reach this result similarly considering the other index.
Hence, if \(\det M \neq 0\) then \(M^{-1} = \frac{1}{\det M}\adjugate M\).
