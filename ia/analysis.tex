\documentclass{article}

\input{../util.tex}

\title{Analysis}
\author{Cambridge University Mathematical Tripos: Part IA}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Limits and Convergence: Reviewing Numbers and Sets}
\subsection{Definition of Limit}
\begin{definition}
    We say that the sequence $a_n \to a$ as $n \to \infty$ if given $\varepsilon > 0$, $\exists N$ such that $\abs{a_n - a} < \varepsilon$ for all $n \geq N$. Note that this $N$ is actually a function of $\varepsilon$; we may need to choose a very large $N$ if the $\varepsilon$ provided is very small, for instance.
\end{definition}
\begin{definition}
    An increasing sequence is a sequence for which $a_n \leq a_{n+1}$, and a decreasing sequence is a sequence for which $a_n \geq a_{n+1}$. Such increasing and decreasing sequences are called monotone.
    A strictly increasing sequence or a strictly decreasing sequence simply strengthens the inequalities to not include the equality case.
\end{definition}

\subsection{Fundamental Axiom of the Real Numbers}
If we have some increasing sequence $a_n \in \mathbb R$, where $\exists A \in \mathbb R$ such that $\forall n \geq 1$, $a_n \leq A$, then $\exists a \in \mathbb R$ such that $a_n \to a$ as $n \to \infty$. This is also known as the `least upper bound' axiom or property. This axiom applies equivalently to decreasing sequences of real numbers bounded below. We can also rephrase the axiom to state that every non-empty set of real numbers that is bounded above has a supremum.
\begin{definition}
    We say that the supremum $\sup S$ of a non-empty, bounded above set $S$ is $K$ if
    \begin{enumerate}[(i)]
        \item $x \leq K$ for all $x \in S$
        \item given $\varepsilon > 0$, $\exists x \in S$ such that $x > K - \varepsilon$
    \end{enumerate}
\end{definition}
Note that the supremum (and hence the infimum) is unique.

\subsection{Properties of Limits}
\begin{lemma}
    The following properties about real sequences hold.
    \begin{enumerate}[(i)]
        \item The limit is unique. That is, if $a_n \to a$ and $a_n \to b$, then $a = b$.
        \item If $a_n \to a$ as $n \to \infty$ and $n_1 < n_2 < \dots$, then $a_{n_j} \to a$ as $j \to \infty$. In other words, subsequences converge to the same limit.
        \item If $a_n = c$ for all $n$, then $a_n \to c$ as $n \to \infty$.
        \item If $a_n \to a$ and $b_n \to b$, then $a_n + b_n \to a + b$.
        \item If $a_n \to a$ and $b_n \to b$, then $a_nb_n \to ab$.
        \item If $a_n \to a$, $a_n \neq 0$ for all $n$, and $a \neq 0$, then $\frac{1}{a_n} \to \frac{1}{a}$.
        \item If $a_n \to a$, and $a_n \leq A$ for all $n$, then $a \leq A$.
    \end{enumerate}
\end{lemma}
\begin{proof}
    We prove the some of these statements here.
    \begin{enumerate}[(i)]
        \item Given $\varepsilon > 0$, $\exists n_1$ such that $\abs{a_n - a} < \varepsilon$ for all $n \geq n_1$, and $\exists n_2$ such that $\abs{a_n - b} < \varepsilon$ for all $n \geq n_2$. So let $N = \max(n_1, n_2)$, so both inequalities hold. Then for all $n \geq N$, using the triangle inequality, $\abs{a - b} \leq \abs{a_n - a} + \abs{a_n - b} < 2\varepsilon$. So $a=b$.
        \item Given $\varepsilon > 0$, $\exists N$ such that $\abs{a_n - a} < \varepsilon$ for all $n \geq N$. Since $n_j \geq j$ (by induction), $\abs{a_{n_j} - a} < \varepsilon$ for all $j \geq N$.
              \setcounter{enumi}{4}
        \item $\abs{a_nb_n - ab} \leq \abs{a_nb_n - a_nb} + \abs{a_nb - ab} = \abs{a_n}\abs{b_n - b} + \abs{b}\abs{a_n - a}$.

              If $a_n \to a$, then given $\varepsilon > 0$, $\exists N_1$ such that $\abs{a_n - a} < \varepsilon$ for all $n \geq N_1$. ($\ast$)

              If $b_n \to b$, then given $\varepsilon > 0$, $\exists N_2$ such that $\abs{b_n - b} < \varepsilon$ for all $n \geq N_2$.

              Using ($\ast$), if $n \geq N_1(1)$ (i.e. $\varepsilon = 1$), $\abs{a_n - a} < 1$, so $\abs{a_n} \leq \abs{a} + 1$.

              Therefore $\abs{a_n b_n - ab} \leq \varepsilon(\abs{a} + 1 + \abs{b})$ for all $n \geq N_3(\varepsilon) = \max\{ N_1(1), N_1(\varepsilon), N_2(\varepsilon) \}$.
    \end{enumerate}
\end{proof}

\subsection{Harmonic Series}
\begin{lemma}
    The sequence $\frac{1}{n}$ tends to zero as $n \to \infty$.
\end{lemma}
\begin{proof}
    We know that $\frac{1}{n}$ is a decreasing sequence, and it is bounded below by zero. Hence it converges to a limit $a$. We will prove now that $a = 0$. $\frac{1}{2n} = \frac{1}{2}\cdot \frac{1}{n}$, and by property (v) above, $\frac{1}{2n}$ tends to $\frac{1}{2}\cdot a$. But $\frac{1}{2n}$ is a subsequence of $\frac{1}{n}$, and so by property (ii) it converges to $a$. So by property (i), $\frac{1}{2} \cdot a = a$ hence $a=0$.
\end{proof}

\subsection{Limits in the Complex Plane}
\begin{remark}
    The definition of the limit of a sequence makes perfect sense for $a_n \in \mathbb C$.
\end{remark}
\begin{definition}
    $a_n \to a$ if given $\varepsilon > 0$, $\exists N$ such that $\forall n \geq N$, $\abs{a_n - a} < \varepsilon$.
\end{definition}
From this definition, it is easy to check that properties (i)--(vi) hold for complex numbers. However, property (vii) makes no sense in the world of the complex numbers since they do not have an ordering.

\section{More on Convergence}
\subsection{The Bolzano-Weierstrass Theorem}
\begin{theorem}
    If $x_n$ is a sequence of real numbers, and there exists some $k$ such that $\abs{x_n} \leq k$ for all $n$, then we can find $n_1 < n_2 < n_3 < n_4 < \dots$ and $x \in \mathbb R$ such that $x_{n_j} \to x$ as $j \to \infty$. In other words, any bounded sequence has a convergent subsequence.
\end{theorem}
\begin{remark}
    This theorem does not state anything about the uniqueness of such a subsequence; indeed, there could exist many subsequences that have possibly different limits. For example, $x_n = (-1)^n$ gives $x_{2n+1} \to -1$ and $x_{2n} \to 1$.
\end{remark}
\begin{proof}
    Let $[a_1, b_1]$ be the range of the sequence, i.e. $[-k, k]$. Then let the midpoint $c_1 = \frac{a_1 + b_1}{2}$. Consider the following alternatives:
    \begin{enumerate}
        \item $x_n \in [a_1, c]$ for infinitely many values of $n$.
        \item $x_n \in [c, b_1]$ for infinitely many values of $n$.
    \end{enumerate}
    Note that cases 1 and 2 could hold at the same time. If case 1 holds, we set $a_2 = a_1$ and $b_2 = c$. If case 1 fails, then case 2 must hold, so we can set $a_2 = c$ and $b_2 = b_1$. We have now constructed a subsequence whose range is half as large as the original sequence, and it contains infinitely many values of $x_n$.

    We can proceed inductively to construct sequences $a_n, b_n$ such that $x_m \in [a_n, b_n]$ for infinitely many values of $m$. This is known as a `bisection method'. By construction, $a_{n-1} \leq a_n \leq b_n \leq b_{n-1}$. Since we are dividing by two each time,
    \[ b_n - a_n = \frac{1}{2}(b_{n-1} - a_{n-1}) \tag{$\ast$} \]
    Note that $a_n$ is a bounded, increasing sequence; and $b_n$ is a bounded, decreasing sequence. By the Fundamental Axiom of the Real Numbers, $a_n$ and $b_n$ converge to limits $a \in [a_1, b_1]$ and $b \in [a_1, b_1]$. Using $(\ast)$, $b-a = \frac{b-a}{2} \implies b = a$.

    Since $x_m \in [a_n, b_n]$ for infinitely many values of $m$, having chosen $n_j$ such that $x_{n_j} \in [a_j, b_j]$, there is $n_{j+1} > n_j$ such that $x_{n_{j+1}} \in [a_{j+1}, b_{j+1}]$. Informally, this works because we have an unlimited supply of such $x$ values. Hence
    \[ a_j \leq x_{n_j} \leq b_j \]
    So this $x_{n_j} \to a$, so we have constructed a convergent subsequence.
\end{proof}

\subsection{Cauchy Sequences}
\begin{definition}
    A sequence $a_n$ is called a Cauchy sequence if given $\varepsilon > 0$ there exists $N > 0$ such that $\abs{a_n - a_m} < \varepsilon$ for all $n, m \geq N$. Informally, the terms of the sequence grow ever closer together such that there are infinitely many consecutive terms within a small region.
\end{definition}
\begin{lemma}
    If a sequence converges, it is a Cauchy sequence.
\end{lemma}
\begin{proof}
    If $a_n \to a$, given $\varepsilon > 0$ then $\exists N$ such that $\forall n \geq N, \abs{a_n - a} < \varepsilon$. Then take $m, n \geq N$, and we have
    \[ \abs{a_n - a_m} \leq \abs{a_n - a} + \abs{a_m - a} < 2\varepsilon \]
\end{proof}
\begin{theorem}
    Every Cauchy sequence converges.
\end{theorem}
\begin{proof}
    First, we note that if $a_n$ is a Cauchy sequence then it is bounded. Let us take $\varepsilon = 1$, so $N = N(1)$ in the Cauchy property. Then
    \[ \abs{a_n - a_m} < 1 \]
    for all $m, n \geq N(1)$. So by the triangle inequality,
    \[ \abs{a_m} \leq \abs{a_m - a_N} + \abs{a_N} < 1 + \abs{a_N} \]
    So the sequence after this point is bounded by $1 + \abs{a_N}$. The remaining terms in the sequence are only finitely many, so we can compute the maximum of all of those terms along with $1+\abs{a_N}$ to produce a bound $k$ for all $n$.

    By the Bolzano-Weierstrass Theorem, this sequence $a_n$ has a convergent subsequence $a_{n_j} \to a$. We want to prove that $a_n \to a$. Given $\varepsilon > 0$, there exists $j_0$ such that $\abs{a_{n_j} - a} < \varepsilon$ for all $j \geq j_0$. Also, $\exists N(\varepsilon)$ such that $\abs{a_m - a_n} < \varepsilon$ for all $m, n \geq N(\varepsilon)$. Combining these, we can take a $j$ such that $n_j \geq \max \{ N(\varepsilon), n_{j_0} \}$. Then, if $n \geq N(\varepsilon)$, using the triangle inequality,
    \[ \abs{a_n - a} \leq \abs{a_n - a_{n_j}} + \abs{a_{n_j} - a} < 2\varepsilon \]
\end{proof}
\noindent Therefore, on $\mathbb R$, a sequence is convergent if and only if it is a Cauchy sequence. This is sometimes referred to as the general principle of convergence, however this is a relatively old-fashioned name. This property is very useful, since we don't need to know what the limit actually is.

\subsection{Series}
Let $a_n$ be a real or complex sequence. We say that $\sum_{j=1}^\infty a_j$ converges to $s$ if the sequence of partial sums $s_N$ converges to $s$ as $N \to \infty$, i.e.
\[ s_N = \sum_{j=1}^N a_j \to s \]
If the sequence of partial sums does not converge, then we say that the series diverges. Note that any problem on series can be turned into a problem on sequences, by considering their partial sums.
\begin{lemma}
    \begin{enumerate}[(i)]
        \item If $\sum_{j=1}^\infty a_j$ and $\sum_{j=1}^\infty b_j$ converge, then so does $\sum_{j=1}^\infty (\lambda a_j + \mu b_j)$, where $\lambda, \mu \in \mathbb C$.
        \item Suppose $\exists N$ such that $a_j = b_j$ for all $j \geq N$. Then either $\sum_{j=1}^\infty a_j$ and $\sum_{j=1}^\infty b_j$ both converge, or they both diverge. In other words, the initial terms do not matter for considering convergence (but the sum will change).
    \end{enumerate}
\end{lemma}
\begin{proof}
    \begin{enumerate}[(i)]
        \item We have
              \begin{align*}
                  s_N            & = \sum_{j=1}^\infty (\lambda a_j + \mu b_j)                 \\
                                 & = \sum_{j=1}^\infty \lambda a_j + \sum_{j=1}^\infty \mu b_j \\
                                 & = \lambda c_N + \mu d_N                                     \\
                  \therefore s_N & \to \lambda c + \mu d
              \end{align*}
        \item For any $n \geq N$, we have
              \begin{align*}
                  s_N & = \sum_{j=1}^n a_j = \sum_{j=1}^{N-1} a_j + \sum_{j=n}^N a_j \\
                  d_N & = \sum_{j=1}^n b_j = \sum_{j=1}^{N-1} b_j + \sum_{j=n}^N b_j \\
              \end{align*}
              Taking the difference, we get
              \[ s_N - d_N = \sum_{j=1}^{N-1} a_j - \sum_{j=1}^{N-1} b_j \]
              which is finite. So $s_N$ converges if and only if $d_N$ also converges.
    \end{enumerate}
\end{proof}

\section{Convergence Tests}
\subsection{Geometric Series}
Let $a_n = x^{n-1}$, where $n \geq 1$. Then
\[ s_n = \sum_{j=1}^n a_j = 1 + x + x^2 + \dots + x^{n-1} \]
Then
\[ s_n = \begin{cases}
        \frac{1 - x^n}{1 - x} & \text{if } x \neq 1 \\
        n                     & \text{if } x = 1
    \end{cases} \]
This can be shown by observing that
\[ x s_n = x + x^2 + \dots + x^n = s_n - 1 + x^n \implies s_n(1-x) = 1-x^n \]
If $\abs{x} < 1$, then $x^n \to 0$ as $x \to \infty$. So $s_n \to \frac{1}{1-x}$. If $x > 1$, then $x^n \to \infty$ and so $s_n \to \infty$. If $x < -1$, $s_n$ oscillates. For completeness, if $x=-1$, $s_n$ oscillates between 0 and 1.

Note that the statement $s_n \to \infty$ means that given $a \in \mathbb R$, $\exists N$ such that $s_n > a$ for all $n \geq N$, and a similar statement holds for negative infinity (swapping the inequality). If $s_n$ does not converge or tend to $\pm \infty$, we say that $s_n$ oscillates.

Thus the geometric series converges if and only if $\abs{x} < 1$. Note that to prove that $x^n \to 0$ if $\abs{x} < 1$, we can consider the caase $0 < x < 1$ and write $1/x = 1 + \delta$ for some positive $\delta$. Then $x^n = \frac{1}{(1 + \delta)^n} \leq \frac{1}{1 + \delta n}$ from the binomial expansion, and this tends to zero as required.

\begin{lemma}
    If $\sum_{j=1}^\infty a_j$ converges, then $\lim_{j \to \infty} a_j = 0$.
\end{lemma}
\begin{proof}
    Given $s_n = \sum_{j=1}^n a_j$, we have $a_n = s_n - s_{n-1}$. If $s_n \to a$, then $a_n \to 0$ since $s_{n-1}$ also tends to $a$.
\end{proof}
\begin{remark}
    The converse is not true. For example, the harmonic series diverges, but the terms approach zero. Consider
    \begin{align*}
        s_{2n} & = s_n + \frac{1}{n+1} + \frac{1}{n+2} + \dots + \frac{1}{2n} \\
               & > s_n + \frac{1}{2n} + \frac{1}{2n} + \dots + \frac{1}{2n}   \\
               & = s_n + \frac{1}{2}
    \end{align*}
    So as $n \to \infty$, if the sequence is convergent then the sequences $s_n$ and $s_{2n}$ tend to the same limit, but they clearly do not.
\end{remark}

\subsection{Comparison Test}
In this section, we will let $a_n \in \mathbb R, a_n \geq 0$. In other words, all series contain only non-negative real terms.
\begin{theorem}
    Suppose $0 \leq b_n \leq a_n$ for all $n$. If $\sum_{j=1}^\infty a_j$ converges, then $\sum_{j=1}^\infty b_j$ converges.
\end{theorem}
\begin{proof}
    Let $s_N$ be the $N$th partial sum over the $a_n$, and let $d_N$ be the $N$th partial sum over the $d_N$. Since $b_n \leq a_n, d_N \leq s_N$. But $s_N \to s$, so $d_N \leq s_N \leq s$. So $d_N$ is an increasing sequence that is bounded above by $s$, so it converges.
\end{proof}
\noindent For example, let us analyse the behaviour of the sum of the sequence $\frac{1}{n^2}$. Note that
\[ \frac{1}{n^2} < \frac{1}{n(n-1)} = \frac{1}{n-1} - \frac{1}{n} \]
for $n \geq 2$. By the comparison test, it is sufficient to show that the series on the right hand side converges, in order to show that the original series converges.
\[ \sum_{j=2}^N a_j = 1 - \frac{1}{N} \to 1 \]
as required. So the original series tends to some value less than or equal to 2.

\subsection{Root Test or Cauchy's Test}
\begin{theorem}
    Suppose we have a sequence of non-negative terms $a_n$. Suppose that $a_n^{1/n} \to a$ as $n \to \infty$. Then if $a < 1$, the series $\sum a_n$ converges. If $a > 1$, the series $\sum a_n$ diverges.
\end{theorem}
\begin{remark}
    Nothing can be said if $a=1$. There is an example later of this fact.
\end{remark}
\begin{proof}
    If $a < 1$, let us choose an $r$ such that $a < r < 1$. By the definition of the limit, $\exists N$ such that $\forall n \geq N$, $a_n^{1/n} < r$. This implies that $a_n < r^n$. The geometric series $\sum r^n$ converges. By comparison, the series $a_n$ converges.

    If $a > 1$, for all $n \geq N$, $a_n^{1/n} > 1$ which implies $a_n > 1$, thus $\sum a_n$ diverges, since $a_n$ does not tend to zero.
\end{proof}

\subsection{Ratio Test or d'Alembert's Test}
\begin{theorem}
    Suppose $a_n > 0$, and $\frac{a_{n+1}}{a_n} \to \ell$. If $\ell < 1$, then the series $\sum a_n$ converges. If $\ell > 1$, then the series $\sum a_n$ diverges.
\end{theorem}
\begin{remark}
    Like before, no conclusion can be drawn if $\ell = 1$.
\end{remark}
\begin{proof}
    Suppose $\ell < 1$. We can choose $\ell < r < 1$, $\exists N$ such that $\forall n \geq N$, $\frac{a_{n+1}}{a_n} < r$. Therefore $a_n < r^{n-N} a_N$. Hence, $a_n < k r^n$ where $k$ is independent of $n$. Applying the comparison test, the series $\sum a_n$ must converge.

    If $\ell > 1$, we can choose $\ell > r > 1$. Then $\exists N$ such that $\forall n \geq N$, $\frac{a_{n+1}}{a_n} > r$. As before, $a_n > r^{n-N} a_N$. But the $r^{n-N}$ diverges, so the original series diverges.
\end{proof}

\section{???}
\subsection{Examples of Ratio and Root Tests}
Consider $\sum_1^\infty \frac{n}{2^n}$. We have
\[ \frac{a_{n+1}}{a_n} = \frac{(n+1)/2^{n+1}}{n/2^n} \to \frac{1}{2} \]
So we have convergence, by the ratio test. Now, consider $\sum_1^\infty \frac{1}{n}$ and $\sum_1^\infty \frac{1}{n^2}$. In both cases, the ratio test gives limit 1. So the ratio test is inconclusive if the limit is 1. Since $n^{1/n} \to 1$, the root test is also inconclusive when the limit is 1. To check this limit, we can write
\[ n^{1/n} = 1 + \delta_n;\quad \delta_n > 0 \]
\[ n = (1 + \delta_n)^n > \frac{n(n-1)}{2}\delta_n^2 \]
using the binomial expansion.
\[ \implies \delta_n^2 < \frac{2}{n-1} \implies \delta_n \to 0 \]
The root test is a good candidate for series that contain powers of $n$, for example
\[ \sum_1^\infty \left[ \frac{n+1}{3n+5} \right]^n \]
In this instance, for example, we have convergence.

\subsection{Cauchy's Condensation Test}
\begin{theorem}
    Let $a_n$ be a decreasing sequence of positive terms. Then $\sum_1^\infty a_n$ converges if and only if $\sum_1^\infty 2^n a_{2^n}$ converges.
\end{theorem}
\begin{proof}
    First, note that if $a_n$ is decreasing, then
    \[ a_{2^k} \underset{(\ast)}{\leq} a_{2^{k-1} + i} \underset{(\dagger)}{\leq} a_{2^{k-1}};\quad 1 \leq i \leq 2^{k-1};\quad k \geq 1 \]
    Now let us assume that $\sum a_n$ converges to $A \in \mathbb R$. Then, by $(\ast)$,
    \begin{align*}
        2^{n-1} a_{2^n} & = a_{2^n} + a_{2^n} + \dots + a_{2^n}                \\
                        & \leq a_{2^{n-1}+1} + a_{2^{n-1}+2} + \dots + a_{2^n} \\
                        & = \sum_{m=2^{n-1}+1}^{2^n}a_m
    \end{align*}
    Thus,
    \[ \sum_{n=1}^N 2^{n-1}a_{2^n} \leq \sum_{n=1}^N \sum_{m=2^{n-1}+1}^{2^n} a_m = \sum_{n=2}^{2^N} a_m \]
    Therefore,
    \[ \sum_{n=1}^N 2^n a_{2^n} \leq 2 \sum_{n=2}^{2^N} a_m \leq 2(A-a_1) \]
    Thus $\sum_{n=1}^N 2^n a_{2^n}$ converges, since it is increasing and bounded above. For the converse, we will assume that $\sum 2^n a_{2^n}$ converges to $B$. Using $(\dagger)$,
    \begin{align*}
        \sum_{m=2^{n-1}}^{2^n} a_m & = a_{2^n} + a_{2^n} + \dots + a_{2^n}                \\
                                   & \leq a_{2^{n-1}} + a_{2^{n-1}} + \dots + a_{2^{n-1}} \\
                                   & = 2^{n-1}a_{2^{n-1}}
    \end{align*}
    So we have
    \[ \sum_{m=2}^{2^N} a_m = \sum_{n=1}^N \sum_{m=2^{n-1}+1}^{2^n} a_m \leq \sum_{n=1}^N 2^{n-1} a_{2^{n-1}} \leq \frac{1}{2} B \]
    Therefore, $\sum_{m=1}^N a_m$ is a bounded, increasing sequence and hence converges.
\end{proof}
\noindent Let us consider an example of this test. Consider the series definition of the Riemann zeta function
\[ \zeta(k) = \sum_{n=1}^\infty \frac{1}{n^k} \]
For what $k \in \mathbb R, k>0$ does this series converge? This is equivalent to asking if the following series converges.
\[ \sum_{n=1}^\infty 2^n \left[ \frac{1}{2^n} \right]^k = \sum_{n=1}^\infty \left( 2^{1-k} \right)^n \]
Hence it converges if and only if $2^{1-k} < 1 \iff k > 1$.

\subsection{Alternating Series}
An alternating series is a series where the sign on each term switches between positive and negative.
\begin{theorem}[Alternating Series Test]
    If $a_n$ decreases and tends to zero as $u \to \infty$, then the alternating series
    \[ \sum_1^\infty (-1)^{n+1} a_n \]
    converges.
\end{theorem}
\begin{proof}
    Let us consider the partial sum
    \[ s_n = a_1 - a_2 + a_3 - a_4 + \dots + (-1)^{n+1}a_n \]
    In particular,
    \[ s_{2n} = (a_1 - a_2) + (a_3 - a_4) + \dots + (a_{2n-1} - a_{2n}) \]
    Since the sequence is decreasing, each parenthesised block is positive. Then $s_{2n} \geq s_{2n-2}$. We can also write the partial sum as
    \[ s_{2n} = a_1 - (a_2 - a_3) - (a_4 - a_5) - \dots - (a_{2n-2} - a_{2n-1}) - a_{2n} \]
    Each parenthesised block here is negative. So $s_{2n} \leq a_1$. So $s_{2n}$ is increasing and bounded above, so it must converge. Now, note that
    \[ s_{2n+1} = s_{2n} + a_{2n+1} \to s_{2n} \]
    since $a_{2n+1} \to 0$. So $s_{2n+1}$ also converges, in fact to the same limit. Hence $s_n$ converges to this same limit.
\end{proof}

\end{document}