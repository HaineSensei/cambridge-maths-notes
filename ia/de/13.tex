\subsection{Abel's theorem}
Consider a second order homogeneous ODE:\@
\[
	y'' + p(x)y' + q(x)y = 0
\]
\begin{theorem}[Abel's Theorem]
	If \(p(x)\) and \(q(x)\) are continuous on an interval \(I\), then the Wro\'nskian \(W(x)\) is either zero or non-zero for all \(x \in I\).
\end{theorem}
\begin{proof}
	Let \(y_1, y_2\) be solutions to the equation.
	Then
	\begin{align}
		\label{abelproof1} y_2(y_1'' + p(x)y_1' + q(x)y_1) & = 0 \\
		\label{abelproof2} y_1(y_2'' + p(x)y_2' + q(x)y_2) & = 0
	\end{align}
	Now, calculating \eqref{abelproof2} \(-\) \eqref{abelproof1}, we get
	\begin{equation}\label{abelproof3}
		(y_1y_2'' - y_2y_1'') + p(x)(y_1y_2' - y_2y_1') = 0
	\end{equation}
	As we are solving a second order equation, \(W(x) = y_1y_2' - y_2y_1'\) and therefore
	\[
		\frac{\dd{W}}{\dd{x}} = y_1y_2'' + y_1'y_2' - y_2'y_1' - y_2y_1'' = y_1y_2'' - y_2y_1''
	\]
	Note that these are the coefficients in \eqref{abelproof3}.
	We have therefore
	\begin{equation}\label{abelproof4}
		W' + pW = 0
	\end{equation}
	Then by separating variables:
	\begin{align*}
		\frac{\dd{W}}{W}              & = -p(x)\dd{x}                         \\
		\int_{x_0}^x \frac{\dd{W}}{W} & = -\int_{x_0}^x p(u)\dd{u}            \\
		W(x)                          & = W(x_0)e^{-\int_{x_0}^x p(u) \dd{u}}
	\end{align*}
	This last equation is known as Abel's Identity, and is very important.
	Since \(p(x)\) is continuous on \(I\) with \(x \in I\), it is bounded and therefore integrable.
	Therefore \(e^{-\int_{x_0}^x p(u) \dd{u}} \neq 0\).
	It follows that if \(W(x_0) = 0\) then \(W(x) = 0\) for all \(x\).
	Likewise, if \(W(x_0) \neq 0\), then \(W(x) \neq 0\) for all \(x\) (on the interval).
\end{proof}
\begin{corollary}
	If \(p(x) = 0\), then \(W = W_0\) which is a constant.
\end{corollary}
Note that we can use this to find \(W(x)\) without actually solving the differential equation itself.
For example, Bessel's Equation
\[
	x^2y'' + xy' + (x^2 - n^2)y = 0
\]
has no closed form solutions, but the Wro\'nskian can be calculated be rewriting it as
\[
	y'' + \frac{1}{x}y' + \frac{x^2-n^2}{x^2}y = 0
\]
and by Abel's Identity,
\begin{align*}
	W(x) & = W_0 e^{-\int_{x_0}^x \frac{1}{u} \dd{u}} \\
	     & = W_0 e^{-\ln x}                           \\
	     & = \frac{W_0}{x}
\end{align*}

\subsection{Using Abel's identity}
We can find a second solution \(y_2\) given a solution \(y_1\) using a reduction of order method, but we can also use Abel's Identity.
\[
	y_1y_2' - y_2y_1' = W_0 e^{-\int_{x_0}^x p(u) \dd{u}}
\]
This is a first order ODE for \(y_2\) which we can now solve:
\[
	\frac{y_1y_2' - y_2y_1'}{y_1^2} =  \frac{W_0}{y_1^2} e^{-\int_{x_0}^x p(u) \dd{u}}
\]
The left hand side is exactly the quotient rule, giving
\[
	\dv{x}\frac{y_2}{y_1} = \frac{W_0}{y_1^2} e^{-\int_{x_0}^x p(u) \dd{u}}
\]
which can be solved to give \(y_2\) as a function of \(y_1\) and \(W\).

\subsection{Abel's theorem in higher dimensions}
Any linear \(n\)th order ODE can be written
\[
	\vb Y' + A(x) \vb Y = 0
\]
where \(A\) is a matrix; this converts an \(n\)th order ODE into a system of \(n\) first order ODEs.
This will be discussed later in the course.
It can be shown that this generalisation of Abel's Identity
\[
	W' + \tr(A)W = 0
\]
holds, and hence
\[
	W' = W_0e^{-\int_{x_0}^x \tr(A) \dd{u}}
\]
and Abel's theorem holds.
This is shown on Example Sheet 3, Question 7.

\subsection{Equidimensional equations}
An ODE is equidimensional if the differential operator is unaffected by a multiplicative scaling.
For example, rescaling
\[
	x \mapsto X = \alpha x
\]
where \(\alpha \in \mathbb R\).
The general form for a second order equidimensional equation is
\begin{equation}\label{equidimensional1}
	ax^2 y'' + bxy' + cy = f(x)
\end{equation}
where \(a, b, c\) are constant.
Note, \(\frac{\dd}{\dd{X}} = \frac{1}{\alpha}\frac{\dd}{\dd{x}}\), and \(\frac{\dd^2}{\dd{X}^2} = \frac{1}{\alpha^2}\frac{\dd}{\dd{x}^2}\), so plugging this into \eqref{equidimensional1} gives
\[
	aX^2\frac{\dd^2 y}{\dd{X}^2} + bX\frac{\dd{y}}{\dd{X}} + cy = f\left(\frac{X}{\alpha}\right)
\]
The left hand side was unaffected by this rescaling, so the equation is equidimensional.

There are two main methods for solving equidimensional equations.
\begin{enumerate}
	\item Note that \(y = x^k\) is an eigenfunction of the differential operator \(x\frac{\dd}{\dd{x}}\).
	      Inspired by this, to solve \eqref{equidimensional1} we will look for solutions of the form \(y=x^k\), so we have
	      \[
		      ak(k-1) + bk + c = 0
	      \]
	      We can simply solve this quadratic for two roots \(k_1\) and \(k_2\).
	      If \(k_1 \neq k_2\), then the complementary function is
	      \[
		      y_c = Ax^{k_1} + Bx^{k_2}
	      \]
	\item If \(k_1 = k_2\), then the substitution \(z = \ln x\) turns \eqref{equidimensional1} into an equation with constant coefficients.
	      \[
		      a \frac{\dd^2 y}{\dd{z}^2} + (b-a)\frac{\dd{y}}{\dd{z}} + cy = f(e^z)
	      \]
	      (TODO verify this).
	      Because this has constant coefficients, our complementary functions will be of the form \(y = e^{\lambda z}\), which can be solved as usual.
	      \[
		      y_c = Ae^{\lambda_1 z} + Be^{\lambda_2 z} = Ax^{\lambda_1} + Bx^{\lambda_2}
	      \]
	      which is the same form as above.
	      In this form, it is easier to see that if the two solutions \(\lambda_1\), \(\lambda_2\) are the same, then
	      \[
		      y_c = Ae^{\lambda_1 z} + Bze^{\lambda_1 z} = Ax^{k_1} + Bx^{k_1}\ln x
	      \]
\end{enumerate}
