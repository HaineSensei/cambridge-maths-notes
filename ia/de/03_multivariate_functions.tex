\subsection{Partial derivatives}
We define the partial derivative of a two-valued function \(f(x, y)\) with respect to \(x\) (for example) by:
\begin{equation}
	\eval{\frac{\partial f}{\partial x}}_{y} = \lim_{\delta x\to 0} \frac{f(x + \delta x, y) - f(x, y)}{\delta x}
\end{equation}
For example, if \(f(x,y) = x^2 + y^3 + e^{xy^2}\), we have
\begin{align*}
	\eval{\frac{\partial f}{\partial x}}_{y}     & = 2x + y^2 e^{xy^2} \\
	\eval{\frac{\partial^2 f}{\partial x^2}}_{y} & = 2 + y^4 e^{xy^2}
\end{align*}
We can also define `cross-derivatives' by differentiating successively with respect to different variables, for example
\[
	\eval{\frac{\partial}{\partial y} \left( \eval{\frac{\partial f}{\partial x}}_{y} \right)}_{x} = 2ye^{xy^2} + 2xy^3e^{xy^2}
\]
The order of computation of cross-derivatives is irrelevant, provided that the required derivatives all exist.
\begin{equation}
	\frac{\partial^2 f}{\partial x \partial y} = \frac{\partial}{\partial x}\frac{\partial f}{\partial y} = \frac{\partial}{\partial y}\frac{\partial f}{\partial x} = \frac{\partial^2 f}{\partial y \partial x}
\end{equation}
We use a subscript shorthand to denote partial differentiation.
Where the point of evaluation of the derivative is not stated, it is implied to be fixed.
For example:
\[
	\eval{\frac{\partial f}{\partial x}}_{y} = \frac{\partial f}{\partial x} = f_x
\]
However, with a function \(f(x, y, z)\):
\[
	\eval{\frac{\partial f}{\partial x}}_{yz} \neq \eval{\frac{\partial f}{\partial x}}_{y}
\]
because \(z\) is not fixed.

\subsection{Multivariate chain rule}
In this section, all use of \(o\) notation is defined to be where all required \(\delta\) values approach 0.
We define the differential of a two-valued function \(f(x, y)\) to be
\begin{equation}\label{differential}
	\delta f = f(x + \delta x, y + \delta y) - f(x, y)
\end{equation}
We can evaluate this differential by rewriting \eqref{differential} as
\begin{align*}
	\delta f =\  & f(x + \delta x, y + \delta y) - f(x + \delta x, y)\ + \\
	             & f(x + \delta x, y) - f(x, y)
\end{align*}
We can move from \((x, y)\) to \((x + \delta x, y + \delta y)\) along the path \((x, y) \to (x + \delta x, y) \to (x + \delta x, y + \delta y)\).
If we move in this way, then we only need to worry about derivatives in the directions of our axes.
From here on in the derivation, the first line will always represent the path segment in the \(y\) direction, and the second line will represent the path segment in the \(x\) direction.

Now that we've separated the differential into these two axes, we can use Taylor series, treating each line as a single-valued function, to expand each of these path segments along the matching axis.
\begin{align*}
	\delta f =\  & f(x + \delta x, y) + \delta y\frac{\partial f}{\partial y}(x + \delta x, y) + o(\delta y) - f(x + \delta x, y)\ + \\
	             & f(x, y) + \delta x \frac{\partial f}{\partial x}(x, y) + o(\delta x) - f(x, y)
\end{align*}
We can now cancel the beginning and ending points of each segment of the path, leaving
\begin{align*}
	\delta f =\  & \delta y\frac{\partial f}{\partial y}(x + \delta x, y)\ + o(\delta y)+ \\
	             & \delta x \frac{\partial f}{\partial x}(x, y) + o(\delta x)
\end{align*}
We can reduce the remaining \(x+\delta x\) term to simply an \(x\) term by performing another Taylor expansion.
\begin{align*}
	\delta f =\  & \delta y\left[ \frac{\partial f}{\partial y}(x, y) + \delta x\frac{\partial^2 f}{\partial y^2}(x, y) + o(\delta x) \right] + o(\delta y)\ + \\
	             & \delta x \frac{\partial f}{\partial x}(x, y) + o(\delta x)
\end{align*}
Expanding out this bracket leaves
\begin{align*}
	\delta f =\  & \delta y\frac{\partial f}{\partial y}(x, y) + \delta x\delta y\frac{\partial^2 f}{\partial y^2}(x, y) + o(\delta x \delta y) + o(\delta y)\ + \\
	             & \delta x \frac{\partial f}{\partial x}(x, y) + o(\delta x)
\end{align*}
We will now change the meanings of each line.
Now, we will group terms by factors.
\begin{align*}
	\delta f =\  & \delta x \frac{\partial f}{\partial x}(x, y) + o(\delta x)\ +                  \\
	             & \delta y\frac{\partial f}{\partial y}(x, y) + o(\delta y)\ +                   \\
	             & \delta x\delta y\frac{\partial^2 f}{\partial y^2}(x, y) + o(\delta x \delta y)
\end{align*}
Because \(o(h)\) is significantly smaller than \(h\), we can eliminate all the \(o\) terms.
\begin{align*}
	\delta f =\  & \delta x \frac{\partial f}{\partial x}(x, y)\ +         \\
	             & \delta y\frac{\partial f}{\partial y}(x, y)\ +          \\
	             & \delta x\delta y\frac{\partial^2 f}{\partial y^2}(x, y)
\end{align*}
Finally, we can eliminate the \(\delta x \delta y\) term because it is vanishingly small as they tend to zero.
\begin{equation}
	\delta f = \delta x \frac{\partial f}{\partial x}(x, y) +
	\delta y\frac{\partial f}{\partial y}(x, y)
\end{equation}
This is the differential form of the multivariate chain rule.
We can take the result of this equation in the limit to create the infinitesimal form:
\begin{equation}\label{mvcr}
	\dd{f} = \dd{x} \frac{\partial f}{\partial x}(x, y) +
	\dd{y}\frac{\partial f}{\partial y}(x, y)
\end{equation}
By integrating \eqref{mvcr}, we get
\[
	\int \dd{f} = \int \frac{\partial f}{\partial x}\ \dd{x} + \int \frac{\partial f}{\partial y}\ \dd{y}
\]
In definite integral form, we can write
\begin{align*}
	f(x_2 - x_1, y_2 - y_1) & = \int_{x_1}^{x_2} \frac{\partial f}{\partial x}(x, y_1)\ \dd{x} + \int_{y_1}^{y_2} \frac{\partial f}{\partial y}(x_2, y)\ \dd{y}    \\
	                        & = \int_{y_1}^{y_2} \frac{\partial f}{\partial y}(x_1, y)\ \dd{y} + \int_{x_1}^{x_2} \frac{\partial f}{\partial x}(x, y_2)\ \dd{x}    \\
	                        & \neq \int_{x_1}^{x_2} \frac{\partial f}{\partial x}(x, y_1)\ \dd{x} + \int_{y_1}^{y_2} \frac{\partial f}{\partial y}(x_1, y)\ \dd{y}
\end{align*}
Note that the first two examples of a right hand side go along the paths \((x_1, y_1) \to (x_2, y_1) \to (x_2, y_2)\) and \((x_1, y_1) \to (x_1, y_2) \to (x_2, y_2)\) by performing the integrals.
However, the last example does not follow a path from \((x_1, y_1)\) to \((x_2, y_2)\), so it is invalid.

\subsection{Change of variables}
We can transform derivatives into different coordinate systems to make problems easier to solve.
For example, let \(f(x, y)\) be some function with a Cartesian coordinate input.
We can rewrite it in terms of polar coordinates \((r, \theta)\).
First, rewrite \(f\) as:
\[
	f(x(r, \theta), y(r, \theta))
\]
then we can write the derivatives.
\[
	\frac{\partial f}{\partial r} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial r} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial r}
\]
We can do similar evaluations for \(\frac{\partial f}{\partial \theta}\), for example.

\subsection{Implicit differentiation}
Consider some surface defined by \(f(x, y, z) = c\).
Then \(f\) implicitly defines functions such as \(z(x, y)\) (provided the function is well-behaved).
We can find, for example, \(\eval{\frac{\partial z}{\partial x}}_y\) by using the multivariate chain rule in three dimensions.

\[
	\eval{\frac{\partial f}{\partial x}}_y =
	\eval{\frac{\partial f}{\partial x}}_{yz} \underbrace{\eval{\frac{\partial x}{\partial x}}_{y}}_{\mathclap{=1}} +
	\eval{\frac{\partial f}{\partial y}}_{xz} \underbrace{\eval{\frac{\partial y}{\partial x}}_{y}}_{\mathclap{=0}} +
	\eval{\frac{\partial f}{\partial z}}_{xy} \eval{\frac{\partial z}{\partial x}}_{y}
\]
Note that the \(\frac{\partial y}{\partial x}\) term is zero because we hold \(y\) to be fixed.
Simplifying, we get
\[
	\eval{\frac{\partial f}{\partial x}}_y =
	\eval{\frac{\partial f}{\partial x}}_{yz} +
	\eval{\frac{\partial f}{\partial z}}_{xy} \eval{\frac{\partial z}{\partial x}}_{y}
\]
The left hand side is zero because on the surface \(z(x, y)\), \(f\) is always equivalent to \(c\) so there is never any \(\delta f\).
The \(\eval{\frac{\partial f}{\partial x}}_{yz}\) term, however, is not zero in general because we are not going across the \(z(x, y)\) surface --- just parallel to the \(x\) axis, because we fixed both \(y\) and \(z\).
Hence,
\[
	\eval{\frac{\partial z}{\partial x}}_y = \frac{-\eval{\frac{\partial f}{\partial x}}_{yz}}{\eval{\frac{\partial f}{\partial z}}_{xy}}
\]

The reciprocal rule for derivatives applies also to partial derivatives so long as the same variables are held fixed.
For example, given the function \(f(x(r, \theta), y(r, \theta))\), we have
\[
	\eval{\frac{\partial r}{\partial x}}_y = \frac{1}{\eval{\frac{\partial x}{\partial r}}_y}
\]
But
\[
	\frac{\partial r}{\partial x} \neq \frac{1}{\frac{\partial x}{\partial r}}
\]
because the left hand side holds \(y\) constant and the right hand side holds \(\theta\) constant.

\subsection{Differentiating an integral with respect to a parameter}
Consider a family of function \(f(x; \alpha)\) where \(\alpha\) is some parameter.
We can say that \(\alpha\) parametrises \(f\).
An example of a parametrised function is the logarithm; \(f(x; \alpha) = \log_\alpha x\).
We define
\[
	I(\alpha) = \int_{a(\alpha)}^{b(\alpha)} f(x; \alpha) \ \dd{x}
\]
So, what is \(\frac{\dd{I}}{\dd \alpha}\)?
By definition, we have
\begin{align*}
	\frac{\dd{I}}{\dd \alpha} & = \lim_{\delta \alpha \to 0} \frac{I(\alpha + \delta \alpha) - I(\alpha)}{\delta \alpha}                                                                                                                                                                                                                                                  \\
	                          & = \lim_{\delta \alpha \to 0} \frac{1}{\delta\alpha} \left[ \int_{a(\alpha + \delta\alpha)}^{b(\alpha + \delta\alpha)} f(x; \alpha + \delta\alpha)\ \dd{x} - \int_{a(\alpha)}^{b(\alpha)} f(x; \alpha)\ \dd{x} \right]                                                                                                                     \\
	                          & = \lim_{\delta \alpha \to 0} \frac{1}{\delta\alpha} \left[ \int_{a(\alpha)}^{b(\alpha)} f(x; \alpha + \delta\alpha) - f(x; \alpha)\ \dd{x} - \int_{a(\alpha)}^{a(\alpha + \delta)} f(x; \alpha + \delta \alpha)\ \dd{x} + \int_{b(\alpha)}^{b(\alpha + \delta)} f(x; \alpha + \delta \alpha)\ \dd{x} \right]                              \\
	                          & = \int_{a(\alpha)}^{b(\alpha)} \lim_{\delta \alpha \to 0} \frac{f(x; \alpha + \delta\alpha) - f(x; \alpha)}{\delta\alpha}\ \dd{x} - f(a; \alpha) \lim_{\delta \alpha \to 0} \frac{a(\alpha + \delta\alpha) - a(\alpha)}{\delta\alpha} + f(b; \alpha) \lim_{\delta \alpha \to 0} \frac{b(\alpha + \delta\alpha) - b(\alpha)}{\delta\alpha} \\
\end{align*}
Therefore:
\[
	\frac{\dd{I}}{\dd \alpha} = \frac{\dd}{\dd \alpha} \int_{a(\alpha)}^{b(\alpha)} f(x; \alpha) \ \dd{x} = \int_{a(\alpha)}^{b(\alpha)} \frac{\partial f}{\partial \alpha} \ \dd{x} + f(b; \alpha) \frac{\dd{b}}{\dd \alpha} - f(a; \alpha) \frac{\dd{a}}{\dd \alpha}
\]
