\subsection{Examples}
\begin{enumerate}
	\item Consider the sequence \(\frac{1}{2},\; \frac{1}{2} + \frac{1}{4},\; \frac{1}{2} + \frac{1}{4} + \frac{1}{8}, \cdots\).
	      This is \(x_1, x_2, x_3, \cdots\) where \(x_n = 1 - \frac{1}{2^n}\) (inductively on \(n\)).
	      We want to show that \(x_n\) tends to 1.
	      Given some \(\varepsilon > 0\), we choose some \(N \in \mathbb N\) with \(N > \frac{1}{\varepsilon}\).
	      Then, for every \(n \geq N\), \(\abs{x_n - 1} = \frac{1}{2^n} \leq \frac{1}{n} \leq \frac{1}{N} < \varepsilon\).
	\item Consider the constant sequence \(c, c, c, c, \cdots\).
	      We want to show that \(x_n \to c\).
	      Given some \(\varepsilon > 0\), we have \(\abs*{x_n - c} < \varepsilon\) for all \(n\); \(N=1\) is the time after which the sequence stays within \(\varepsilon\) of \(c\).
	\item Consider now \(x_n = (-1)^n\), i.e.\ \(-1, 1, -1, 1, \cdots\).
	      We want to show that this does not tend to a limit.
	      Suppose \(x_n \to c\) as \(n \to \infty\).
	      We may choose some \(\varepsilon\) that acts as a counterexample --- for example, \(\varepsilon = 1\).
	      So \(\exists N \in \mathbb N\) such that \(\forall n \geq n\) we have \(\abs{x_n - c} < 1\).
	      In particular, \(\abs{1 - c} < 1\) and \(\abs{-1 - c} < 1\) so \(\abs{1 - (-1)} < 2\), by the triangle inequality.
	      This is a contradiction.
	\item The sequence \(x_n\) given by
	      \[
		      x_n = \begin{cases}
			      \frac{1}{n} & n \text{ odd}  \\
			      0           & n \text{ even}
		      \end{cases}
	      \]
	      should tend to zero.
	      Given some \(\varepsilon > 0\), we will choose \(N \in \mathbb N\) with \(\frac{1}{N} < \varepsilon\).
	      Then for all \(n \geq N\), either \(x_n = \frac{1}{n}\) or 0.
	      In either case, \(\abs{x_n - 0} \leq \frac{1}{n} \leq \frac{1}{N} < \varepsilon\).
\end{enumerate}
We can denote the entirety of a sequence \(x_1, x_2, \cdots\) as \((x_n)\) or \((x_n)_{n=1}^\infty\).
For example, \(\left( (-1)^n \right)_{n=1}^{\infty}\) is divergent.
This isn't saying that it goes to infinity, just that it doesn't converge.
Note also that if \(x_n \to c\) and \(x_n \to d\), then \(c=d\).
Suppose that \(c \neq d\).
Then pick \(\varepsilon = \frac{\abs{c-d}}{2}\).
Then \(\exists N \in \mathbb N\) with \(\abs{x_n - c} < \varepsilon\), and \(\exists M \in \mathbb N\) with \(\abs{x_n - d} < \varepsilon\).
After the point \(\max(N, M)\), the points must be within \(\varepsilon\) of both \(c\) and \(d\), but as \(c\) and \(d\) are \(2\varepsilon\) apart this is a contradiction (by the triangle inequality).

\subsection{Series}
A sequence given in the form \(x_1,\; x_1 + x_2,\; x_1 + x_2 + x_3, \cdots\) is called a series.
They are often written \(\sum_{n=1}^\infty x_n\).
The \(k\)th term of the sequence, given by \(\sum_{n=1}^k x_n\), is called the \(k\)th partial sum.
If the series converges to some value \(c\), then we can write \(\sum_{n=1}^\infty x_n = c\).
Note that we cannot use this notation to denote the limit until we know that the limit actually exists.
This is just the same as with sequences, where we cannot write \(\lim_{n\to\infty} x_n\) until we know that the limit exists.

Limits behave as we would expect.
For example, if \(x_n \leq d\) for all \(n\), and \(x_n \to c\), then \(c \leq d\).
Suppose \(c > d\).
Thwn we will choose \(\varepsilon = \frac{\abs{c - d}}{2}\).
Then there are no points \(x_n\) within this bound of \(c\) \contradiction.

\begin{proposition}
	If \(x_n \to c\) and \(y_n \to d\), then \(x_n + y_n \to c + d\).
\end{proposition}
\begin{proof}
	Given some \(\varepsilon > 0\), let \(\zeta = \frac{1}{2}\varepsilon\).
	Then, after some term \(x_N\), \(\abs{x_n - c} < \zeta\), and after some term \(y_M\), \(\abs{y_m - d} < \zeta\).
	So for every \(n \geq \max(M, N)\), by the triangle inequality, \(\abs{(x_n + y_n) - (c + d)} < 2\zeta = \varepsilon\) as required.
\end{proof}
This is commonly known as an \(\varepsilon/2\) argument.
Also, if we had instead not taken any \(\zeta\) value and just stuck with \(\varepsilon\), it would still be a good proof because we could just have divided \(\varepsilon\) at the beginning --- it's not expected that you completely rewrite the proof to add in this division.
